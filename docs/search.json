[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Welcome age big Earth observation data! Petabytes images now openly accessible cloud services. free access massive data sets, need new methods measure change planet using image data. essential contribution big EO data provide access image time series capture signals locations continually. Time series powerful tool monitoring change, providing insights information single snapshots achieve. Better measurement natural resources depletion caused deforestation, forest degradation, desertification possible. Experts improve production agricultural statistics. Using image time series, analysts can use large data collections detect subtle changes ecosystem health distinguish various land classes effectively. Time series analysis innovative way address global challenges like climate change, biodiversity preservation, sustainable agriculture.book introduces sits, open-source R package big Earth observation data analysis using satellite image time series. Users build regular data cubes cloud services Amazon Web Services, Microsoft Planetary Computer, Copernicus Data Space Ecosystem, NASA Harmonized Landsat-Sentinel, Brazil Data Cube, Swiss Data Cube, Digital Earth Australia, Digital Earth Africa. sits API includes training sample quality measures, machine learning deep learning classification algorithms, Bayesian post-processing methods smoothing uncertainty assessment. evaluate results, sits supports best practice accuracy assessments.","code":""},{"path":"index.html","id":"how-much-r-knowledge-is-required","chapter":"Preface","heading":"How much R knowledge is required?","text":"sits package designed remote sensing experts Earth Sciences field want use advanced data analysis techniques basic programming knowledge. package provides clear direct set functions easy learn master. Users minimal background R programming can start using sits right away. familiar Python JavaScript may consider lack R knowledge barrier use sits. Fear . unfamiliar R can rely programming knowledge since R scripts sits easy follow. Users need basic understanding core concepts functions work, also required Python JavaScript. minimal investment rewarded access package rich set tools.quickly master needed run sits, please read Parts 1 2 Garrett Golemund’s book, Hands-Programming R. Although needed run sits, R skills benefit book Hadley Wickham Gareth Golemund, R Data Science (2nd edition). Important concepts spatial analysis presented Edzer Pebesma Roger Bivand book Spatial Data Science.","code":""},{"path":"index.html","id":"software-version-described-in-this-book","chapter":"Preface","heading":"Software version described in this book","text":"version sits package described book 1.5.1.","code":""},{"path":"index.html","id":"main-reference-for-sits","chapter":"Preface","heading":"Main reference for sits","text":"use sits work, please cite following paper:Rolf Simoes, Gilberto Camara, Gilberto Queiroz, Felipe Souza, Pedro R. Andrade, Lorena Santos, Alexandre Carvalho, Karine Ferreira. Satellite Image Time Series Analysis Big Earth Observation Data. Remote Sensing, 13, p. 2428, 2021.","code":""},{"path":"index.html","id":"intellectual-property-rights","chapter":"Preface","heading":"Intellectual property rights","text":"book licensed Attribution-NonCommercial-ShareAlike 4.0 International (CC -NC-SA 4.0) Creative Commons. sits package licensed GNU General Public License, version 3.0.","code":""},{"path":"setup.html","id":"setup","chapter":"Setup","heading":"Setup","text":"","code":""},{"path":"setup.html","id":"how-to-use-this-on-line-book","chapter":"Setup","heading":"How to use this on-line book","text":"book contains reproducible code can run R environment. three options setup working environment:Install R RStudio packages required sits, specific procedures type operating systems.Use Docker image provided Brazil Data Cube.Install sits dependencies using conda.","code":""},{"path":"setup.html","id":"how-to-install-sits-using-r-and-rstudio","chapter":"Setup","heading":"How to install sits using R and RStudio","text":"suggest staged installation, follows:Get install base R CRAN.Install RStudio Posit website.","code":""},{"path":"setup.html","id":"installing-sits-from-cran","chapter":"Setup","heading":"Installing sits from CRAN","text":"Comprehensive R Archive Network (CRAN), network servers (also known mirrors) around world store --date versions basic code packages R. follows, describe use CRAN sits Windows, Linux MacOS.","code":""},{"path":"setup.html","id":"installing-in-microsoft-windows-and-macos-environments","chapter":"Setup","heading":"Installing in Microsoft Windows and MacOS environments","text":"Windows MacOS users strongly encouraged install binary packages CRAN. sits package relies sf terra packages, require GDAL PROJ libraries. Run RStudio install binary packages sf terra, order:installing binaries sf terra, install sits follows;run examples book, please also install sitsdata package, available GitHub. necessary use package devtools install sitsdata.install sits source, please install Rtools Windows access compiling environment. Mac, please follow instructions available .","code":"\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\ninstall.packages(\"sits\", dependencies = TRUE)\ninstall.packages(\"devtools\")\ndevtools::install_github(\"e-sensing/sitsdata\")"},{"path":"setup.html","id":"installing-in-ubuntu-environments","chapter":"Setup","heading":"Installing in Ubuntu environments","text":"Ubuntu, first step install latest version GDAL, GEOS, PROJ4 libraries binaries. , use repository ubuntugis-unstable, done follows:Getting error adding PPA repository due absence package software-properties-common. installing GDAL, GEOS, PROJ4, please install packages sf terra:please proceed install sits, can installed regular R package.","code":"sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install libudunits2-dev libgdal-dev libgeos-dev libproj-dev \nsudo apt-get install gdal-bin\nsudo apt-get install proj-bin\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\ninstall.packages(\"sits\", dependencies = TRUE)"},{"path":"setup.html","id":"installing-in-debian-environments","chapter":"Setup","heading":"Installing in Debian environments","text":"Debian, use rocker geospatial dockerfiles.","code":""},{"path":"setup.html","id":"installing-in-fedora-environments","chapter":"Setup","heading":"Installing in Fedora environments","text":"case Fedora, following command installs required dependencies:","code":"sudo dnf install gdal-devel proj-devel geos-devel sqlite-devel udunits2-devel"},{"path":"setup.html","id":"using-docker-images","chapter":"Setup","heading":"Using Docker images","text":"familiar Docker, images sits available RStudio Jupyter notebook. images provided Brazil Data Cube team:Version R RStudio.Version Jupyter Notebooks.Windows Mac platform, install Docker obtain one two images listed Brazil Data Cube. images contain full sits running environment. GDAL running docker containers, please add security flag --security-opt seccomp=unconfined start.","code":""},{"path":"setup.html","id":"install-sits-from-conda","chapter":"Setup","heading":"Install sits from CONDA","text":"Conda open-source, cross-platform package manager. convenient way installl Python R packages. use conda, first download software CONDA website. installation, use conda install sits terminal follows:conda installer download packages libraries required run sits. easiest way install sits Windows.","code":"# add conda-forge to the download channels \nconda config --add channels conda-forge\nconda config --set channel_priority strict\n# install sits using conda\nconda install conda-forge::r-sits"},{"path":"setup.html","id":"accessing-the-development-version","chapter":"Setup","heading":"Accessing the development version","text":"source code repository sits GitHub. two versions available GitHub: master dev. master contains current stable version, either code available CRAN minor update bug fixes. install master version, install devtools (already available) follows:install dev (development) version, contains latest updates might unstable, install devtools (already available), install sits follows:","code":"\ninstall.packages(\"devtools\")\ndevtools::install_github(\"e-sensing/sits\", dependencies = TRUE)\ninstall.packages(\"devtools\")\ndevtools::install_github(\"e-sensing/sits@dev\", dependencies = TRUE)"},{"path":"setup.html","id":"additional-requirements","chapter":"Setup","heading":"Additional requirements","text":"run examples book, please also install sitsdata package. recommend installing using wget. See instructions GNU Wget site.","code":"\noptions(download.file.method = \"wget\")\ndevtools::install_github(\"e-sensing/sitsdata\")"},{"path":"setup.html","id":"using-gpus-with-sits","chapter":"Setup","heading":"Using GPUs with sits","text":"torch package automatically recognizes GPU available machine uses training classification. significant performance gain GPUs used instead CPUs deep learning models. need specific adjustments torch scripts. use GPUs, torch requires version 11.6 CUDA library, available Ubuntu 18.04 20.04. Please follow detailed instructions setting torch available .","code":"\ninstall.packages(\"torch\")"},{"path":"acknowledgements.html","id":"acknowledgements","chapter":"Acknowledgements","heading":"Acknowledgements","text":"","code":""},{"path":"acknowledgements.html","id":"funding-sources","chapter":"Acknowledgements","heading":"Funding Sources","text":"authors acknowledge funders supported development sits:Amazon Fund, established Brazil financial contribution Norway, contract 17.2.0536.1. Brazilian Development Bank (BNDES) Foundation Science, Technology, Space Applications (FUNCATE), establishment Brazil Data Cube.Amazon Fund, established Brazil financial contribution Norway, contract 17.2.0536.1. Brazilian Development Bank (BNDES) Foundation Science, Technology, Space Applications (FUNCATE), establishment Brazil Data Cube.Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) grants 312151/2014-4 140684/2016-6.Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) grants 312151/2014-4 140684/2016-6.Sao Paulo Research Foundation (FAPESP) eScience Program grant 2014/08398-6, providing MSc, PhD, post-doc scholarships, equipment, travel support.Sao Paulo Research Foundation (FAPESP) eScience Program grant 2014/08398-6, providing MSc, PhD, post-doc scholarships, equipment, travel support.International Climate Initiative Germany Federal Ministry Environment, Nature Conservation, Building Nuclear Safety (IKI) grant 17-III-084-Global--RESTORE+ (“RESTORE+: Addressing Landscape Restoration Degraded Land Indonesia Brazil”).International Climate Initiative Germany Federal Ministry Environment, Nature Conservation, Building Nuclear Safety (IKI) grant 17-III-084-Global--RESTORE+ (“RESTORE+: Addressing Landscape Restoration Degraded Land Indonesia Brazil”).Microsoft Planetary Computer initiative GEO-Microsoft Cloud Computer Grants Programme.Microsoft Planetary Computer initiative GEO-Microsoft Cloud Computer Grants Programme.Instituto Clima e Sociedade, project grant “Modernization PRODES DETER Amazon monitoring systems”.Instituto Clima e Sociedade, project grant “Modernization PRODES DETER Amazon monitoring systems”.Open-Earth-Monitor Cyberinfrastructure project, received funding European Union’s Horizon Europe research innovation programme grant agreement . 101059548.Open-Earth-Monitor Cyberinfrastructure project, received funding European Union’s Horizon Europe research innovation programme grant agreement . 101059548.FAO-EOSTAT initiative, uses next generation Earth observation tools produce land cover land use statistics.FAO-EOSTAT initiative, uses next generation Earth observation tools produce land cover land use statistics.","code":""},{"path":"acknowledgements.html","id":"community-contributions","chapter":"Acknowledgements","heading":"Community Contributions","text":"authors thank R-spatial community foundational work, including Marius Appel, Tim Appelhans, Robert Hijmans, Jakub Nowosad, Edzer Pebesma, Martijn Tennekes R packages gdalcubes, leafem, terra, supercells, sf/stars, tmap. grateful work Dirk Eddelbuettel Rcpp RcppArmadillo Ron Wehrens package kohonen. much indebted Hadley Wickham tidyverse, Daniel Falbel torch luz packages, RStudio team package leaflet. multiple authors machine learning packages randomForest, e1071, xgboost provided robust algorithms. like thank Python developers shared deep learning algorithms image time series classification: Vivien Sainte Fare Garnot, Zhiguang Wang, Maja Schneider, Marc Rußwurm. first author also thanks Roger Bivand benign influence things related R.","code":""},{"path":"acknowledgements.html","id":"reproducible-papers-and-books-used-in-building-sits","chapter":"Acknowledgements","heading":"Reproducible papers and books used in building sits","text":"thank authors following papers making code papers open reusable. contribution essential build sits.Edzer Pebesma, Simple Features R: Standardized Support Spatial Vector Data. R Journal, 10(1), 2018.Edzer Pebesma, Simple Features R: Standardized Support Spatial Vector Data. R Journal, 10(1), 2018.Martin Tennekes, tmap: Thematic Maps R. Journal Statistical Software, 84(6), 1–39, 2018.Martin Tennekes, tmap: Thematic Maps R. Journal Statistical Software, 84(6), 1–39, 2018.Ron Wehrens Johannes Kruisselbrink, Flexible Self-Organising Maps kohonen 3.0. Journal Statistical Software, 87, 7, 2018.Ron Wehrens Johannes Kruisselbrink, Flexible Self-Organising Maps kohonen 3.0. Journal Statistical Software, 87, 7, 2018.Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller, Deep learning time series classification: review. Data Mining Knowledge Discovery, 33(4): 917–963, 2019.Hassan Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller, Deep learning time series classification: review. Data Mining Knowledge Discovery, 33(4): 917–963, 2019.Charlotte Pelletier, Geoffrey Webb, Francois Petitjean. Temporal Convolutional Neural Network Classification Satellite Image Time Series. Remote Sensing 11 (5), 2019.Charlotte Pelletier, Geoffrey Webb, Francois Petitjean. Temporal Convolutional Neural Network Classification Satellite Image Time Series. Remote Sensing 11 (5), 2019.Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sèbastien Lefèvre, Marco Körner, Breizhcrops: Time Series Dataset Crop Type Mapping. International Archives Photogrammetry, Remote Sensing Spatial Information Sciences ISPRS, 2020.Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sèbastien Lefèvre, Marco Körner, Breizhcrops: Time Series Dataset Crop Type Mapping. International Archives Photogrammetry, Remote Sensing Spatial Information Sciences ISPRS, 2020.Marius Appel Edzer Pebesma, -Demand Processing Data Cubes Satellite Image Collections Gdalcubes Library. Data 4 (3): 1–16, 2020.Marius Appel Edzer Pebesma, -Demand Processing Data Cubes Satellite Image Collections Gdalcubes Library. Data 4 (3): 1–16, 2020.Vivien Garnot, Loic Landrieu, Sebastien Giordano, Nesrine Chehata, Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention, Conference Computer Vision Pattern Recognition, 2020.Vivien Garnot, Loic Landrieu, Sebastien Giordano, Nesrine Chehata, Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention, Conference Computer Vision Pattern Recognition, 2020.Vivien Garnot Loic Landrieu, Lightweight Temporal Self-Attention Classifying Satellite Images Time Series, 2020.Vivien Garnot Loic Landrieu, Lightweight Temporal Self-Attention Classifying Satellite Images Time Series, 2020.Maja Schneider, Marco Körner, Re: Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention ReScience C 7 (2), 2021.Maja Schneider, Marco Körner, Re: Satellite Image Time Series Classification Pixel-Set Encoders Temporal Self-Attention ReScience C 7 (2), 2021.Rolf Simoes, Felipe Souza, Mateus Zaglia, Gilberto Queiroz, Rafael dos Santos Karine Ferreira, Rstac: R Package Access Spatiotemporal Asset Catalog Satellite Imagery. IGARSS, 2021, pp. 7674-7677.Rolf Simoes, Felipe Souza, Mateus Zaglia, Gilberto Queiroz, Rafael dos Santos Karine Ferreira, Rstac: R Package Access Spatiotemporal Asset Catalog Satellite Imagery. IGARSS, 2021, pp. 7674-7677.Jakub Nowosad, Tomasz Stepinksi, Extended SLIC superpixels algorithm applications non-imagery geospatial rasters. International Journal Applied Earth Observations Geoinformation, 2022.Jakub Nowosad, Tomasz Stepinksi, Extended SLIC superpixels algorithm applications non-imagery geospatial rasters. International Journal Applied Earth Observations Geoinformation, 2022.Sigrid Keydana, Deep Learning Scientific Computing R torch, Chapman Hall/CRC, London, 2023.Sigrid Keydana, Deep Learning Scientific Computing R torch, Chapman Hall/CRC, London, 2023.Robin Lovelace, Jakub Nowosad, Jannes Münchow, Geocomputation R. Chapman Hall/CRC, London, 2023.Robin Lovelace, Jakub Nowosad, Jannes Münchow, Geocomputation R. Chapman Hall/CRC, London, 2023.Edzer Pebesma, Roger Bivand, Spatial Data Science: applications R. Chapman Hall/CRC, London, 2023.Edzer Pebesma, Roger Bivand, Spatial Data Science: applications R. Chapman Hall/CRC, London, 2023.","code":""},{"path":"acknowledgements.html","id":"publications-using-sits","chapter":"Acknowledgements","heading":"Publications using sits","text":"section gathers publications used sits generate results.2024Giuliani, Gregory. Time-First Approach Land Cover Mapping Using Big Earth Observation Data Time-Series Data Cube – Case Study Lake Geneva Region (Switzerland). Big Earth Data, 2024.Giuliani, Gregory. Time-First Approach Land Cover Mapping Using Big Earth Observation Data Time-Series Data Cube – Case Study Lake Geneva Region (Switzerland). Big Earth Data, 2024.Werner, João, Mariana Belgiu et al., Mapping Integrated Crop–Livestock Systems Using Fused Sentinel-2 PlanetScope Time Series Deep Learning. Remote Sensing 16, . 8 (January 2024): 1421.Werner, João, Mariana Belgiu et al., Mapping Integrated Crop–Livestock Systems Using Fused Sentinel-2 PlanetScope Time Series Deep Learning. Remote Sensing 16, . 8 (January 2024): 1421.2023Hadi, Firman, Laode Muhammad Sabri, Yudo Prasetyo, Bambang Sudarsono. Leveraging Time-Series Imageries Open Source Tools Enhanced Land Cover Classification. IOP Conference Series: Earth Environmental Science, 1276:012035. IOP Publishing, 2023.Hadi, Firman, Laode Muhammad Sabri, Yudo Prasetyo, Bambang Sudarsono. Leveraging Time-Series Imageries Open Source Tools Enhanced Land Cover Classification. IOP Conference Series: Earth Environmental Science, 1276:012035. IOP Publishing, 2023.Bruno Adorno, Thales Körting, Silvana Amaral, Contribution time-series data cubes classify urban vegetation types remote sensing. Urban Forest & Urban Greening, 79, 127817, 2023.Bruno Adorno, Thales Körting, Silvana Amaral, Contribution time-series data cubes classify urban vegetation types remote sensing. Urban Forest & Urban Greening, 79, 127817, 2023.2021Lorena Santos, Karine R. Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, Quality control class noise reduction satellite image time series. ISPRS Journal Photogrammetry Remote Sensing, 177, 75–88, 2021.Lorena Santos, Karine R. Ferreira, Gilberto Camara, Michelle Picoli, Rolf Simoes, Quality control class noise reduction satellite image time series. ISPRS Journal Photogrammetry Remote Sensing, 177, 75–88, 2021.Lorena Santos, Karine Ferreira, Michelle Picoli, Gilberto Camara, Raul Zurita-Milla Ellen-Wien Augustijn, Identifying Spatiotemporal Patterns Land Use Cover Samples Satellite Image Time Series. Remote Sensing, 13(5), 974, 2021.Lorena Santos, Karine Ferreira, Michelle Picoli, Gilberto Camara, Raul Zurita-Milla Ellen-Wien Augustijn, Identifying Spatiotemporal Patterns Land Use Cover Samples Satellite Image Time Series. Remote Sensing, 13(5), 974, 2021.2020Rolf Simoes, Michelle Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro Andrade, Alber Sánchez, Karine Ferreira, Alexandre Carvalho, Land use cover maps Mato Grosso State Brazil 2001 2017. Nature Scientific Data, 7, article 34, 2020.Rolf Simoes, Michelle Picoli, Gilberto Camara, Adeline Maciel, Lorena Santos, Pedro Andrade, Alber Sánchez, Karine Ferreira, Alexandre Carvalho, Land use cover maps Mato Grosso State Brazil 2001 2017. Nature Scientific Data, 7, article 34, 2020.Michelle Picoli, Ana Rorato, Pedro Leitão, Gilberto Camara, Adeline Maciel, Patrick Hostert, Ieda Sanches, Impacts Public Private Sector Policies Soybean Pasture Expansion Mato Grosso—Brazil 2001 2017. Land, 9(1), 2020.Michelle Picoli, Ana Rorato, Pedro Leitão, Gilberto Camara, Adeline Maciel, Patrick Hostert, Ieda Sanches, Impacts Public Private Sector Policies Soybean Pasture Expansion Mato Grosso—Brazil 2001 2017. Land, 9(1), 2020.Karine Ferreira, Gilberto Queiroz et al., Earth Observation Data Cubes Brazil: Requirements, Methodology Products. Remote Sensing, 12, 4033, 2020.Karine Ferreira, Gilberto Queiroz et al., Earth Observation Data Cubes Brazil: Requirements, Methodology Products. Remote Sensing, 12, 4033, 2020.Adeline Maciel, Lubia Vinhas, Michelle Picoli, Gilberto Camara, Identifying Land Use Change Trajectories Brazil’s Agricultural Frontier. Land, 9, 506, 2020.Adeline Maciel, Lubia Vinhas, Michelle Picoli, Gilberto Camara, Identifying Land Use Change Trajectories Brazil’s Agricultural Frontier. Land, 9, 506, 2020.2018Michelle Picoli, Gilberto Camara, et al., Big Earth Observation Time Series Analysis Monitoring Brazilian Agriculture. ISPRS Journal Photogrammetry Remote Sensing, 145, 328–339, 2018.","code":""},{"path":"acknowledgements.html","id":"ai-support-in-preparing-the-book","chapter":"Acknowledgements","heading":"AI support in preparing the book","text":"authors use Generative AI tools (Chat-GPT, Grammarly ProWritingAid) improve readability language work. core technical scientific content book prepared exclusively authors. Assistance Generative AI limited improving definitions making text easier follow.","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"","code":""},{"path":"introduction.html","id":"who-is-this-book-for","chapter":"Introduction","heading":"Who is this book for?","text":"book, tailored land use change experts researchers, practical guide enables analyze big Earth observation data sets. provides readers means producing high-quality maps land use land cover, guiding steps achieve good results. Given natural world’s complexity huge variations human-nature interactions, local experts know countries ecosystems can extract full information big EO data.One group readers keen engage national authorities forest, agriculture, statistics developing countries. aim foster collaborative environment can use EO data enhance national land use cover estimates, supporting sustainable development policies. achieve goal, sits strong backing FAO Expert Group Use Earth Observation data (FAO-EOSTAT)[https://www.fao.org/-action/eostat]. FAO-EOSTAT forefront using advanced EO data analysis methods agricultural statistics developing countries [[1]][2].","code":""},{"path":"introduction.html","id":"why-work-with-satellite-image-time-series","chapter":"Introduction","heading":"Why work with satellite image time series?","text":"Satellite imagery provides extensive data environment. encompassing vast areas Earth’s surface, images enable researchers analyze local worldwide transformations. observing location multiple times, satellites provide data environmental changes survey areas difficult observe ground. Given unique features, images offer essential information many applications, including deforestation, crop production, food security, urban footprints, water scarcity, land degradation. Using time series, experts improve understanding ecological patterns processes. Instead selecting individual images specific dates comparing , researchers track change continuously [3].","code":""},{"path":"introduction.html","id":"time-first-space-later","chapter":"Introduction","heading":"Time-first, space-later","text":"“Time-first, space-later” concept satellite image classification takes time series analysis first step analyzing remote sensing data, spatial information considered time series classified. time-first part brings better understanding changes landscapes. Detecting tracking seasonal long-term trends becomes feasible, well identifying anomalous events patterns data, wildfires, floods, droughts. pixel data cube treated time series, using information available temporal instances case. Time series classification pixel-based, producing set labeled pixels. result used input space-later part method. phase, smoothing algorithm improves results time-first classification considering spatial neighborhood pixel. resulting map thus combines spatial temporal information.","code":""},{"path":"introduction.html","id":"land-use-and-land-cover","chapter":"Introduction","heading":"Land use and land cover","text":"UN Food Agriculture Organization defines land cover “observed biophysical cover Earth’s surface” [4]. Land cover can observed mapped directly remote sensing images. FAO’s guidelines reports, land use described “human activities purposes land managed exploited”. Although land cover land use denote different approaches describing Earth’s landscape, practice considerable overlap concepts [5]. classifying remote sensing images, natural areas classified using land cover types (e.g, forest), human-modified areas described land use classes (e.g., pasture).One advantages using image time series land classification capacity measuring changes landscape related agricultural practices. example, time series vegetation index area crop production show pattern minima (planting sowing stages) maxima (flowering stage). Thus, classification schemas based image time series data can richer detailed associated land cover. follows, use term “land classification” refer image classification representing land cover land use classes.","code":""},{"path":"introduction.html","id":"how-sits-works","chapter":"Introduction","heading":"How sits works","text":"sits package uses satellite image time series land classification, using time-first, space-later approach. data preparation part, collections big Earth observation images organized data cubes. spatial location data cube associated time series. Locations known labels train machine learning algorithm, classifies time series data cube, shown Figure 1.\nFigure 1: Using time series land classification (source: authors).\npackage provides tools analysis, visualization, classification satellite image time series. Users follow typical workflow pixel-based classification:Select analysis-ready data image collection cloud provider AWS, Microsoft Planetary Computer, Digital Earth Africa, Brazil Data Cube.Build regular data cube using chosen image collection.Obtain new bands indices operations data cubes.Extract time series samples data cube used training data.Perform quality control filtering time series samples.Train machine learning model using time series samples.Classify data cube using model get class probabilities pixel.Post-process probability cube remove outliers.Produce labeled map post-processed probability cube.Evaluate accuracy classification using best practices.workflow step corresponds function sits API, shown Table Figure 2. functions convenient default parameters behaviors. single function builds machine learning (ML) models. classification function processes big data cubes efficient parallel processing. Since sits API simple learn, achieving good results require -depth knowledge machine learning parallel processing.\nTable 1: sits API workflow land classification.\n\nFigure 2: Main functions sits API (source: authors).\nAdditionally, experts can perform object-based image analysis (OBIA) sits. case, classifying time series, one can use sits_segments() create set closed polygons. polygons classified using subset time series contained inside segment. details, see Chapter Object-based time series image analysis.","code":""},{"path":"introduction.html","id":"creating-a-data-cube","chapter":"Introduction","heading":"Creating a data cube","text":"two kinds data cubes sits: () irregular data cubes generated selecting image collections cloud providers AWS Planetary Computer; (b) regular data cubes images fully covering chosen area, image spectral bands spatial resolution, images follow set adjacent regular time intervals. Machine learning applications need regular data cubes. Please refer Chapter Earth observation data cubes details.first steps using sits : () select analysis-ready data image collection available cloud provider stored locally using sits_cube(); (b) collection regular, use sits_regularize() build regular data cube.section shows build data cube local images already organized regular data cube. data cube composed MODIS MOD13Q1 images region close city Sinop Mato Grosso, Brazil. region one world’s largest producers soybeans. images indexes NDVI EVI covering one-year period 2013-09-14 2014-08-29 (use “year-month-day” dates). 23 time instances, covering 16-day period. data available package sitsdata.build data cube local files, users must provide information original source data obtained. case, sits_cube() needs parameters:source, cloud provider data obtained (case, Brazil Data Cube “BDC”);collection, collection cloud provider images extracted. case, data comes MOD13Q1 collection 6;data_dir, local directory image files stored;parse_info, vector strings stating file names store information “tile”, “band”, “date”. case, local images stored files whose names similar TERRA_MODIS_012010_EVI_2014-07-28.tif. file represents image obtained MODIS sensor onboard TERRA satellite, covering part tile 012010 EVI band date 2014-07-28.\nFigure 3: False color MODIS image NDVI band 2013-09-14 sinop data cube (source: Brazil Data Cube).\naim parse_info parameter extract tile, band, date information file name. Given large variation image file names generated different produces, includes designators X1 X2; place holders parts file name relevant sits_cube().R object returned sits_cube() contains metadata describing contents data cube. includes data source collection, satellite, sensor, tile collection, bounding box, projection, list files. file refers one band image one temporal instances cube.list image files make data cube stored data frame column file_info. file, sits stores information spectral band, reference date, size, spatial resolution, coordinate reference system, bounding box, path file location cloud cover information (available).key attribute data cube timeline, shown . command sits_timeline() lists temporal references associated sits objects, including samples, data cubes models.timeline sinop_cube data cube 23 intervals temporal difference 16 days. chosen dates capture agricultural calendar Mato Grosso, Brazil. agricultural year starts September-October sowing summer crop (usually soybeans) harvested February-March. winter crop (mostly Corn, Cotton Millet) planted March harvested June-July. LULC classification, training samples date cube share timeline number intervals similar start end dates.","code":"\n# load package \"tibble\"\nlibrary(tibble)\n# load packages \"sits\" and \"sitsdata\"\nlibrary(sits)\nlibrary(sitsdata)\n# Create a data cube using local files\nsinop_cube <- sits_cube(\n  source = \"BDC\",\n  collection = \"MOD13Q1-6.1\",\n  bands = c(\"NDVI\", \"EVI\"),\n  data_dir = system.file(\"extdata/sinop\", package = \"sitsdata\"),\n  parse_info = c(\"satellite\", \"sensor\", \"tile\", \"band\", \"date\")\n)\n# Plot the NDVI for the first date (2013-09-14)\nplot(sinop_cube,\n  band = \"NDVI\",\n  dates = \"2013-09-14\",\n  palette = \"RdYlGn\"\n)\n# Show the description of the data cube\nsinop_cube#> # A tibble: 1 × 11\n#>   source collection satellite sensor tile     xmin    xmax    ymin    ymax crs  \n#>   <chr>  <chr>      <chr>     <chr>  <chr>   <dbl>   <dbl>   <dbl>   <dbl> <chr>\n#> 1 BDC    MOD13Q1-6… TERRA     MODIS  0120… -6.18e6 -5.96e6 -1.35e6 -1.23e6 \"PRO…\n#> # ℹ 1 more variable: file_info <list>\n# Show information on the images files which are part of a data cube\nsinop_cube$file_info[[1]]#> # A tibble: 46 × 13\n#>    fid   band  date       nrows ncols  xres  yres      xmin      ymin      xmax\n#>    <chr> <chr> <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>     <dbl>     <dbl>\n#>  1 1     EVI   2013-09-14   551   944  232.  232. -6181982. -1353336. -5963298.\n#>  2 1     NDVI  2013-09-14   551   944  232.  232. -6181982. -1353336. -5963298.\n#>  3 2     EVI   2013-09-30   551   944  232.  232. -6181982. -1353336. -5963298.\n#>  4 2     NDVI  2013-09-30   551   944  232.  232. -6181982. -1353336. -5963298.\n#>  5 3     EVI   2013-10-16   551   944  232.  232. -6181982. -1353336. -5963298.\n#>  6 3     NDVI  2013-10-16   551   944  232.  232. -6181982. -1353336. -5963298.\n#>  7 4     EVI   2013-11-01   551   944  232.  232. -6181982. -1353336. -5963298.\n#>  8 4     NDVI  2013-11-01   551   944  232.  232. -6181982. -1353336. -5963298.\n#>  9 5     EVI   2013-11-17   551   944  232.  232. -6181982. -1353336. -5963298.\n#> 10 5     NDVI  2013-11-17   551   944  232.  232. -6181982. -1353336. -5963298.\n#> # ℹ 36 more rows\n#> # ℹ 3 more variables: ymax <dbl>, crs <chr>, path <chr>\n# Show the R object that describes the data cube\nsits_timeline(sinop_cube)#>  [1] \"2013-09-14\" \"2013-09-30\" \"2013-10-16\" \"2013-11-01\" \"2013-11-17\"\n#>  [6] \"2013-12-03\" \"2013-12-19\" \"2014-01-01\" \"2014-01-17\" \"2014-02-02\"\n#> [11] \"2014-02-18\" \"2014-03-06\" \"2014-03-22\" \"2014-04-07\" \"2014-04-23\"\n#> [16] \"2014-05-09\" \"2014-05-25\" \"2014-06-10\" \"2014-06-26\" \"2014-07-12\"\n#> [21] \"2014-07-28\" \"2014-08-13\" \"2014-08-29\""},{"path":"introduction.html","id":"the-time-series-tibble","chapter":"Introduction","heading":"The time series tibble","text":"handle time series information, sits uses tibble. Tibbles extensions data.frame tabular data structures provided tidyverse set packages. example shows tibble 1,837 time series obtained MODIS MOD13Q1 images. series four attributes: two bands (NIR MIR) two indexes (NDVI EVI). dataset available package sitsdata.time series tibble contains data metadata. first six columns contain metadata: spatial temporal information, label assigned sample, data cube data extracted. time_series column contains time series data spatiotemporal location. data also organized tibble, column dates columns values spectral band.timeline time series associated samples follows agricultural calendar, starting September 14th ending August 28th. samples contain 23 values, corresponding temporal interval sinop data cube. Notice although years samples different, samples given year follow agricultural calendar.time series can displayed showing time_series column.distribution samples per class can obtained using summary() command. classification schema uses nine labels, four associated crops (Soy_Corn, Soy_Cotton, Soy_Fallow, Soy_Millet), two natural vegetation (Cerrado, Forest) one Pasture.helpful plot dispersion time series. follows, brevity, filter one label (Forest) select one index (NDVI). Note filtering label use function dplyr package, selecting index use sits_select(). use two different functions selection way metadata stored samples files. labels samples listed column label samples tibble, shown . case, one can use functions dplyr package extract subsets. particular, function dplyr::filter retaining rows satisfy given condition. example, result dplyr::filter set samples associated “Forest” label. second selection involves obtaining values NDVI band. operation requires access time_series column, stored list. case, selection dplyr::filter work. handle cases, sits provides sits_select() select subsets inside time_series list.\nFigure 4: Joint plot samples band NDVI label Forest (source: authors).\nfigure shows time series associated label Forest band NDVI (light blue), highlighting median (shown dark red) first third quartiles (shown brown). spikes noise caused presence clouds.","code":"\n# Load the MODIS samples for Mato Grosso from the \"sitsdata\" package\nlibrary(tibble)\nlibrary(sitsdata)\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\nsamples_matogrosso_mod13q1#> # A tibble: 1,837 × 7\n#>    longitude latitude start_date end_date   label   cube     time_series      \n#>        <dbl>    <dbl> <date>     <date>     <chr>   <chr>    <list>           \n#>  1     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#>  2     -59.4    -9.31 2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#>  3     -59.4    -9.31 2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#>  4     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#>  5     -55.2   -10.8  2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#>  6     -51.9   -13.4  2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#>  7     -56.0   -10.1  2005-09-14 2006-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#>  8     -54.6   -10.4  2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#>  9     -52.5   -11.0  2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 10     -52.1   -14.0  2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> # ℹ 1,827 more rows\n# Load the time series for MODIS samples for Mato Grosso\nsamples_matogrosso_mod13q1[1, ]$time_series[[1]]#> # A tibble: 23 × 5\n#>    Index       NDVI   EVI   NIR    MIR\n#>    <date>     <dbl> <dbl> <dbl>  <dbl>\n#>  1 2006-09-14 0.500 0.263 0.230 0.139 \n#>  2 2006-09-30 0.485 0.330 0.359 0.161 \n#>  3 2006-10-16 0.716 0.397 0.264 0.0757\n#>  4 2006-11-01 0.654 0.415 0.332 0.124 \n#>  5 2006-11-17 0.591 0.433 0.400 0.172 \n#>  6 2006-12-03 0.662 0.439 0.348 0.125 \n#>  7 2006-12-19 0.734 0.444 0.295 0.0784\n#>  8 2007-01-01 0.739 0.502 0.348 0.0887\n#>  9 2007-01-17 0.768 0.526 0.351 0.0761\n#> 10 2007-02-02 0.797 0.550 0.355 0.0634\n#> # ℹ 13 more rows\n# Load the MODIS samples for Mato Grosso from the \"sitsdata\" package\nsummary(samples_matogrosso_mod13q1)#> # A tibble: 7 × 3\n#>   label      count   prop\n#>   <chr>      <int>  <dbl>\n#> 1 Cerrado      379 0.206 \n#> 2 Forest       131 0.0713\n#> 3 Pasture      344 0.187 \n#> 4 Soy_Corn     364 0.198 \n#> 5 Soy_Cotton   352 0.192 \n#> 6 Soy_Fallow    87 0.0474\n#> 7 Soy_Millet   180 0.0980\n# select all samples with label \"Forest\"\nsamples_forest <- dplyr::filter(\n  samples_matogrosso_mod13q1,\n  label == \"Forest\"\n)\n# select the NDVI band for all samples with label \"Forest\"\nsamples_forest_ndvi <- sits_select(\n  samples_forest,\n  band = \"NDVI\"\n)\nplot(samples_forest_ndvi)"},{"path":"introduction.html","id":"training-a-machine-learning-model","chapter":"Introduction","heading":"Training a machine learning model","text":"next step train machine learning (ML) model using sits_train(). takes two inputs, samples (time series tibble) ml_method (function implements machine learning algorithm). result model used classification. ML algorithm requires specific parameters user-controllable. novice users, sits provides default parameters produce good results. Please see Chapter Machine learning data cubes details.Since time series data four attributes (EVI, NDVI, NIR, MIR) data cube images two, select NDVI EVI values use resulting data training. build classification model, use random forest model called sits_rfor(). Results random forest model can vary different runs, due stochastic nature algorithm, reason, code fragment , set seed R’s pseudo-random number generation explicitly ensure results produced documentation purposes.\nFigure 5: relevant variables trained random forest model (source: authors).\n","code":"\nset.seed(03022024)\n# Select the bands NDVI and EVI\nsamples_2bands <- sits_select(\n  data = samples_matogrosso_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n# Train a random forest model\nrf_model <- sits_train(\n  samples = samples_2bands,\n  ml_method = sits_rfor()\n)\n# Plot the most important variables of the model\nplot(rf_model)"},{"path":"introduction.html","id":"data-cube-classification","chapter":"Introduction","heading":"Data cube classification","text":"training machine learning model, next step classify data cube using sits_classify(). function produces set raster probability maps, one class. maps, value pixel proportional probability belongs class. function two mandatory parameters: data, data cube time series tibble classified; ml_model, trained ML model. Optional parameters include: () multicores, number cores used; (b) memsize, RAM used classification; (c) output_dir, directory classified raster files written. Details classification process available “Image classification data cubes”.\nFigure 6: Probability map class Forest (source: authors).\ncompleting classification, plot probability maps class Forest. Probability maps helpful visualize degree confidence classifier assigns labels pixel. can used produce uncertainty information support active learning, described Chapter Image classification data cubes.","code":"\n# Classify the raster image\nsinop_probs <- sits_classify(\n  data = sinop_cube,\n  ml_model = rf_model,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp3\"\n)\n# Plot the probability cube for class Forest\nplot(sinop_probs, labels = \"Forest\", palette = \"BuGn\")"},{"path":"introduction.html","id":"spatial-smoothing","chapter":"Introduction","heading":"Spatial smoothing","text":"working big Earth observation data, much variability class. result, pixels misclassified. errors likely occur transition areas classes. address problems, sits_smooth() takes probability cube input uses class probabilities pixel’s neighborhood reduce labeling uncertainty. Plotting smoothed probability map class Forest shows outliers removed.\nFigure 7: Smoothed probability map class Forest (source: authors).\n","code":"\n# Perform spatial smoothing\nsinop_bayes <- sits_smooth(\n  cube = sinop_probs,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp3\"\n)\nplot(sinop_bayes, labels = \"Forest\", palette = \"BuGn\")"},{"path":"introduction.html","id":"labeling-a-probability-data-cube","chapter":"Introduction","heading":"Labeling a probability data cube","text":"removing outliers using local smoothing, final classification map can obtained using sits_label_classification(). function assigns pixel class highest probability.\nFigure 8: Classification map Sinop (source: authors).\nresulting classification files can read QGIS. Links associated files available sinop_map object nested table file_info.","code":"\n# Label the probability file\nsinop_map <- sits_label_classification(\n  cube = sinop_bayes,\n  output_dir = \"./tempdir/chp3\"\n)\nplot(sinop_map)\n# Show the location of the classification file\nsinop_map$file_info[[1]]#> # A tibble: 1 × 12\n#>   band  start_date end_date   ncols nrows  xres  yres      xmin     xmax    ymin\n#>   <chr> <date>     <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>    <dbl>   <dbl>\n#> 1 class 2013-09-14 2014-08-29   944   551  232.  232. -6181982.  -5.96e6 -1.35e6\n#> # ℹ 2 more variables: ymax <dbl>, path <chr>"},{"path":"earth-observation-data-cubes.html","id":"earth-observation-data-cubes","chapter":"Earth observation data cubes","heading":"Earth observation data cubes","text":"","code":""},{"path":"earth-observation-data-cubes.html","id":"analysis-ready-dataard","chapter":"Earth observation data cubes","heading":"Analysis-ready data(ARD)","text":"Analysis Ready Data (CEOS-ARD) satellite data processed meet ARD standards defined Committee Earth Observation Satellites (CEOS). ARD data simplify accelerate analysis Earth observation data providing consistent high-quality data standardized across different sensors platforms.ARD images processing includes geometric corrections, radiometric corrections, sometimes atmospheric corrections. Images georeferenced, meaning accurately aligned coordinate system. Optical ARD images include cloud shadow masking information. masks indicate pixels affected clouds cloud shadows. optical sensors, CEOS-ARD images converted surface reflectance values, represent fraction light reflected surface. makes data comparable across different times locations.SAR images, CEOS-ARD specification require images undergo Radiometric Terrain Correction (RTC) provided GammaNought (\\(\\gamma_0\\)) backscatter values. value mitigates variations diverse observation geometries recommended land applications.ARD images available various satellite platforms, including Landsat, Sentinel, commercial satellites. provides wide range spatial, spectral, temporal resolutions suit different applications. organised collection files, pixel contains single value spectral band given date. collections available cloud services Brazil Data Cube, Digital Earth Africa, Microsoft’s Planetary Computer. general, timelines images ARD collection different. Images still contain cloudy missing pixels; bands images collection may different resolutions. Figure 9 shows example Landsat ARD image collection.\nFigure 9: ARD image collection (source: USGS. Reproduction based fair use doctrine).\nARD image collections organized spatial partitions. Sentinel-2/2A images follow Military Grid Reference System (MGRS) tiling system, divides world 60 UTM zones 8 degrees longitude. zone blocks 6 degrees latitude. Blocks split tiles 110 \\(\\times\\) 110 km\\(^2\\) 10 km overlap. Figure 10 shows MGRS tiling system part Northeastern coast Brazil, contained UTM zone 24, block M.\nFigure 10: MGRS tiling system used Sentinel-2 images (source: US Army. Reproduction based fair use doctrine).\nLandsat-4/5/7/8/9 satellites use Worldwide Reference System (WRS-2), breaks coverage Landsat satellites images identified path row (see Figure 11). path descending orbit satellite; WRS-2 system 233 paths per orbit, path 119 rows, row refers latitudinal center line frame imagery. Images WRS-2 geometrically corrected UTM projection.\nFigure 11: WRS-2 tiling system used Landsat-5/7/8/9 images (source: INPE ESRI. Reproduction based fair use doctrine).\n","code":""},{"path":"earth-observation-data-cubes.html","id":"image-collections-handled-by-sits","chapter":"Earth observation data cubes","heading":"Image collections handled by sits","text":"version 1.5.1,sits supports access following ARD image cloud providers:Amazon Web Services (AWS): Open data Sentinel-2/2A level 2A collections Earth’s land surface.Brazil Data Cube (BDC): Open data collections Sentinel-2/2A, Landsat-8, CBERS-4/4A, MOD13Q1 products Brazil. collections organized regular data cubes.Copernicus Data Space Ecosystem (CDSE): Open data collections Sentinel-1 RTC Sentinel-2/2A images.Digital Earth Africa (DEAFRICA): Open data collections Sentinel-1 RTC, Sentinel-2/2A, Landsat-5/7/8/9 Africa. Additional products available include ALOS_PALSAR mosaics, DEM_COP_30, NDVI_ANOMALY based Landsat data, monthly daily rainfall data CHIRPS.Digital Earth Australia (DEAUSTRALIA): Open data ARD collections Sentinel-2A/2B Landsat-5/7/8/9 images; yearly geomedian Landsat 5/7/8 images; yearly fractional land cover 1986 2024.Harmonized Landsat-Sentinel (HLS): HLS, provided NASA, open data collection processes Landsat 8 Sentinel-2 imagery common standard.Microsoft Planetary Computer (MPC): Open data collections Sentinel-1 GRD, Sentinel-2/2A, Landsat-4/5/7/8/9 images Earth’s land areas. Also supported Copernicus DEM-30 MOD13Q1, MOD10A1 MOD09A1 products. Sentinel-1 RTC collections accessible require payment.Swiss Data Cube (SDC): Open data collection Sentinel-2/2A Landsat-8 images Switzerland.Terrascope: Cloud service EO products includes ESA World Cover map.USGS: Landsat-4/5/7/8/9 collections available AWS, require access payment.addition, sits supports use Planet monthly mosaics stored local files. detailed description providers collections supported sits, please run sits_list_collections().","code":""},{"path":"earth-observation-data-cubes.html","id":"regular-image-data-cubes","chapter":"Earth observation data cubes","heading":"Regular image data cubes","text":"Machine learning deep learning (ML/DL) classification algorithms require input data consistent. dimensionality data used training model data classified. gaps missing values. Thus, use ML/DL algorithms remote sensing data, ARD image collections converted regular data cubes. Adapting previous definition Appel Pebesma [6], consider regular data cube following definition properties:regular data cube four-dimensional data structure dimensions x (longitude easting), y (latitude northing), time, bands. spatial, temporal, attribute dimensions independent interchangeable.spatial dimensions refer coordinate system, grids defined UTM (Universal Transverse Mercator) MGRS (Military Grid Reference System). grid (tile) grid corresponds unique zone coordinate system. data cube may span various tiles UTM zones.temporal dimension set continuous equally-spaced intervals.every combination dimensions, cell single value.cells data cube spatiotemporal extent. spatial resolution cell X Y dimensions. temporal intervals . cell contains valid set measures. pixel associated unique coordinate zone coordinate system. position space, data cube provide set valid time series. time interval, regular data cube provide valid 2D image (see Figure 12).\nFigure 12: Conceptual view data cubes (source: authors).\nCurrently, cloud service provides regular data cubes default Brazil Data Cube (BDC). ARD collections available cloud services regular space time. Bands may different resolutions, images may cover entire time, time intervals may irregular. reason, subsets collections need converted regular data cubes processing. produce data cubes machine-learning data analysis, users first create irregular data cube ARD collection use sits_regularize(), described .","code":""},{"path":"earth-observation-data-cubes.html","id":"creating-data-cubes","chapter":"Earth observation data cubes","heading":"Creating data cubes","text":"obtain information ARD image collection cloud providers, sits uses SpatioTemporal Asset Catalogue (STAC) protocol, specification geospatial information many large image collection providers adopted. ‘spatiotemporal asset’ file represents information Earth captured specific space time. access STAC endpoints, sits uses rstac R package.function sits_cube() supports access image collections cloud services; following parameters:source: Name provider.collection: collection available provider supported sits. find collections supported sits, see sits_list_collections().platform: Optional parameter specifying platform collections multiple satellites.tiles: Set tiles image collection reference system. Either tiles roi specified.roi: region interest. Either: () named vector (lon_min, lon_max, lat_min, lat_max) WGS 84 coordinates; (b) sf object. images intersecting convex hull roi selected.bands: Optional parameter bands used. missing, bands collection used.orbit: Optional parameter required Sentinel-1 images (default = “descending”).start_date: initial date temporal interval containing time series images.end_date: final date temporal interval containing time series images.result sits_cube() tibble description selected images required processing. contain actual data, pointers images. attributes individual image files can assessed listing file_info column tibble.","code":""},{"path":"earth-observation-data-cubes.html","id":"amazon-web-services","chapter":"Earth observation data cubes","heading":"Amazon Web Services","text":"Amazon Web Services (AWS) holds two kinds collections: open-data requester-pays. Open data collections can accessed without cost. Requester-pays collections require payment AWS account. Currently, sits supports collection SENTINEL-2-L2A open data. bands 10 m resolution B02, B03, B04, B08. 20 m bands B05, B06, B07, B8A, B11, B12. Bands B01 B09 available 60 m resolution. CLOUD band also available. example shows access one tile open data SENTINEL-2-L2A collection. tiles parameter allows selecting desired area according MGRS reference system.\nFigure 13: Sentinel-2 image area Northeastern coast Brazil (© EU Copernicus Sentinel Programme; source: AWS).\n","code":"\n# Create a data cube covering an area in Brazil\ns2_23MMU_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = \"23MMU\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2018-07-12\",\n  end_date = \"2019-07-28\"\n)\nplot(s2_23MMU_cube,\n  red = \"B11\",\n  blue = \"B02\",\n  green = \"B8A\",\n  date = \"2018-10-05\"\n)"},{"path":"earth-observation-data-cubes.html","id":"microsoft-planetary-computer","chapter":"Earth observation data cubes","heading":"Microsoft Planetary Computer","text":"sits supports access three open data collection Microsoft’s Planetary Computer (MPC): SENTINEL-1-GRD, SENTINEL-2-L2A, LANDSAT-C2-L2. also allows access COP-DEM-GLO-30 (Copernicus Global DEM 30 meter resolution) MOD13Q1-6.1(version 6.1 MODIS MOD13Q1 product). Access non-open data collection SENTINEL-1-RTC available users registration MPC.","code":""},{"path":"earth-observation-data-cubes.html","id":"sentinel-22a-images-in-mpc","chapter":"Earth observation data cubes","heading":"SENTINEL-2/2A images in MPC","text":"SENTINEL-2/2A ARD images available MPC bands resolutions available AWS (see ). example shows access SENTINEL-2-L2A collection.\nFigure 14: Sentinel-2 image area state Rondonia, Brazil (© EU Copernicus Sentinel Programme; source: Microsoft).\n","code":"\n# Create a data cube covering an area in the Brazilian Amazon\ns2_20LKP_cube_MPC <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = \"20LKP\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = \"2019-07-01\",\n  end_date = \"2019-07-28\"\n)\n# Plot a color composite of one date of the cube\nplot(s2_20LKP_cube_MPC,\n  red = \"B11\", blue = \"B02\", green = \"B8A\",\n  date = \"2019-07-18\"\n)"},{"path":"earth-observation-data-cubes.html","id":"landsat-c2-l2-images-in-mpc","chapter":"Earth observation data cubes","heading":"LANDSAT-C2-L2 images in MPC","text":"LANDSAT-C2-L2 collection provides access data Landsat-4/5/7/8/9 satellites. Images satellites intercalibrated ensure data consistency. compatibility different Landsat sensors, band names BLUE, GREEN, RED, NIR08, SWIR16, SWIR22. images 30 m resolution. collection, tile search supported; roi parameter used. example shows retrieve data region interest covering city Brasilia Brazil.\nFigure 15: Landsat-8 image area Northeast Brazil (sources: USGS Microsoft).\n","code":"\n# Read a ROI that covers part of the Northeastern coast of Brazil\nroi <- c(\n  lon_min = -43.5526, lat_min = -2.9644,\n  lon_max = -42.5124, lat_max = -2.1671\n)\n# Select the cube\ns2_L8_cube_MPC <- sits_cube(\n  source = \"MPC\",\n  collection = \"LANDSAT-C2-L2\",\n  bands = c(\"BLUE\", \"RED\", \"GREEN\", \"NIR08\", \"SWIR16\", \"CLOUD\"),\n  roi = roi,\n  start_date = \"2019-06-01\",\n  end_date = \"2019-09-01\"\n)\n# Plot the tile that covers the Lencois Maranhenses\nplot(s2_L8_cube_MPC,\n  red = \"RED\", green = \"GREEN\", blue = \"BLUE\",\n  date = \"2019-06-30\"\n)"},{"path":"earth-observation-data-cubes.html","id":"sentinel-1-grd-images-in-mpc","chapter":"Earth observation data cubes","heading":"SENTINEL-1-GRD images in MPC","text":"Sentinel-1 GRD products consist focused SAR data detected, multi-looked projected ground range using WGS84 Earth ellipsoid model. GRD images subject variations radar signal’s intensity due topographic effects, antenna pattern, range spreading loss, radiometric distortions. common types distortions include foreshortening, layover shadowing.Foreshortening occurs radar signal strikes steep terrain slope facing radar, causing slope appear compressed image. Features like mountains can appear much steeper , true heights can difficult interpret. Layover happens radar signal reaches top tall feature (like mountain building) reaches base. result, top feature displaced towards radar appears front base. results reversal order features along radar line--sight, making image interpretation challenging. Shadowing occurs radar signal obstructed tall object, casting shadow area behind radar illuminate. shadowed areas appear dark SAR images, information available regions, similar optical shadows.Access Sentinel-1 GRD images can done either MGRS tiles (tiles) region interest (roi). recommend using MGRS tiling system specifying area interest, since images regularized, re-projected MGRS tiles. default, images descending orbit selected.following example shows create data cube S1 GRD images region Mato Grosso Brazil area Amazon forest deforested. resulting cube follow specific projection coordinates stated EPSG 4326 (latitude/longitude). geometry derived SAR slant-range perspective; thus, appear included relation Earth’s longitude.\nFigure 16: Sentinel-1 image area Mato Grosso, Brazil (© EU Copernicus Sentinel Programme; source: Microsoft).\nexplained earlier chapter, areas areas large elevation differences, Sentinel-1 GRD images geometric distortions. reason, whenever possible, recommend use RTC (radiometrically terrain corrected) images described next session.","code":"\ncube_s1_grd <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-1-GRD\",\n  bands = c(\"VV\"),\n  orbit = \"descending\",\n  tiles = c(\"21LUJ\", \"21LVJ\"),\n  start_date = \"2021-08-01\",\n  end_date = \"2021-09-30\"\n)\nplot(cube_s1_grd, band = \"VV\", palette = \"Greys\")"},{"path":"earth-observation-data-cubes.html","id":"sentinel-1-rtc-images-in-mpc","chapter":"Earth observation data cubes","heading":"SENTINEL-1-RTC images in MPC","text":"RTC SAR image undergone corrections geometric distortions radiometric distortions caused terrain. purpose RTC processing enhance interpretability usability SAR images various applications providing accurate representation Earth’s surface. radar backscatter values normalized account variations, ensuring image accurately represents reflectivity surface features.terrain correction addresses geometric distortions caused side-looking geometry SAR imaging, foreshortening, layover, shadowing. uses Digital Elevation Model (DEM) model terrain re-project SAR image slant range (radar line--sight) ground range (true geographic coordinates). process aligns SAR image actual topography, providing accurate spatial representation.MPC, access Sentinel-1-RTC images requires Planetary Computer account. User receive Shared Access Signature (SAS) Token MPC allows access RTC data. user receives token Microsoft, needs include environment variable MPC_TOKEN .Rprofile. Therefore, following example works users SAS token.\nFigure 17: Sentinel-1-RTC image area Colombia (© EU Copernicus Sentinel Programme; source: Microsoft).\nimage central region Colombia, country large variations altitude due Andes mountains. Users invited compare images one SENTINEL-1-GRD collection see significant geometrical distortions GRD image compared RTC one.","code":"\ncube_s1_rtc <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-1-RTC\",\n  bands = c(\"VV\", \"VH\"),\n  orbit = \"descending\",\n  tiles = \"18NZM\",\n  start_date = \"2021-08-01\",\n  end_date = \"2021-09-30\"\n)\nplot(cube_s1_rtc, band = \"VV\", palette = \"Greys\")"},{"path":"earth-observation-data-cubes.html","id":"copernicus-dem-30-meter-images-in-mpc","chapter":"Earth observation data cubes","heading":"Copernicus DEM 30 meter images in MPC","text":"Copernicus digital elevation model 30-meter global dataset (COP-DEM-GLO-30) high-resolution topographic data product provided European Space Agency (ESA) Copernicus Program. vertical accuracy Copernicus DEM 30-meter dataset typically within meters, can vary depending region original data sources. primary data source Copernicus DEM data TanDEM-X mission, designed German Aerospace Center (DLR). TanDEM-X provides high-resolution radar data interferometric synthetic aperture radar (InSAR) techniques.Copernicus DEM 30 meter organized 1\\(^\\circ\\) 1\\(^\\circ\\) grid. sits, access COP-DEM-GLO-30 images can done either MGRS tiles (tiles) region interest (roi). case, cube retrieved based parts grid intersect region interest chosen tiles.\nFigure 18: Copernicus 30-meter DEM area Brazil (© DLR e.V. 2010-2014 &copy Airbus Defence Space GmbH 2014-2018 provided COPERNICUS European Union ESA; source: Microsoft).\n","code":"\ncube_dem_30 <- sits_cube(\n  source = \"MPC\",\n  collection = \"COP-DEM-GLO-30\",\n  tiles = \"20LMR\",\n  band = \"ELEVATION\"\n)\nplot(cube_dem_30, band = \"ELEVATION\", palette = \"RdYlGn\", rev = TRUE)"},{"path":"earth-observation-data-cubes.html","id":"brazil-data-cube","chapter":"Earth observation data cubes","heading":"Brazil Data Cube","text":"Brazil Data Cube (BDC) built Brazil’s National Institute Space Research (INPE), provide regular EO data cubes CBERS, LANDSAT, SENTINEL-2, TERRA/MODIS satellites environmental applications. collections available BDC : LANDSAT-OLI-16D (Landsat-8 OLI, 30 m resolution, 16-day intervals), SENTINEL-2-16D (Sentinel-2A 2B MSI images 10 m resolution, 16-day intervals), CBERS-WFI-16D (CBERS 4 WFI, 64 m resolution, 16-day intervals), CBERS-WFI-8D(CBERS 4 4A WFI images, 64m resolution, 8-day intervals), MOD13Q1-6.1 (MODIS MOD13SQ1 product, collection 6, 250 m resolution, 16-day intervals). details, use sits_list_collections(source = \"BDC\").BDC uses three hierarchical grids based Albers Equal Area projection SIRGAS 2000 datum. large grid tiles 4224.4 \\(\\times4\\) 224.4 km2 used CBERS-4 AWFI collections 64 m resolution; CBERS-4 AWFI tile contains images 6600 \\(\\times\\) 6600 pixels. medium grid used Landsat-8 OLI collections 30 m resolution; tiles extension 211.2 \\(\\times\\) 211.2 km2, image 7040 \\(\\times\\) 7040 pixels. small grid covers 105.6 \\(\\times\\) 105.6 km2 used Sentinel-2 MSI collections 10 m resolutions; image 10560 \\(\\times\\) 10560 pixels. data cubes BDC regularly spaced time cloud-corrected [7].\nFigure 19: Hierarchical BDC tiling system showing () large BDC grid overlayed Brazilian biomes, (b) one large tile, (c) four medium tiles, (d) sixteen small tiles (Source: Ferreira et al. (2020). Reproduction fair use doctrine).\naccess BDC, users must provide credentials using environment variables, shown . Obtaining BDC access key free. Users must register BDC site obtain key. example , data cube defined one tile (“005004”) CBERS-WFI-16D collection, holds CBERS AWFI images 16 days resolution.\nFigure 20: CBERS-4 WFI image Cerrado area Brazil (© INPE/Brazil licensed CC--SA. source: Brazil Data Cube).\n","code":"\n# Define a tile from the CBERS-4/4A AWFI collection\ncbers_tile <- sits_cube(\n  source = \"BDC\",\n  collection = \"CBERS-WFI-16D\",\n  tiles = \"005004\",\n  bands = c(\"B13\", \"B14\", \"B15\", \"B16\", \"CLOUD\"),\n  start_date = \"2021-05-01\",\n  end_date = \"2021-09-01\"\n)\n# Plot one time instance\nplot(cbers_tile,\n  red = \"B15\",\n  green = \"B16\",\n  blue = \"B13\",\n  date = \"2021-05-09\"\n)"},{"path":"earth-observation-data-cubes.html","id":"copernicus-data-space-ecosystem-cdse","chapter":"Earth observation data cubes","heading":"Copernicus Data Space Ecosystem (CDSE)","text":"Copernicus Data Space Ecosystem (CDSE) cloud service designed support access Earth observation data Copernicus Sentinel missions sources. designed maintained European Space Agency (ESA) support European Commission.Configuring user access CDSE involves several steps ensure proper registration, access data, utilization platform’s tools services. Visit Copernicus Data Space Ecosystem registration page. Complete registration form details, including name, email address, organization, sector. Confirm email address verification link sent inbox.registration, need obtain access credentials S3 service implemented CDSE, can obtained using CSDE S3 credentials site. site request add new credential. receive two keys: S3 access key secret access key. Take note include following lines .Rprofile.including lines .Rprofile, restart R changes take effect. following steps, users access Copernicus Data Space Ecosystem.","code":"Sys.setenv(\n    AWS_ACCESS_KEY_ID = \"your access key\",\n    AWS_SECRET_ACCESS_KEY = \"your secret access key\"\n      AWS_S3_ENDPOINT = \"eodata.dataspace.copernicus.eu\",\n      AWS_VIRTUAL_HOSTING = \"FALSE\"\n)"},{"path":"earth-observation-data-cubes.html","id":"sentinel-22a-images-in-cdse","chapter":"Earth observation data cubes","heading":"SENTINEL-2/2A images in CDSE","text":"CDSE hosts global collection Sentinel-2 Level-2A images, processed according CEOS Analysis-Ready Data specifications. One example provided , present Sentinel-2 image Lena river delta Siberia summertime.\nFigure 21: Sentinel-2 image Lena river delta summertime (© EU Copernicus Sentinel Programme; source: CDSE).\n","code":"\n# obtain a collection of images of a tile covering part of Lena delta\nlena_cube <- sits_cube(\n  source = \"CDSE\",\n  collection = \"SENTINEL-2-L2A\",\n  bands = c(\"B02\", \"B04\", \"B8A\", \"B11\", \"B12\"),\n  start_date = \"2023-05-01\",\n  end_date = \"2023-09-01\",\n  tiles = c(\"52XDF\")\n)\n# plot an image from summertime\nplot(lena_cube, date = \"2023-07-06\", red = \"B12\", green = \"B8A\", blue = \"B04\")"},{"path":"earth-observation-data-cubes.html","id":"sentinel-1-rtc-images-in-cdse","chapter":"Earth observation data cubes","heading":"SENTINEL-1-RTC images in CDSE","text":"important product development CDSE radiometric terrain corrected (RTC) Sentinel-1 images. CDSE, product referred normalized terrain backscater (NRB). S1-NRB product contains radiometrically terrain corrected (RTC) gamma nought backscatter (γ0) processed Single Look Complex (SLC) Level-1A data. acquired polarization stored individual binary image file.images projected gridded United States Military Grid Reference System (US-MGRS). use US-MGRS tile grid ensures high level interoperability Sentinel-2 Level-2A ARD products making easy also set-complex analysis systems exploit SAR optical data. speckle inherent SAR acquisitions, speckle filtering applied S1-NRB product order preserve spatial resolution. applications (processing methods) may require spatial temporal filtering stationary backscatter estimates.details, please refer S1-NRB product website. July 2024, RTC images available Africa. Global coverage expected grow ESA expands S1-RTC archive. following example shows S1-RTC image Rift valley Ethiopia.\nFigure 22: Sentinel-1-RTC image Rift Valley Ethiopia (© EU Copernicus Sentinel Programme; source: CDSE).\n","code":"\n# retrieve a S1-RTC cube and plot\ns1_cube <- sits_cube(\n  source = \"CDSE\",\n  collection = \"SENTINEL-1-RTC\",\n  bands = c(\"VV\", \"VH\"),\n  orbit = \"descending\",\n  start_date = \"2023-01-01\",\n  end_date = \"2023-12-31\",\n  tiles = c(\"37NCH\")\n)\nplot(s1_cube, band = \"VV\", date = c(\"2023-03-03\"), palette = \"Greys\")"},{"path":"earth-observation-data-cubes.html","id":"digital-earth-africa","chapter":"Earth observation data cubes","heading":"Digital Earth Africa","text":"Digital Earth Africa (DEAFRICA) cloud service provides open-access Earth observation data African continent. ARD image collections sits :Sentinel-2 level 2A (SENTINEL-2-L2A), organised MGRS tiles.Sentinel-1 radiometrically terrain corrected (SENTINEL-1-RTC)Landsat-5 (LS5-SR), Landsat-7 (LS7-SR), Landsat-8 (LS8-SR) Landat-9 (LS9-SR). Landsat collections ARD data organized WRS-2 tiles.SAR L-band images produced PALSAR sensor onboard Japanese ALOS satellite(ALOS-PALSAR-MOSAIC). Data organized 5\\(^\\circ\\) 5\\(^\\circ\\) grid spatial resolution 25 meters. Images available annually 2007 2010 (ALOS/PALSAR) 2015 2022 (ALOS-2/PALSAR-2).Estimates vegetation condition using NDVI anomalies (NDVI-ANOMALY) compared long-term baseline condition. available measurements “NDVI_MEAN” (mean NDVI month) “NDVI-STD-ANOMALY” (standardised NDVI anomaly month).Rainfall information provided Climate Hazards Group InfraRed Precipitation Station data (CHIRPS) University California Santa Barbara. monthly (RAINFALL-CHIRPS-MONTHLY) daily (RAINFALL-CHIRPS-DAILY) products Africa.Digital elevation model provided EC Copernicus program (COP-DEM-30) 30 meter resolution organized 1\\(^\\circ\\) 1\\(^\\circ\\) grid.Annual geomedian images Landsat 8 Landsat 9 (GM-LS8-LS9-ANNUAL (LANDSAT/OLI)`) grid system WRS-2.Annual geomedian images Sentinel-2 (GM-S2-ANNUAL) MGRS grid.Rolling three-month geomedian images Sentinel-2 (GM-S2-ROLLING) MGRS grid.Semestral geomedian images Sentinel-2 (GM-S2-SEMIANNUAL) MGRS grid.Access DEAFRICA Sentinel-2 images can done wither using tiles roi parameter. example, requested roi produces cube contains one MGRS tiles (“35LPH”) covering area Madagascar includes Betsiboka Estuary.\nFigure 23: Sentinel-2 image area Madagascar (© EU Copernicus Sentinel Programme; source: Digital Earth Africa).\nnext example retrieves set ARD Landsat-9 data, covering Serengeti plain Tanzania.\nFigure 24: Landsat-9 image area Serengeti Tanzania (source: Digital Earth Africa).\nfollowing example shows retrieve subset ALOS-PALSAR mosaic year 2020, area near border Congo Rwanda.\nFigure 25: ALOS-PALSAC mosaic Congo forest area (© JAXA EORC; source: Digital Earth Africa).\n","code":"\ndea_s2_cube <- sits_cube(\n  source = \"DEAFRICA\",\n  collection = \"SENTINEL-2-L2A\",\n  roi = c(\n    lon_min = 46.1, lat_min = -15.6,\n    lon_max = 46.6, lat_max = -16.1\n  ),\n  bands = c(\"B02\", \"B04\", \"B08\"),\n  start_date = \"2019-04-01\",\n  end_date = \"2019-05-30\"\n)\nplot(dea_s2_cube, red = \"B04\", blue = \"B02\", green = \"B08\")\ndea_l9_cube <- sits_cube(\n  source = \"DEAFRICA\",\n  collection = \"LS9-SR\",\n  roi = c(\n    lon_min = 33.0, lat_min = -3.60,\n    lon_max = 33.6, lat_max = -3.00\n  ),\n  bands = c(\"B04\", \"B05\", \"B06\"),\n  start_date = \"2023-05-01\",\n  end_date = \"2023-08-30\"\n)\nplot(dea_l9_cube,\n  date = \"2023-06-26\",\n  red = \"B06\", green = \"B05\", blue = \"B04\"\n)\ndea_alos_cube <- sits_cube(\n  source = \"DEAFRICA\",\n  collection = \"ALOS-PALSAR-MOSAIC\",\n  roi = c(\n    lon_min = 28.69, lat_min = -2.35,\n    lon_max = 29.35, lat_max = -1.56\n  ),\n  bands = c(\"HH\", \"HV\"),\n  start_date = \"2020-01-01\",\n  end_date = \"2020-12-31\"\n)\nplot(dea_alos_cube, band = \"HH\")"},{"path":"earth-observation-data-cubes.html","id":"digital-earth-australia","chapter":"Earth observation data cubes","heading":"Digital Earth Australia","text":"Digital Earth Australia (DEAUSTRALIA) initiative Geoscience Australia uses satellite data monitor analyze environmental changes resources across Australian continent. provides many datasets offer detailed information phenomena droughts, agriculture, water availability, floods, coastal erosion, urban development. DEAUSTRALIA image collections sits :GA_LS5T_ARD_3: ARD images Landsat-5 satellite, bands “BLUE”, “GREEN”, “RED”, “NIR”, “SWIR-1”, “SWIR-2”, “CLOUD”.GA_LS7E_ARD_3: ARD images Landsat-7 satellite, bands Landsat-5.GA_LS8C_ARD_3: ARD images Landsat-8 satellite, bands “COASTAL-AEROSOL”, “BLUE”, “GREEN”, “RED”, “NIR”, “SWIR-1”, “SWIR-2”, “PANCHROMATIC”, “CLOUD”.GA_LS9C_ARD_3: ARD images Landsat-9 satellite, bands Landsat-8.GA_S2AM_ARD_3: ARD images Sentinel-2A satellite, bands “COASTAL-AEROSOL”, “BLUE”, “GREEN”, “RED”, “RED-EDGE-1”, “RED-EDGE-2”, “RED-EDGE-3”, “NIR-1”, “NIR-2”, “SWIR-2”, “SWIR-3”, “CLOUD”.GA_S2BM_ARD_3: ARD images Sentinel-2B satellite, bands Sentinel-2A.GA_LS5T_GM_CYEAR_3: Landsat-5 geomedian images, bands “BLUE”, “GREEN”, “RED”, “NIR”, “SWIR1”, “SWIR2”, “EDEV”, “SDEV”, “BCDEV”.GA_LS7E_GM_CYEAR_3: Landsat-7 geomedian images, bands Landsat-5 geomedian.GA_LS8CLS9C_GM_CYEAR_3: Landsat-8/9 geomedian images, bands Landsat-5 geomedian.GA_LS_FC_3: Landsat fractional land cover, bands “BS”, “PV”, “NPV”.GA_S2LS_INTERTIDAL_CYEAR_3: Landsat/Sentinel intertidal data, bands “ELEVATION”, “ELEVATION-UNCERTAINTY”, “EXPOSURE”, “TA-HAT”, “TA-HOT”, “TA-LOT”, “TA-LAT” “TA-OFFSET-HIGH”, “TA-OFFSET-LOW”, “TA-SPREAD”, “QA-NDWI-CORR”“QA-NDWI-FREQ”.following code retrieves image Sentinel-2\nFigure 26: Plot Sentinel-2 image obtained DEAUSTRALIA collection date 2023-10-14 showing MGRS tile 56KKV (© EU Copernicus Sentinel Programme; source: Digital Earth Australia).\n","code":"\n# get roi for an MGRS tile\nbbox_55KGR <- sits_mgrs_to_roi(\"55KGR\")\n# retrieve the world cover map for the chosen roi\ns2_56KKV <- sits_cube(\n  source = \"DEAUSTRALIA\",\n  collection = \"GA_S2AM_ARD_3\",\n  tiles = \"56KKV\",\n  bands = c(\"BLUE\", \"GREEN\", \"RED\", \"NIR-2\", \"SWIR-2\", \"CLOUD\"),\n  start_date = \"2023-09-01\",\n  end_date = \"2023-11-30\"\n)\n# plot the resulting map\nplot(s2_56KKV, green = \"NIR-2\", blue = \"BLUE\", red = \"SWIR-2\", date = \"2023-10-14\")"},{"path":"earth-observation-data-cubes.html","id":"harmonized-landsat-sentinel","chapter":"Earth observation data cubes","heading":"Harmonized Landsat-Sentinel","text":"Harmonized Landsat Sentinel (HLS) NASA initiative processes harmonizes Landsat 8 Sentinel-2 imagery common standard, including atmospheric correction, alignment, resampling, corrections BRDF (bidirectional reflectance distribution function). purpose HLS project create unified consistent dataset integrates advantages systems, making easier work data.NASA Harmonized Landsat Sentinel (HLS) service provides two image collections:Landsat 8 OLI Surface Reflectance HLS (HLSL30) – HLSL30 product includes atmospherically corrected surface reflectance Landsat 8 OLI sensors 30 m resolution. dataset includes 11 spectral bands.Landsat 8 OLI Surface Reflectance HLS (HLSL30) – HLSL30 product includes atmospherically corrected surface reflectance Landsat 8 OLI sensors 30 m resolution. dataset includes 11 spectral bands.Sentinel-2 MultiSpectral Instrument Surface Reflectance HLS (HLSS30) – HLSS30 product includes atmospherically corrected surface reflectance Sentinel-2 MSI sensors 30 m resolution. dataset includes 12 spectral bands.Sentinel-2 MultiSpectral Instrument Surface Reflectance HLS (HLSS30) – HLSS30 product includes atmospherically corrected surface reflectance Sentinel-2 MSI sensors 30 m resolution. dataset includes 12 spectral bands.HLS tiling system identical one used Sentinel-2 (MGRS). tiles dimension 109.8 km overlap 4,900 m side.access NASA HLS, users need registed NASA EarthData, save login password ~/.netrc plain text file Unix (%HOME%_netrc Windows). file must contain following fields:recommend using earthdatalogin package create .netrc file earthdatalogin::edl_netrc. function creates properly configured .netrc file user’s home directory environment variable GDAL_HTTP_NETRC_FILE, shown example.Access images NASA HLS done region interest tiles. following example shows HLS Sentinel-2 image Brazilian coast.\nFigure 27: Plot Sentinel-2 image obtained NASA HLS collection date 2020-06-15 showing island Ilhabela Brazilian coast (©EU Copernicus Sentinel Programme; source: NASA).\nImages HLS Landsat Sentinel-2 collections accessed separately can combined sits_merge(). script creates HLS Landsat cube area Sentinel-2 cube bands. two cubes merged.Comparing timelines original cubes merged one, one can see benefits merged collection time series data analysis.\nFigure 28: Plot Sentinel-2 image obtained merging NASA HLS collection Sentinel-2 collection date 2020-06-15 showing island Ilhabela Brazilian coast (© EU Copernicus Sentinel Programme; source: NASA).\n","code":"machine urs.earthdata.nasa.gov\nlogin <username>\npassword <password>\nlibrary(earthdatalogin)\n\nearthdatalogin::edl_netrc(\n  username = \"<your user name>\",\n  password = \"<your password>\"\n)\n# define a region of interest\nroi <- c(\n  lon_min = -45.6422, lat_min = -24.0335,\n  lon_max = -45.0840, lat_max = -23.6178\n)\n\n# create a cube from the HLSS30 collection\nhls_cube_s2 <- sits_cube(\n  source = \"HLS\",\n  collection = \"HLSS30\",\n  roi = roi,\n  bands = c(\"BLUE\", \"GREEN\", \"RED\", \"CLOUD\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2020-09-01\"),\n  progress = FALSE\n)\n# plot the cube\nplot(hls_cube_s2, red = \"RED\", green = \"GREEN\", blue = \"BLUE\", date = \"2020-06-20\")\n# define a region of interest\nroi <- c(\n  lon_min = -45.6422, lat_min = -24.0335,\n  lon_max = -45.0840, lat_max = -23.6178\n)\n\n# create a cube from the HLSS30 collection\nhls_cube_l8 <- sits_cube(\n  source = \"HLS\",\n  collection = \"HLSL30\",\n  roi = roi,\n  bands = c(\"BLUE\", \"GREEN\", \"RED\", \"CLOUD\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2020-09-01\"),\n  progress = FALSE\n)\n# merge the Sentinel-2 and Landsat-8 cubes\nhls_cube_merged <- sits_merge(hls_cube_s2, hls_cube_l8)\n# Timeline of the Sentinel-2 cube\nsits_timeline(hls_cube_s2)#>  [1] \"2020-06-15\" \"2020-06-20\" \"2020-06-25\" \"2020-06-30\" \"2020-07-05\"\n#>  [6] \"2020-07-10\" \"2020-07-20\" \"2020-07-25\" \"2020-08-04\" \"2020-08-09\"\n#> [11] \"2020-08-14\" \"2020-08-19\" \"2020-08-24\" \"2020-08-29\"\n# Timeline of the Landsat-8 cube\nsits_timeline(hls_cube_l8)#> [1] \"2020-06-09\" \"2020-06-25\" \"2020-07-11\" \"2020-07-27\" \"2020-08-12\"\n#> [6] \"2020-08-28\"\n# Timeline of the Landsat-8 cube\nsits_timeline(hls_cube_merged)#>  [1] \"2020-06-09\" \"2020-06-15\" \"2020-06-20\" \"2020-06-25\" \"2020-06-30\"\n#>  [6] \"2020-07-05\" \"2020-07-10\" \"2020-07-11\" \"2020-07-20\" \"2020-07-25\"\n#> [11] \"2020-07-27\" \"2020-08-04\" \"2020-08-09\" \"2020-08-12\" \"2020-08-14\"\n#> [16] \"2020-08-19\" \"2020-08-24\" \"2020-08-28\" \"2020-08-29\"\n# plotting a harmonized Landsat image from the merged dataset\n# plot the cube\nplot(hls_cube_merged,\n  red = \"RED\",\n  green = \"GREEN\",\n  blue = \"BLUE\",\n  date = \"2020-07-11\"\n)"},{"path":"earth-observation-data-cubes.html","id":"eo-products-from-terrascope","chapter":"Earth observation data cubes","heading":"EO products from TERRASCOPE","text":"Terrascope online platform accessing open-source satellite images. service, operated VITO, offers range Earth observation data processing services accessible free charge. Currently, sits supports World Cover 2021 maps, produced VITO support form European Commission ESA. following code shows access World Cover 2021 convering tile “22LBL”. first step use sits_mgrs_to_roi() get region interest expressed bounding box; box entered roi parameter sits_cube() function. Since World Cover data available 3\\(^\\circ\\) 3\\(^\\circ\\) grid, necessary use sits_cube_copy() extract exact MGRS tile.\nFigure 29: Plot World Cover 2021 map covering MGRS tile 22LBL (© TerraScope).\n","code":"\n# get roi for an MGRS tile\nbbox_22LBL <- sits_mgrs_to_roi(\"22LBL\")\n# retrieve the world cover map for the chosen roi\nworld_cover_2021 <- sits_cube(\n  source = \"TERRASCOPE\",\n  collection = \"WORLD-COVER-2021\",\n  roi = bbox_22LBL\n)\n# cut the 3 x 3 degree grid to match the MGRS tile 22LBL\nworld_cover_2021_20LBL <- sits_cube_copy(\n  cube = world_cover_2021,\n  roi = bbox_22LBL,\n  multicores = 6,\n  output_dir = \"./tempdir/chp4\"\n)\n# plot the resulting map\nplot(world_cover_2021_20LBL)"},{"path":"earth-observation-data-cubes.html","id":"planet-data-as-ard-local-files","chapter":"Earth observation data cubes","heading":"Planet data as ARD local files","text":"ARD images downloaded cloud collections local computer associated STAC endpoint describes . must organized named allow sits create data cube . local files directory spatial resolution projection. file must contain single image band single date. file name needs include tile, date, band information. Users must provide information original data source allow sits retrieve information image attributes band names, missing values, etc. working local cubes, sits_cube() needs following parameters:source: Name original data provider; list providers collections, use sits_list_collections().collection: Collection data extracted.data_dir: Local directory images.bands: Optional parameter describe bands retrieved.parse_info: Information parse file names. File names need contain information tile, date, band, separated delimiter (usually \"_\").delim: Separator character descriptors file name (default \"_\").able read local files, must belong collection registered sits. collections known sits default shown using sits_list_collections(). register new collection, please see information provided Technical Annex.example shows define data cube using Planet images sitsdata package. dataset contains monthly PlanetScope mosaics tile “604-1043” August October 2022, bands B01, B02, B04, B04.general, sits users need match local file names values provided parse_info parameter. file names dataset use format PLANETSCOPE_MOSAIC_604-1043_B4_2022-10-01.tif, fits default value parse_info c(\"source\", \"collection\", \"tile\", \"band\", \"date\") delim “_“, necessary set values creating data cube local files.\nFigure 30: Planet image area Colombia (© Planet - reproduction based fair use doctrine).\n","code":"\n# Define the directory where Planet files are stored\ndata_dir <- system.file(\"extdata/Planet\", package = \"sitsdata\")\n# Create a data cube from local files\nplanet_cube <- sits_cube(\n  source = \"PLANET\",\n  collection = \"MOSAIC\",\n  data_dir = data_dir\n)\n\n# Plot the first instance of the Planet data in natural colors\nplot(planet_cube, red = \"B3\", green = \"B2\", blue = \"B1\")"},{"path":"earth-observation-data-cubes.html","id":"reading-classified-images-as-local-data-cube","chapter":"Earth observation data cubes","heading":"Reading classified images as local data cube","text":"also possible create local cubes based results produced classification post-classification algorithms. case, parameters required, parameter parse_info specified differently, follows:source: Name original data provider.collection: Name collection data extracted.data_dir: Local directory classified images.band: Band name associated type result. Use: () probs probability cubes produced sits_classify(); (b) bayes, cubes produced sits_smooth(); (c) entropy, least, ratio margin, according method selected using sits_uncertainty(); (d) class classified cubes.labels: Labels associated names classes (required cubes produced sits_uncertainty()).version: Version result (default = v1).parse_info: File name parsing information allow sits deduce values tile, start_date, end_date, band, version file name. Unlike non-classified image files, cubes produced classification post-classification start_date end_date.following code creates results cube based classification deforestation Brazil. classified cube obtained large data cube Sentinel-2 images, covering state Rondonia, Brazil comprising 40 tiles, 10 spectral bands, covering period 2020-06-01 2021-09-11. Samples four classes trained random forest classifier. Internally, classified images use integers represent classes. Thus, labels associated integers represent class name.\nFigure 31: Classified data cube year 2020/2021 Rondonia, Brazil (© EU Copernicus Sentinel Programme; source: authors).\n","code":"\n# Create a cube based on a classified image\ndata_dir <- system.file(\"extdata/Rondonia-20LLP\",\n  package = \"sitsdata\"\n)\n# File name  \"SENTINEL-2_MSI_20LLP_2020-06-04_2021-08-26_class_v1.tif\"\nRondonia_class_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  bands = \"class\",\n  labels = c(\n    \"1\" = \"Burned_Area\", \"2\" = \"Cleared_Area\",\n    \"3\" = \"Highly_Degraded\", \"4\" = \"Forest\"\n  ),\n  data_dir = data_dir,\n  parse_info = c(\n    \"satellite\", \"sensor\", \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  )\n)\n# Plot the classified cube\nplot(Rondonia_class_cube)"},{"path":"earth-observation-data-cubes.html","id":"regularizing-data-cubes","chapter":"Earth observation data cubes","heading":"Regularizing data cubes","text":"ARD collections available AWS, MPC, USGS, DEAFRICA regular space time. Bands may different resolutions, images may cover entire tile, time intervals irregular. reason, data collections need converted regular data cubes calling sits_regularize(), uses gdalcubes package [6]. obtaining regular data cube, users can perform data analysis classification operations, shown following chapters.","code":""},{"path":"earth-observation-data-cubes.html","id":"regularizing-sentinel-2-images","chapter":"Earth observation data cubes","heading":"Regularizing Sentinel-2 images","text":"following example, user created irregular data cube Sentinel-2 collection available Microsoft’s Planetary Computer (MPC) tiles 20LKP 20LLP state Rondonia, Brazil. first build irregular data cube using sits_cube().\nFigure 32: Sentinel-2 tile 20LLP date 2018-07-03 (© EU Copernicus Sentinel Programme; source: authors).\ndifferent acquisition orbits Sentinel-2 Sentinel-2A satellites, two tiles also different timelines. Tile 20LKP 12 instances, tile 20LLP 24 instances chosen period. function sits_regularize() builds data cube regular timeline best estimate valid pixel interval. period parameter sets time interval two images. Values period use ISO8601 time period specification, defines time intervals P[n]Y[n]M[n]D, “Y” stands years, “M” months, “D” days. Thus, P1M stands one-month period, P15D fifteen-day period. joining different images get best image period, sits_regularize() uses aggregation method organizes images chosen interval order increasing cloud cover selects first cloud-free pixel. example, use small spatial resolution regular cube speed processing; actual case, suggest using 10-meter spatial resolution cube.\nFigure 33: Regularized image tile Sentinel-2 tile 20LLP (© EU Copernicus Sentinel Programme; source: authors).\n","code":"\n# Creating an irregular data cube from MPC\ns2_cube_rondonia <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = c(\"20LKP\", \"20LLP\"),\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  start_date = as.Date(\"2018-06-30\"),\n  end_date = as.Date(\"2018-08-31\")\n)\n# Show the different timelines of the cube tiles\nsits_timeline(s2_cube_rondonia)#> $`20LKP`\n#>  [1] \"2018-07-03\" \"2018-07-08\" \"2018-07-13\" \"2018-07-18\" \"2018-07-23\"\n#>  [6] \"2018-07-28\" \"2018-08-02\" \"2018-08-07\" \"2018-08-12\" \"2018-08-17\"\n#> [11] \"2018-08-22\" \"2018-08-27\"\n#> \n#> $`20LLP`\n#>  [1] \"2018-06-30\" \"2018-07-03\" \"2018-07-05\" \"2018-07-08\" \"2018-07-10\"\n#>  [6] \"2018-07-13\" \"2018-07-15\" \"2018-07-18\" \"2018-07-20\" \"2018-07-23\"\n#> [11] \"2018-07-25\" \"2018-07-28\" \"2018-07-30\" \"2018-08-02\" \"2018-08-04\"\n#> [16] \"2018-08-07\" \"2018-08-09\" \"2018-08-12\" \"2018-08-14\" \"2018-08-17\"\n#> [21] \"2018-08-19\" \"2018-08-22\" \"2018-08-24\" \"2018-08-27\" \"2018-08-29\"\n# plot the first image of the irregular cube\ns2_cube_rondonia |>\n  dplyr::filter(tile == \"20LLP\") |>\n  plot(red = \"B11\", green = \"B8A\", blue = \"B02\", date = \"2018-07-03\")\n# Regularize the cube to 15 day intervals\nreg_cube_rondonia <- sits_regularize(\n  cube       = s2_cube_rondonia,\n  output_dir = \"./tempdir/chp4\",\n  res        = 40,\n  period     = \"P16D\",\n  multicores = 6\n)\n\n# Plot the first image of the tile 20LLP of the regularized cube\n# The pixels of the regular data cube cover the full MGRS tile\nreg_cube_rondonia |>\n  dplyr::filter(tile == \"20LLP\") |>\n  plot(red = \"B11\", green = \"B8A\", blue = \"B02\")"},{"path":"earth-observation-data-cubes.html","id":"regularizing-sentinel-1-images","chapter":"Earth observation data cubes","heading":"Regularizing Sentinel-1 images","text":"acquisition mode, SAR images usually stored following geometry acquisition, inclined respect Earth. case GRD RTC collections available Microsoft Planetary Computer (MPC). allow easier use Sentinel-1 data merge Sentinel-2 images, regularization sits reprojects SAR data MGRS grid, shown following example. example uses “SENTINEL-1-RTC” collection MPC. Readers subscription can replace “SENTINEL-1-RTC” “SENTINEL-1-GRD” example.\nFigure 34: Original Sentinel-1 image covering tile 22LBL (© EU Copernicus Sentinel Programme; source: Microsoft).\ncreating irregular data cube data available MPC, use sits_regularize() produce SAR data cube matches MGRS tile “22LBL”. plotting SAR image, select multidate plot “VH” band, first date displayed red, second green third blue, show RGB map changes visually enhanced.\nFigure 35: Regular Sentinel-1 image covering tile 22LBL (© EU Copernicus Sentinel Programme; source: Microsoft).\n","code":"\n# create an RTC cube from MPC collection for a region in Mato Grosso, Brazil.\ncube_s1_rtc <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-1-RTC\",\n  bands = c(\"VV\", \"VH\"),\n  orbit = \"descending\",\n  tiles = c(\"22LBL\"),\n  start_date = \"2021-06-01\",\n  end_date = \"2021-10-01\"\n)\nplot(cube_s1_rtc, band = \"VH\", palette = \"Greys\", scale = 0.7)\n# define the output directory\n# # Create a directory to store files\nif (!file.exists(\"./tempdir/chp4/sar\")) {\n  dir.create(\"./tempdir/chp4/sar\")\n}\n# create a regular RTC cube from MPC collection for a tile 22LBL.\ncube_s1_reg <- sits_regularize(\n  cube = cube_s1_rtc,\n  period = \"P16D\",\n  res = 40,\n  tiles = c(\"22LBL\"),\n  memsize = 12,\n  multicores = 6,\n  output_dir = \"./tempdir/chp4/sar\"\n)\nplot(cube_s1_reg,\n  band = \"VH\", palette = \"Greys\", scale = 0.7,\n  dates = c(\"2021-06-06\", \"2021-07-24\", \"2021-09-26\")\n)"},{"path":"earth-observation-data-cubes.html","id":"merging-sentinel-1-and-sentinel-2-images","chapter":"Earth observation data cubes","heading":"Merging Sentinel-1 and Sentinel-2 images","text":"combine Sentinel-1 Sentinel-2 data, first step produce regular data cubes MGRS tiles compatible time steps. timelines exactly , need close enough matching acceptable number time steps. example uses regular Sentinel-1 cube tile “22LBL” produced previous sections. next step produce regular Sentinel-2 data cube tile regularize . cube defines irregular data cube retrieved Planetary Computer.\nFigure 36: Sentinel-2 image covering tile 22LBL (© EU Copernicus Sentinel Programme; source: authors).\nnext step create regular data cube tile “20LBL”.creating two regular cubes, can merge . step, one first compare timelines see match. Timelines regular cubes constrained acquisition dates, case Sentinel-1 Sentinel-2 different. Attentive readers noticed start end dates cubes selected Planetary Computer (see code ) slightly difference, need ensure regular cubes number time steps. timelines cubes shown .Considering timelines close enough cubes can combined, can use sits_merge function produce combined cube. example, show plot radar optical bands.\nFigure 37: Sentinel-2 Sentinel-1 RGB composite tile 22LBL (source: authors).\n","code":"\n# define the output directory\ncube_s2 <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"CLOUD\"),\n  tiles = c(\"22LBL\"),\n  start_date = \"2021-06-01\",\n  end_date = \"2021-09-30\"\n)\nplot(cube_s2, red = \"B11\", green = \"B8A\", blue = \"B02\", date = \"2021-07-07\")\nif (!file.exists(\"./tempdir/chp4/s2_opt\")) {\n  dir.create(\"./tempdir/chp4/s2_opt\")\n}\n# define the output directory\ncube_s2_reg <- sits_regularize(\n  cube = cube_s2,\n  period = \"P16D\",\n  res = 40,\n  tiles = c(\"22LBL\"),\n  memsize = 12,\n  multicores = 6,\n  output_dir = \"./tempdir/chp4/s2_opt\"\n)\n# timeline of the Sentinel-2 cube\nsits_timeline(cube_s2_reg)#> [1] \"2021-06-02\" \"2021-06-18\" \"2021-07-04\" \"2021-07-20\" \"2021-08-05\"\n#> [6] \"2021-08-21\" \"2021-09-06\" \"2021-09-22\"\n# timeline of the Sentinel-2 cube\nsits_timeline(cube_s1_reg)#> [1] \"2021-06-06\" \"2021-06-22\" \"2021-07-08\" \"2021-07-24\" \"2021-08-09\"\n#> [6] \"2021-08-25\" \"2021-09-10\" \"2021-09-26\"\n# merge Sentinel-1 and Sentinel-2 cubes\ncube_s1_s2 <- sits_merge(cube_s2_reg, cube_s1_reg)\n# plot a an image with both SAR and optical bands\nplot(cube_s1_s2, red = \"B11\", green = \"B8A\", blue = \"VH\")"},{"path":"earth-observation-data-cubes.html","id":"combining-multitemporal-data-cubes-with-digital-elevation-models","chapter":"Earth observation data cubes","heading":"Combining multitemporal data cubes with digital elevation models","text":"many applications, especially regions large topographical, soil climatic variations, useful merge multitemporal data cubes base information digital elevation models (DEM). Merging multitemporal satellite images digital elevation models (DEMs) offers several advantages enhance analysis interpretation geospatial data. Elevation data provides additional two-dimensional satellite images, help distinguish land use land cover classes impacted altitude gradients. One example capacity distinguish low-altitude high-altitude forests. case topography changes significantly, DEM information can improve accuracy classification algorithms.example DEM integation data cube, consider agricultural region Chile located narrow area close Andes. steep gradient cube benefits inclusion DEM.\nFigure 38: Sentinel-2 image covering tile 19HBA (source: authors).\n, produce regular data cube use classification. example, use reduced resolution (30 meters) expedite processing. practice, resolution 10 meters recommended.next step recover DEM area. purpose, use Copernicus Global DEM-30, select area covered tile. explained MPC access section , Copernicus DEM tiles stored 1\\(^\\circ\\) 1\\(^\\circ\\) grid. match MGRS tile, regularized similar way Sentinel-1 images, shown . select DEM, temporal information required.obtaining 1\\(^\\circ\\) 1\\(^\\circ\\) data cube covering selected tile, next step regularize . done using sits_regularize() function. function produce DEM matches exactly chosen tile.\nFigure 39: Copernicus DEM-30 covering tile 19HBA (© DLR e.V. 2010-2014 &copy Airbus Defence Space GmbH 2014-2018 provided COPERNICUS European Union ESA; source: Microsoft authors).\nobtaining regular data cubes satellite images DEMs, two ways combine . One option take DEM band multitemporal information, duplicate band every time step DEM becomes one additional time series. alternative use DEMs base cubes, take single additional band. options discusses follows.","code":"\ns2_cube_19HBA <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  tiles = \"19HBA\",\n  bands = c(\"B04\", \"B8A\", \"B12\", \"CLOUD\"),\n  start_date = \"2021-01-01\",\n  end_date = \"2021-03-31\"\n)\nplot(s2_cube_19HBA, red = \"B12\", green = \"B8A\", blue = \"B04\")\ns2_cube_19HBA_reg <- sits_regularize(\n  cube = s2_cube_19HBA,\n  period = \"P16D\",\n  res = 30,\n  output_dir = \"./tempdir/chp4/s2_19HBA\"\n)\n# obtain the DEM cube for\ndem_cube_19HBA <- sits_cube(\n  source = \"MPC\",\n  collection = \"COP-DEM-GLO-30\",\n  bands = \"ELEVATION\",\n  tiles = \"19HBA\"\n)\n# obtain the DEM cube for\ndem_cube_19HBA_reg <- sits_regularize(\n  cube = dem_cube_19HBA,\n  res = 30,\n  bands = \"ELEVATION\",\n  tiles = \"19HBA\",\n  output_dir = \"./tempdir/chp4/dem_19HBA\"\n)\n# plot the DEM reversing the palette\nplot(dem_cube_19HBA_reg, band = \"ELEVATION\", palette = \"Spectral\", rev = TRUE)"},{"path":"earth-observation-data-cubes.html","id":"merging-multitemporal-data-cubes-with-dem","chapter":"Earth observation data cubes","heading":"Merging multitemporal data cubes with DEM","text":"two ways combine multitemporal data cubes DEM data. first method takes DEM base information, used combination multispectral time series. exemple, consider situation data cube 10 bands 23 time steps, 230-dimensional space. Adding DEM base cube include one dimension attribute space. combination supported function sits_add_base_cube. resulting cube, information image time series DEM stored separately. data cube metadata now include column called base_info.Although combination conceptually simple, drawbacks. Since attribute space now mixes times series fixed-time information, applicable classification method random forests. way random forest works, attributes used every decision tree. training tree, node, random subset features selected, best split chosen based subset rather features. Thus, may significant number decision trees use DEM attribute. result, effect DEM information may underestimated.alternative combine image data cube DEM using sits_merge. case, DEM becomes another band. Although may look peculiar replicate DEM many time build artificial time series, many advantages . classification algorithms available sits (including deep learning ones) can used classify resulting cube. cases DEM information particularly important, organisation places DEM data par spectral bands. Users encouraged compare results obtained direct merging DEM spectral bands method DEM taken base cube.","code":"\nmerged_cube_base <- sits_add_base_cube(s2_cube_19HBA_reg, dem_cube_19HBA_reg)\nmerged_cube_base$base_info[[1]]#> # A tibble: 1 × 11\n#>   source collection     satellite sensor  tile    xmin   xmax   ymin  ymax crs  \n#>   <chr>  <chr>          <chr>     <chr>   <chr>  <dbl>  <dbl>  <dbl> <dbl> <chr>\n#> 1 MPC    COP-DEM-GLO-30 TANDEM-X  X-band… 19HBA 199980 309780 5.99e6 6.1e6 EPSG…\n#> # ℹ 1 more variable: file_info <list>\nmerged_cube <- sits_merge(s2_cube_19HBA_reg, dem_cube_19HBA_reg)\nmerged_cube$file_info[[1]]#> # A tibble: 24 × 13\n#>    fid   band      date       nrows ncols  xres  yres   xmin   ymin   xmax  ymax\n#>    <chr> <chr>     <date>     <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> <dbl>\n#>  1 1     B04       2021-01-03  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#>  2 1     B12       2021-01-03  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#>  3 1     B8A       2021-01-03  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#>  4 1     ELEVATION 2021-01-03  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#>  5 2     B04       2021-01-19  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#>  6 2     B12       2021-01-19  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#>  7 2     B8A       2021-01-19  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#>  8 1     ELEVATION 2021-01-19  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#>  9 3     B04       2021-02-04  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#> 10 3     B12       2021-02-04  3660  3660    30    30 199980 5.99e6 309780 6.1e6\n#> # ℹ 14 more rows\n#> # ℹ 2 more variables: crs <chr>, path <chr>"},{"path":"operations-on-data-cubes.html","id":"operations-on-data-cubes","chapter":"Operations on data cubes","heading":"Operations on data cubes","text":"","code":""},{"path":"operations-on-data-cubes.html","id":"pixel-based-and-neighborhood-based-operations","chapter":"Operations on data cubes","heading":"Pixel-based and neighborhood-based operations","text":"Pixel-based operations remote sensing images refer image processing techniques operate individual pixels cells image without considering spatial relationships neighboring pixels. operations typically applied pixel image independently can used extract information spectral, radiometric, spatial properties. Pixel-based operations produce spectral indexes combine data multiple bands.Neighborhood-based operations applied groups pixels image. neighborhood typically defined rectangular circular region centered given pixel. operations can used removing noise, detecting edges, sharpening, among uses.sits_apply() function computes new indices desired mathematical operation function bands available cube using valid R expression. applies operation tiles temporal intervals. two types operations sits_apply():Pixel-based operations produce index based individual pixels existing bands. input bands indexes part input data cube names used cube. new index computed every pixel images time series. Besides arithmetic operators, function also accepts vectorized R functions can applied matrices (e.g., sqrt(), log(), sin()).Pixel-based operations produce index based individual pixels existing bands. input bands indexes part input data cube names used cube. new index computed every pixel images time series. Besides arithmetic operators, function also accepts vectorized R functions can applied matrices (e.g., sqrt(), log(), sin()).Neighborhood-based operations produce derived value based window centered around individual pixel. available functions w_median(), w_sum(), w_mean(), w_min(), w_max(), w_sd() (standard deviation), w_var() (variance). Users set window size (odd values allowed).Neighborhood-based operations produce derived value based window centered around individual pixel. available functions w_median(), w_sum(), w_mean(), w_min(), w_max(), w_sd() (standard deviation), w_var() (variance). Users set window size (odd values allowed).following examples show use sits_apply().","code":""},{"path":"operations-on-data-cubes.html","id":"computing-vegetation-indexes","chapter":"Operations on data cubes","heading":"Computing vegetation indexes","text":"Using vegetation indexes established practice remote sensing. indexes aim improve discrimination vegetation structure combining two wavebands, one leaf pigments reflect incoming light another leaves absorb incoming radiation. Green leaves natural vegetation forests strong emissivity rate near-infrared bands low emissivity rates red bands electromagnetic spectrum. spectral properties used calculate Normalized Difference Vegetation Index (NDVI), widely used index computed normalized difference values infra-red red bands. Including red-edge bands Sentinel-2 images broadened scope bands used calculate indices [8], [9]. follows, show examples vegetation index calculation using Sentinel-2 data cube.First, define data cube tile state Rondonia, Brazil, including bands used compute different vegetation indexes. regularize cube using target resolution 60 m reduce processing time.many options calculating vegetation indexes using Sentinel-2 bands. widely used method combines band B08 (785-899 nm) band B04 (650-680 nm). Recent works literature propose using red-edge bands B05 (698-713 nm), B06 (733-748 nm), B07 (773-793 nm) capturing subtle variations chlorophyll absorption producing indexes, called Normalized Difference Vegetation Red-edge indexes (NDRE) [8]. recent review, Chaves et al. argue red-edge bands important distinguishing leaf structure chlorophyll content different vegetation species [10]. example , show include indexes regular data cube Sentinel-2 spectral bands.first calculate NDVI usual way, using bands B08 B04.\nFigure 40: NDVI using bands B08 B04 Sentinel-2 (© EU Copernicus Programme modified authors).\nnow compare traditional NDVI vegetation index computed using red-edge bands. example NDRE1 index, obtained using bands B06 B05. Sun et al. argue vegetation index built using bands B06 B07 provides better approximation leaf area index estimates NDVI [9]. Notice contrast forests deforested areas robust NDRE1 index NDVI.\nFigure 41: NDRE1 using bands B06 B05 Sentinel-2 (© EU Copernicus Programme modified authors).\n","code":"\n# Create a directory to store files\nif (!file.exists(\"./tempdir/chp5\")) {\n  dir.create(\"./tempdir/chp5\")\n}\n# Create an irregular data cube from AWS\ns2_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  tiles = \"20LKP\",\n  bands = c(\n    \"B02\", \"B03\", \"B04\",\n    \"B05\", \"B06\", \"B07\",\n    \"B08\", \"B8A\", \"B11\",\n    \"B12\", \"CLOUD\"\n  ),\n  start_date = as.Date(\"2018-07-01\"),\n  end_date = as.Date(\"2018-08-31\")\n)\n# Regularize the cube to 15 day intervals\nreg_cube <- sits_regularize(\n  cube       = s2_cube,\n  output_dir = \"./tempdir/chp5\",\n  res        = 60,\n  period     = \"P15D\",\n  multicores = 4\n)\n# Calculate NDVI index using bands B08 and B04\nreg_cube <- sits_apply(reg_cube,\n  NDVI = (B08 - B04) / (B08 + B04),\n  output_dir = \"./tempdir/chp5\"\n)\nplot(reg_cube, band = \"NDVI\", palette = \"RdYlGn\")\n# Calculate NDRE1 index using bands B06 and B05\nreg_cube <- sits_apply(reg_cube,\n  NDRE1 = (B06 - B05) / (B06 + B05),\n  output_dir = \"./tempdir/chp5\"\n)\n# Plot NDRE1 index\nplot(reg_cube, band = \"NDRE1\", palette = \"RdYlGn\")"},{"path":"operations-on-data-cubes.html","id":"spectral-indexes-for-identifying-burned-areas","chapter":"Operations on data cubes","heading":"Spectral indexes for identifying burned areas","text":"Band combination can also generate spectral indices detecting degradation fires, important element environmental degradation. Forest fires significantly impact emissions impoverish natural ecosystems [11]. Fires open canopy, making microclimate drier increasing amount dry fuel [12]. One well-established technique detecting burned areas remote sensing images normalized burn ratio (NBR), difference near-infrared short wave infrared band, calculated using bands B8A B12.\nFigure 42: NBR ratio using Sentinel-2 B11 B8A (© EU Copernicus Programme modified authors).\n","code":"\n# Calculate the NBR index\nreg_cube <- sits_apply(reg_cube,\n  NBR = (B12 - B8A) / (B12 + B8A),\n  output_dir = \"./tempdir/chp5\"\n)\n# Plot the NBR for the first date\nplot(reg_cube, band = \"NBR\", palette = \"Reds\")"},{"path":"operations-on-data-cubes.html","id":"support-for-non-normalized-indexes","chapter":"Operations on data cubes","heading":"Support for non-normalized indexes","text":"data cube operations discussed far produce normalized indexes. default, indexes generated sits_apply() function normalized -1 1, scaled factor 0.0001. Normalized indexes saved INT2S (Integer sign). normalized parameter FALSE, scaling factor applied index saved FLT4S (Float sign). code shows exemple non-normalized index, CVI - chlorophyll vegetation index. CVI spectral index used estimate chlorophyll content overall health vegetation. combines bands visible near-infrared (NIR) regions assess vegetation characteristics. Since CVI normalized, set parameter normalized FALSE inform sits_apply() generate FLT4S image.\nFigure 43: CVI index using bands B03, B05, B8A (© EU Copernicus Programme modified authors).\n","code":"\n# Calculate the NBR index\nreg_cube <- sits_apply(reg_cube,\n  CVI = (B8A / B03) * (B05 / B03),\n  normalized = FALSE,\n  output_dir = \"./tempdir/chp5\"\n)\nplot(reg_cube, band = \"CVI\", palette = \"Greens\")"},{"path":"operations-on-data-cubes.html","id":"temporal-combination-operations","chapter":"Operations on data cubes","heading":"Temporal combination operations","text":"cases users want produce results combine values time series associated pixel data cube using reduction operators. context time series analysis, reduction operator function reduces sequence data points single value smaller set values. process involves summarizing aggregating information time series meaningful way. Reduction operators often used extract key statistics features data, making easier analyze interpret.produce temporal combinations, sits provides sits_reduce, associated functions:t_max(): maximum value series.t_min(): minimum value seriest_mean(): mean series.t_median(): median series.t_sum(): sum points series.t_std(): standard deviation series.t_skewness(): skewness series.t_kurtosis(): kurtosis series.t_amplitude(): difference maximum minimum values cycle. small amplitude means stable cycle.t_fslope(): maximum value first slope cycle. Indicates cycle presents abrupt change curve. slope two values relates speed growth senescence phasest_mse(): average spectral energy density. energy time series distributed frequency.t_fqr(): value first quartile series (0.25).t_tqr(): value third quartile series (0.75).t_iqr(): interquartile range (difference third first quartiles).functions t_sum(), t_std(), t_skewness(), t_kurtosis(), t_mse() produce values greater limit two-byte integer. Therefore, save images generated floating point format.following examples show example temporal reduction operations.\nFigure 44: maximum NDVI Sentinel-2 cube (© EU Copernicus Programme modified authors).\n","code":"\n# Calculate the NBR index\nave_cube <- sits_reduce(reg_cube,\n  NDVIMAX = t_max(NDVI),\n  output_dir = \"./tempdir/chp5/reduce\"\n)\nplot(ave_cube, band = \"NDVIMAX\", palette = \"Greens\")"},{"path":"operations-on-data-cubes.html","id":"spectral-mixture-analysis","chapter":"Operations on data cubes","heading":"Spectral mixture analysis","text":"Many pixels images medium-resolution satellites Landsat Sentinel-2 contain mixture spectral responses different land cover types inside resolution element [13]. many applications, desirable obtain proportion given class inside mixed pixel. purpose, literature proposes mixture models; models represent pixel values combination multiple pure land cover types [14]. Assuming spectral response pure land cover classes (called endmembers) known, spectral mixture analysis derives new bands containing proportion endmember inside pixel.used method spectral mixture analysis linear model [14]. main idea behind linear mixture model observed pixel spectrum can expressed linear combination spectra pure endmembers, weighted respective proportions (abundances) within pixel. Mathematically, model can represented :\n\\[\nR_i = \\sum_{j=1}^N a_{,j}*x_j + \\epsilon_i, \\{1,...M}, M > N,\n\\]\n\\(=1,..M\\) set spectral bands \\(j=1,..N\\) set land classes. pixel, \\(R_i\\) reflectance -th spectral band, \\(x_j\\) reflectance value due j-th endmember, \\(a_{,j}\\) proportion j-th endmember -th spectral band. solve system equations obtain proportion endmember, sits uses non-negative least squares (NNLS) regression algorithm, available R package RStoolbox developed Jakob Schwalb-Willmann, based sequential coordinate-wise algorithm (SCA) proposed Franc et al. [15].run mixture model sits, necessary inform values pixels represent spectral responses unique class. -called “pure” pixels. quality resulting endmember images depends quality pure pixels, chosen carefully based expert knowledge area. Since sits supports multiple endmember spectral mixture analysis [16], users can specify one pure pixel per endmember account natural variability.sits, spectral mixture analysis done sits_mixture_model(), two mandatory parameters: cube (data cube) endmembers, named table (equivalent) defines pure pixels. endmembers table must following named columns: () type, defines class associated endmember; (b) names, names bands. line table must contain value endmember bands (see example). improve readability, suggest endmembers parameters defined tribble. tribble tibble easier read row--row layout. example , define three endmembers classes Forest, Soil, Water. Note values band expressed integers ranging 0 10,000.\nFigure 45: Percentage forest per pixel estimated mixture model ((© EU Copernicus Programme modified authors).\n\nFigure 46: Percentage water per pixel estimated mixture model (source: authors).\n\nFigure 47: Percentage soil per pixel estimated mixture model (source: authors).\nLinear mixture models (LMM) improve interpretation remote sensing images accounting mixed pixels providing accurate representation Earth’s surface. LMMs provide accurate representation mixed pixels considering contributions multiple land classes within single pixel. can lead improved land cover classification accuracy compared conventional per-pixel classification methods, may struggle accurately classify mixed pixels.LMMs also allow estimation abundances land class within pixel, providing valuable sub-pixel information. can especially useful applications spatial resolution sensor fine enough resolve individual land cover types, monitoring urban growth studying vegetation dynamics. considering sub-pixel composition land classes, LMMs can provide sensitive measure changes land cover time. can lead accurate precise change detection, particularly areas complex land cover patterns subtle changes land cover may occur.Applications spectral mixture analysis remote sensing include forest degradation [20], wetland surface dynamics [21], urban area characterization [22]. models providing valuable information wide range applications, land mapping change detection resource management environmental monitoring.","code":"\n# Define the endmembers for three classes and six bands\nem <- tibble::tribble(\n  ~class,   ~B02, ~B03, ~B04, ~B8A, ~B11, ~B12,\n  \"forest\",  200,  352,  189, 2800, 1340,  546,\n  \"soil\",    400,  650,  700, 3600, 3500, 1800,\n  \"water\",   700, 1100, 1400,  850,   40,   26\n)\n# Generate the mixture model\nreg_cube <- sits_mixture_model(\n  data = reg_cube,\n  endmembers = em,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp5\"\n)\n# Plot the FOREST for the first date using the Greens palette\nplot(reg_cube, band = \"FOREST\", palette = \"Greens\")\n# Plot the water endmember for the first date using the Blues palette\nplot(reg_cube, band = \"WATER\", palette = \"Blues\")\n# Plot the SOIL endmember for the first date using the orange red (OrRd) palette\nplot(reg_cube, band = \"SOIL\", palette = \"OrRd\")"},{"path":"working-with-time-series.html","id":"working-with-time-series","chapter":"Working with time series","heading":"Working with time series","text":"","code":""},{"path":"working-with-time-series.html","id":"data-structures-for-satellite-time-series","chapter":"Working with time series","heading":"Data structures for satellite time series","text":"sits package uses sets time series data describing properties spatiotemporal locations interest. land classification, sets consist samples labeled experts. package can also used type classification, provided timeline bands time series used training match data cubes.sits, time series stored tibble data structure. following code shows first three lines time series tibble containing 1,882 labeled samples land classes Mato Grosso state Brazil. samples time series extracted MODIS MOD13Q1 product 2000 2016, provided every 16 days 250 m resolution Sinusoidal projection. Based ground surveys high-resolution imagery, includes samples seven classes: Forest, Cerrado, Pasture, Soy_Fallow, Soy_Cotton, Soy_Corn, Soy_Millet.time series tibble contains data metadata. first six columns contain spatial temporal information, label assigned sample, data cube data extracted. first sample labeled Pasture location (-58.5631, -13.8844), valid period (2006-09-14, 2007-08-29). Informing dates label valid crucial correct classification. case, researchers labeling samples used agricultural calendar Brazil. relevant dates applications countries likely differ used example. time_series column contains time series data spatiotemporal location. data also organized tibble, column dates columns values spectral band.","code":"\n# Samples\ndata(\"samples_matogrosso_mod13q1\")\nsamples_matogrosso_mod13q1[1:4, ]#> # A tibble: 4 × 7\n#>   longitude latitude start_date end_date   label   cube     time_series      \n#>       <dbl>    <dbl> <date>     <date>     <chr>   <chr>    <list>           \n#> 1     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 2     -59.4    -9.31 2014-09-14 2015-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 3     -59.4    -9.31 2013-09-14 2014-08-29 Pasture bdc_cube <tibble [23 × 5]>\n#> 4     -57.8    -9.76 2006-09-14 2007-08-29 Pasture bdc_cube <tibble [23 × 5]>"},{"path":"working-with-time-series.html","id":"utilities-for-handling-time-series","chapter":"Working with time series","heading":"Utilities for handling time series","text":"package provides functions data manipulation displaying information time series tibbles. example, summary() shows labels sample set frequencies.many cases, helpful relabel dataset. example, may situations using smaller set labels desirable samples one label original set may distinguishable samples labels. use sits_labels()<- assign new labels. example shows relabeling time series set shown ; samples associated crops grouped single Croplands label.Since metadata embedded time series use tibble data format, functions dplyr, tidyr, purrr packages tidyverse [23] can used process data. example, following code uses sits_select() get subset sample dataset two bands (NDVI EVI) uses dplyr::filter() select samples labeled Cerrado.","code":"\nsummary(samples_matogrosso_mod13q1)#> # A tibble: 7 × 3\n#>   label      count   prop\n#>   <chr>      <int>  <dbl>\n#> 1 Cerrado      379 0.206 \n#> 2 Forest       131 0.0713\n#> 3 Pasture      344 0.187 \n#> 4 Soy_Corn     364 0.198 \n#> 5 Soy_Cotton   352 0.192 \n#> 6 Soy_Fallow    87 0.0474\n#> 7 Soy_Millet   180 0.0980\n# Copy the sample set for Mato Grosso\nsamples_new_labels <- samples_matogrosso_mod13q1\n# Show the current labels\nsits_labels(samples_new_labels)#> [1] \"Cerrado\"    \"Forest\"     \"Pasture\"    \"Soy_Corn\"   \"Soy_Cotton\"\n#> [6] \"Soy_Fallow\" \"Soy_Millet\"\n# Update the labels\nsits_labels(samples_new_labels) <- c(\n  \"Cerrado\", \"Forest\",\n  \"Pasture\", \"Croplands\",\n  \"Cropland\", \"Cropland\",\n  \"Cropland\"\n)\nsummary(samples_new_labels)#> # A tibble: 5 × 3\n#>   label     count   prop\n#>   <chr>     <int>  <dbl>\n#> 1 Cerrado     379 0.206 \n#> 2 Cropland    619 0.337 \n#> 3 Croplands   364 0.198 \n#> 4 Forest      131 0.0713\n#> 5 Pasture     344 0.187\n# Select NDVI band\nsamples_ndvi <- sits_select(samples_matogrosso_mod13q1,\n  bands = \"NDVI\"\n)\n# Select only samples with Cerrado label\nsamples_cerrado <- dplyr::filter(\n  samples_ndvi,\n  label == \"Cerrado\"\n)"},{"path":"working-with-time-series.html","id":"time-series-visualisation","chapter":"Working with time series","heading":"Time series visualisation","text":"Given samples display, plot() tries group many spatial locations together. following example, first 12 samples labeled Cerrado refer spatial location consecutive time periods. reason, samples plotted together.\nFigure 48: Plot first ‘Cerrado’ samples (source: authors).\nmany samples, default visualization combines samples together single temporal interval, even belong different years. plot shows spread values time series band. strong red line plot indicates median values, two orange lines first third interquartile ranges. See ?sits::plot details data visualization sits.\nFigure 49: Plot Cerrado samples (source: authors).\nsee spatial distribution samples, use sits_view() create interactive plot. spatial visulisation useful show data collected.","code":"\n# Plot the first 12 samples\nplot(samples_cerrado[1:12, ])\n# Plot all cerrado samples together\nplot(samples_cerrado)\nsits_view(samples_matogrosso_mod13q1)"},{"path":"working-with-time-series.html","id":"visualizing-sample-patterns","chapter":"Working with time series","heading":"Visualizing sample patterns","text":"dealing large time series, useful obtain single plot captures essential temporal variability class. Following work dtwSat R package [24], use generalized additive model (GAM) obtain single time series based statistical approximation. GAM, predictor depends linearly smooth function predictor variables.\\[\ny = \\beta_{} + f(x) + \\epsilon, \\epsilon \\sim N(0, \\sigma^2).\n\\]function sits_patterns() uses GAM predict idealized approximation time series associated class bands. resulting patterns can viewed using plot().\nFigure 50: Patterns samples Mato Grosso (source: authors).\nresulting patterns provide insights time series behaviour class. response Forest class quite distinctive. also show possible separate single double cropping classes. similarities double-cropping classes (Soy_Corn Soy_Millet) Cerrado Pasture classes. subtle differences class signatures provide hints possible ways machine learning algorithms might distinguish classes. One example difference middle-infrared response dry season (May September) differentiate Cerrado Pasture.","code":"\n# Estimate the patterns for each class and plot them\nsamples_matogrosso_mod13q1 |>\n  sits_patterns() |>\n  plot()"},{"path":"working-with-time-series.html","id":"geographical-variability-of-training-samples","chapter":"Working with time series","heading":"Geographical variability of training samples","text":"working machine learning classification Earth observation data, important evaluate training samples well distributed study area. Training data often comes ground surveys made chosen locations. large areas, ideally representative samples need capture spatial variability. practice, however, ground surveys means data collection limited selected areas. many cases, geographical distribution training data cover study area equally. mismatch can problem achieving good quality classification. stated Meyer Pebesma [25]: “large gaps geographic space always imply large gaps feature space”.Meyer Pebesma propose using spatial distance distribution plot, displays two distributions nearest-neighbor distances: sample--sample prediction-location--sample [25]. difference two distributions reflects degree spatial clustering reference data. Ideally, two distributions similar. Cases sample--sample distance distribution match prediction-location--sample distribution indicate possible problems training data collection.sits implements spatial distance distribution plots sits_geo_dist() function. function gets training data samples parameter, study area roi parameter expressed sf object. Additional parameters n (maximum number samples distribution) crs (coordinate reference system samples). default, n 1000, crs “EPSG:4326”. example shows use sits_geo_dist().\nFigure 51: Distribution sample--sample sample--prediction distances (source: authors).\nplot shows mismatch sample--sample sample--prediction distributions. samples closer close location values need predicted. case, many areas samples collected prediction uncertainty higher. similar cases, improving distribution training samples always welcome. possible, areas insufficient samples lower accuracy. information must reported potential users classification results.","code":"\n# Read a shapefile for the state of Mato Grosso, Brazil\nmt_shp <- system.file(\"extdata/shapefiles/mato_grosso/mt.shp\",\n  package = \"sits\"\n)\n# Convert to an sf object\nmt_sf <- sf::read_sf(mt_shp)\n\n# Calculate sample-to-sample and sample-to-prediction distances\ndistances <- sits_geo_dist(\n  samples = samples_modis_ndvi,\n  roi = mt_sf\n)\n# Plot sample-to-sample and sample-to-prediction distances\nplot(distances)"},{"path":"working-with-time-series.html","id":"obtaining-time-series-data-from-data-cubes","chapter":"Working with time series","heading":"Obtaining time series data from data cubes","text":"get set time series sits, first create regular data cube request one time series cube using sits_get_data(). function uses two mandatory parameters: cube samples. cube indicates data cube time series extracted. samples parameter accepts following data types:data.frame information latitude longitude (mandatory), start_date, end_date, label sample point.csv file columns latitude, longitude, start_date, end_date, label.shapefile containing either POINTor POLYGON geometries. See details .sf object (sf package) POINT POLYGON geometry information. See details .example , given data cube, user provides latitude longitude desired location. Since bands, start date, end date time series missing, sits obtains data cube. result tibble one time series can visualized using plot().\nFigure 52: NDVI EVI time series fetched local raster cube (source: authors).\nuseful case set labeled samples can used training dataset. case, trusted observations usually labeled commonly stored plain text files comma-separated values (csv) using shapefiles (shp).retrieve training samples time series analysis, users must provide temporal information (start_date end_date). simplest case, samples share dates. strict requirement. possible specify different dates long compatible duration. example, dataset samples_matogrosso_mod13q1 provided sitsdata package contains samples different years covering duration. samples MOD13Q1 product, contains number images per year. Thus, time series dataset samples_matogrosso_mod13q1 number dates.Given suitably built csv sample file, sits_get_data() requires two parameters: () cube, name R object describes data cube; (b) samples, name CSV file.Users can also specify samples providing shapefiles sf objects containing POINT POLYGON geometries. geographical location inferred geometries associated shapefile sf object. files containing points, geographical location obtained directly. polygon geometries, parameter n_sam_pol (defaults 20) determines number samples extracted polygon. temporal information can provided explicitly user; absent, inferred data cube. label information available shapefile sf object, parameter label_attr compulsory indicate column contains label associated time series.","code":"\n# Obtain a raster cube based on local files\ndata_dir <- system.file(\"extdata/sinop\", package = \"sitsdata\")\nraster_cube <- sits_cube(\n  source     = \"BDC\",\n  collection = \"MOD13Q1-6.1\",\n  data_dir   = data_dir,\n  parse_info = c(\"satellite\", \"sensor\", \"tile\", \"band\", \"date\")\n)\n# Obtain a time series from the raster cube from a point\nsample_latlong <- tibble::tibble(\n  longitude = -55.57320,\n  latitude  = -11.50566\n)\nseries <- sits_get_data(\n  cube = raster_cube,\n  samples = sample_latlong\n)\nplot(series)\n# Retrieve a list of samples described by a csv file\nsamples_csv_file <- system.file(\"extdata/samples/samples_sinop_crop.csv\",\n  package = \"sits\"\n)\n# Read the csv file into an R object\nsamples_csv <- read.csv(samples_csv_file)\n# Print the first three samples\nsamples_csv[1:3, ]#> # A tibble: 3 × 6\n#>      id longitude latitude start_date end_date   label  \n#>   <int>     <dbl>    <dbl> <chr>      <chr>      <chr>  \n#> 1     1     -55.7    -11.8 2013-09-14 2014-08-29 Pasture\n#> 2     2     -55.6    -11.8 2013-09-14 2014-08-29 Pasture\n#> 3     3     -55.7    -11.8 2013-09-14 2014-08-29 Forest\n# Get the points from a data cube in raster brick format\npoints <- sits_get_data(\n  cube = raster_cube,\n  samples = samples_csv_file\n)\n# Show the tibble with the first three points\npoints[1:3, ]#> # A tibble: 3 × 7\n#>   longitude latitude start_date end_date   label    cube        time_series\n#>       <dbl>    <dbl> <date>     <date>     <chr>    <chr>       <list>     \n#> 1     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6.1 <tibble>   \n#> 2     -55.8    -11.7 2013-09-14 2014-08-29 Cerrado  MOD13Q1-6.1 <tibble>   \n#> 3     -55.7    -11.7 2013-09-14 2014-08-29 Soy_Corn MOD13Q1-6.1 <tibble>\n# Obtain a set of points inside the state of Mato Grosso, Brazil\nshp_file <- system.file(\"extdata/shapefiles/mato_grosso/mt.shp\",\n  package = \"sits\"\n)\n# Read the shapefile into an \"sf\" object\nsf_shape <- sf::st_read(shp_file)#> Reading layer `mt' from data source \n#>   `/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/sits/extdata/shapefiles/mato_grosso/mt.shp' \n#>   using driver `ESRI Shapefile'\n#> Simple feature collection with 1 feature and 3 fields\n#> Geometry type: MULTIPOLYGON\n#> Dimension:     XY\n#> Bounding box:  xmin: -61.63284 ymin: -18.03993 xmax: -50.22481 ymax: -7.349034\n#> Geodetic CRS:  SIRGAS 2000\n# Create a data cube based on MOD13Q1 collection from BDC\nmodis_cube <- sits_cube(\n  source      = \"BDC\",\n  collection  = \"MOD13Q1-6.1\",\n  bands       = c(\"NDVI\", \"EVI\"),\n  roi         = sf_shape,\n  start_date  = \"2020-06-01\",\n  end_date    = \"2021-08-29\"\n)\n\n# Read the points from the cube and produce a tibble with time series\nsamples_mt <- sits_get_data(\n  cube         = modis_cube,\n  samples      = shp_file,\n  start_date   = \"2020-06-01\",\n  end_date     = \"2021-08-29\",\n  n_sam_pol    = 20,\n  multicores   = 4\n)"},{"path":"working-with-time-series.html","id":"filtering-time-series","chapter":"Working with time series","heading":"Filtering time series","text":"Satellite image time series generally contaminated atmospheric influence, geolocation error, directional effects [26]. Atmospheric noise, sun angle, interferences observations different equipment specifications, nature climate-land dynamics can sources variability [27]. Inter-annual climate variability also changes phenological cycles vegetation, resulting time series whose periods intensities match year--year basis. make best use available satellite data archives, methods satellite image time series analysis need deal noisy non-homogeneous datasets.literature satellite image time series several applications filtering correct smooth vegetation index data. package supports well-known Savitzky–Golay (sits_sgolay()) Whittaker (sits_whittaker()) filters. evaluation NDVI time series filtering estimating phenological parameters India, Atkinson et al. found Whittaker filter provides good results [27]. Zhou et al. found Savitzky-Golay filter suitable reconstructing tropical evergreen broadleaf forests [28].","code":""},{"path":"working-with-time-series.html","id":"savitzkygolay-filter","chapter":"Working with time series","heading":"Savitzky–Golay filter","text":"Savitzky-Golay filter fits successive array \\(2n+1\\) adjacent data points \\(d\\)-degree polynomial linear least squares. main parameters filter polynomial degree (\\(d\\)) length window data points (\\(n\\)). generally produces smoother results larger value \\(n\\) /smaller value \\(d\\) [29]. optimal value two parameters can vary case case. sits, parameter order sets order polynomial (default = 3), parameter length sets size temporal window (default = 5), parameter scaling sets temporal expansion (default = 1). following example shows effect Savitsky-Golay filter point extracted MOD13Q1 product, ranging 2000-02-18 2018-01-01.\nFigure 53: Savitzky-Golay filter applied multi-year NDVI time series (source: authors).\nresulting smoothed curve desirable unwanted properties. 2000 2008, Savitsky-Golay filter removes noise clouds. However, 2010, region converted agriculture, filter removes important part natural variability crop cycle. Therefore, length parameter arguably big, resulting oversmoothing.","code":"\n# Take NDVI band of the first sample dataset\npoint_ndvi <- sits_select(point_mt_6bands, band = \"NDVI\")\n# Apply Savitzky Golay filter\npoint_sg <- sits_sgolay(point_ndvi, length = 11)\n# Merge the point and plot the series\nsits_merge(point_sg, point_ndvi) |> plot()"},{"path":"working-with-time-series.html","id":"whittaker-filter","chapter":"Working with time series","heading":"Whittaker filter","text":"Whittaker smoother attempts fit curve representing raw data, penalized subsequent points vary much [30]. Whittaker filter balances residual original data smoothness fitted curve. filter one parameter: \\(\\lambda{}\\) works smoothing weight parameter. following example shows effect Whittaker filter point extracted MOD13Q1 product, ranging 2000-02-18 2018-01-01. lambda parameter controls smoothing filter. default, set 0.5, small value. example shows effect larger smoothing parameter.\nFigure 54: Whittaker filter applied one-year NDVI time series (source: authors).\nSimilar observed Savitsky-Golay filter, high values smoothing parameter lambda produce -smoothed time series reduces capacity time series represent natural variations crop growth. reason, low smoothing values recommended using sits_whittaker().","code":"\n# Take NDVI band of the first sample dataset\npoint_ndvi <- sits_select(point_mt_6bands, band = \"NDVI\")\n# Apply Whitakker filter\npoint_whit <- sits_whittaker(point_ndvi, lambda = 8)\n# Merge the point and plot the series\nsits_merge(point_whit, point_ndvi) |> plot()"},{"path":"improving-the-quality-of-training-samples.html","id":"improving-the-quality-of-training-samples","chapter":"Improving the quality of training samples","heading":"Improving the quality of training samples","text":"Selecting good training samples machine learning classification satellite images critical achieving accurate results. Experience machine learning methods shown number quality training samples crucial factors obtaining accurate results [31]. Large accurate datasets preferable, regardless algorithm used, noisy training samples can negatively impact classification performance [32]. Thus, beneficial use pre-processing methods improve quality samples eliminate may incorrectly labeled possess low discriminatory power.necessary distinguish wrongly labeled samples differences resulting natural variability class signatures. working large geographic region, variability vegetation phenology leads different patterns assigned label. related issue limitation crisp boundaries describe natural world. Class definitions use idealized descriptions (e.g., “savanna woodland tree cover 50% 90% ranging 8 15 m height”). Class boundaries fuzzy sometimes overlap, making hard distinguish . improve sample quality, sits provides methods evaluating training data.Given set training samples, experts first cross-validate training set assess inherent prediction error. results show whether data internally consistent. Since cross-validation predict actual model performance, chapter provides additional tools improving quality training sets. detailed information available Chapter Validation accuracy measurements.","code":""},{"path":"improving-the-quality-of-training-samples.html","id":"datasets-used-in-this-chapter","chapter":"Improving the quality of training samples","heading":"Datasets used in this chapter","text":"examples chapter use two datasets:cerrado_2classes: set time series Cerrado region Brazil, second largest biome South America area 2 million km^2. data contains 746 samples divided 2 classes (Cerrado Pasture). time series covers 12 months (23 data points) MOD13Q1 product, 2 bands (EVI, NDVI).cerrado_2classes: set time series Cerrado region Brazil, second largest biome South America area 2 million km^2. data contains 746 samples divided 2 classes (Cerrado Pasture). time series covers 12 months (23 data points) MOD13Q1 product, 2 bands (EVI, NDVI).samples_cerrado_mod13q1: set time series Cerrado region Brazil. data ranges 2000 2017 includes 50,160 samples divided 12 classes (Dense_Woodland, Dunes, Fallow_Cotton, Millet_Cotton, Pasture, Rocky_Savanna, Savanna, Savanna_Parkland, Silviculture, Soy_Corn, Soy_Cotton, Soy_Fallow). time series covers 12 months (23 data points) MOD13Q1 product, 4 bands (EVI, NDVI, MIR, NIR). use bands NDVI EVI faster processing.samples_cerrado_mod13q1: set time series Cerrado region Brazil. data ranges 2000 2017 includes 50,160 samples divided 12 classes (Dense_Woodland, Dunes, Fallow_Cotton, Millet_Cotton, Pasture, Rocky_Savanna, Savanna, Savanna_Parkland, Silviculture, Soy_Corn, Soy_Cotton, Soy_Fallow). time series covers 12 months (23 data points) MOD13Q1 product, 4 bands (EVI, NDVI, MIR, NIR). use bands NDVI EVI faster processing.","code":"\nlibrary(sits)\nlibrary(sitsdata)\n# Take only the NDVI and EVI bands\nsamples_cerrado_mod13q1_2bands <- sits_select(\n  data = samples_cerrado_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n\n# Show the summary of the samples\nsummary(samples_cerrado_mod13q1_2bands)#> # A tibble: 12 × 3\n#>    label            count    prop\n#>    <chr>            <int>   <dbl>\n#>  1 Dense_Woodland    9966 0.199  \n#>  2 Dunes              550 0.0110 \n#>  3 Fallow_Cotton      630 0.0126 \n#>  4 Millet_Cotton      316 0.00630\n#>  5 Pasture           7206 0.144  \n#>  6 Rocky_Savanna     8005 0.160  \n#>  7 Savanna           9172 0.183  \n#>  8 Savanna_Parkland  2699 0.0538 \n#>  9 Silviculture       423 0.00843\n#> 10 Soy_Corn          4971 0.0991 \n#> 11 Soy_Cotton        4124 0.0822 \n#> 12 Soy_Fallow        2098 0.0418"},{"path":"improving-the-quality-of-training-samples.html","id":"cross-validation-of-training-sets","chapter":"Improving the quality of training samples","heading":"Cross-validation of training sets","text":"Cross-validation technique estimate inherent prediction error model [33]. Since cross-validation uses training samples, results accuracy measures unless samples carefully collected represent diversity possible occurrences classes study area [34]. practice, working large areas, hard obtain random stratified samples cover different variations land classes associated ecosystems study area. Thus, cross-validation taken measure model performance training data estimate overall map accuracy.Cross-validation uses part available samples fit classification model different part test . k-fold validation method splits data \\(k\\) partitions approximately size proceeds fitting model testing \\(k\\) times. step, take one distinct partition test remaining \\({k-1}\\) training model calculate prediction error classifying test partition. simple average gives us estimation expected prediction error. recommended choices \\(k\\) \\(5\\) \\(10\\) [33].sits_kfold_validate() supports k-fold validation sits. result confusion matrix accuracy statistics (overall class). examples , use multiprocessing speed results. parameters sits_kfold_validate :samples: training samples organized time series tibble;folds: number folds, many times split data (default = 5);ml_method: ML/DL method used validation (default = random forest);multicores: number cores used parallel processing (default = 2).show example cross-validation samples_cerrado_mod13q1 dataset.results show good validation, reaching 94% accuracy. However, accuracy guarantee good classification result. shows training data internally consistent. follows, present additional methods improving sample quality.Cross-validation measures well model fits training data. Using results measure classification accuracy valid training data good sample entire dataset. Training data subject various sources bias. land classification, classes much frequent others, training dataset imbalanced. Regional differences soil climate conditions large areas lead classes different spectral responses. Field analysts may restricted places access (e.g., along roads) collecting samples. additional problem mixed pixels. Expert interpreters select samples stand fieldwork reference images. Border pixels unlikely chosen part training data. reasons, cross-validation results measure classification accuracy entire dataset.","code":"\nrfor_validate <- sits_kfold_validate(\n  samples = samples_cerrado_mod13q1_2bands,\n  folds = 5,\n  ml_method = sits_rfor(),\n  multicores = 5\n)\nrfor_validate#> Confusion Matrix and Statistics\n#> \n#>                   Reference\n#> Prediction         Pasture Dense_Woodland Rocky_Savanna Savanna_Parkland\n#>   Pasture             6618             23             9                5\n#>   Dense_Woodland       496           9674           604                0\n#>   Rocky_Savanna          8             62          7309               27\n#>   Savanna_Parkland       4              0            50             2641\n#>   Savanna               56            200            33               26\n#>   Dunes                  0              0             0                0\n#>   Soy_Corn               9              0             0                0\n#>   Soy_Cotton             1              0             0                0\n#>   Soy_Fallow            11              0             0                0\n#>   Fallow_Cotton          3              0             0                0\n#>   Silviculture           0              7             0                0\n#>   Millet_Cotton          0              0             0                0\n#>                   Reference\n#> Prediction         Savanna Dunes Soy_Corn Soy_Cotton Soy_Fallow Fallow_Cotton\n#>   Pasture              114     0       36         12         25            41\n#>   Dense_Woodland       138     0        3          2          1             0\n#>   Rocky_Savanna          9     0        0          0          0             0\n#>   Savanna_Parkland      15     0        1          0          1             1\n#>   Savanna             8896     0        9          0          1             0\n#>   Dunes                  0   550        0          0          0             0\n#>   Soy_Corn               0     0     4851         58        355             8\n#>   Soy_Cotton             0     0       40       4041          0            19\n#>   Soy_Fallow             0     0       29          0       1710             1\n#>   Fallow_Cotton          0     0        2          3          5           555\n#>   Silviculture           0     0        0          0          0             0\n#>   Millet_Cotton          0     0        0          8          0             5\n#>                   Reference\n#> Prediction         Silviculture Millet_Cotton\n#>   Pasture                     1             1\n#>   Dense_Woodland            102             0\n#>   Rocky_Savanna               0             0\n#>   Savanna_Parkland            0             0\n#>   Savanna                     8             0\n#>   Dunes                       0             0\n#>   Soy_Corn                    0             3\n#>   Soy_Cotton                  0            21\n#>   Soy_Fallow                  0             0\n#>   Fallow_Cotton               0            20\n#>   Silviculture              312             0\n#>   Millet_Cotton               0           271\n#> \n#> Overall Statistics\n#>                             \n#>  Accuracy : 0.9455          \n#>    95% CI : (0.9435, 0.9475)\n#>                             \n#>     Kappa : 0.9365          \n#> \n#> Statistics by Class:\n#> \n#>                           Class: Pasture Class: Dense_Woodland\n#> Prod Acc (Sensitivity)            0.9184                0.9707\n#> Specificity                       0.9938                0.9665\n#> User Acc (Pos Pred Value)         0.9612                0.8779\n#> Neg Pred Value                    0.9864                0.9925\n#> F1 score                          0.9393                0.9219\n#>                           Class: Rocky_Savanna Class: Savanna_Parkland\n#> Prod Acc (Sensitivity)                  0.9131                  0.9785\n#> Specificity                             0.9975                  0.9985\n#> User Acc (Pos Pred Value)               0.9857                  0.9735\n#> Neg Pred Value                          0.9837                  0.9988\n#> F1 score                                0.9480                  0.9760\n#>                           Class: Savanna Class: Dunes Class: Soy_Corn\n#> Prod Acc (Sensitivity)            0.9699            1          0.9759\n#> Specificity                       0.9919            1          0.9904\n#> User Acc (Pos Pred Value)         0.9639            1          0.9181\n#> Neg Pred Value                    0.9933            1          0.9973\n#> F1 score                          0.9669            1          0.9461\n#>                           Class: Soy_Cotton Class: Soy_Fallow\n#> Prod Acc (Sensitivity)               0.9799            0.8151\n#> Specificity                          0.9982            0.9991\n#> User Acc (Pos Pred Value)            0.9803            0.9766\n#> Neg Pred Value                       0.9982            0.9920\n#> F1 score                             0.9801            0.8885\n#>                           Class: Fallow_Cotton Class: Silviculture\n#> Prod Acc (Sensitivity)                  0.8810              0.7376\n#> Specificity                             0.9993              0.9999\n#> User Acc (Pos Pred Value)               0.9439              0.9781\n#> Neg Pred Value                          0.9985              0.9978\n#> F1 score                                0.9113              0.8410\n#>                           Class: Millet_Cotton\n#> Prod Acc (Sensitivity)                  0.8576\n#> Specificity                             0.9997\n#> User Acc (Pos Pred Value)               0.9542\n#> Neg Pred Value                          0.9991\n#> F1 score                                0.9033"},{"path":"improving-the-quality-of-training-samples.html","id":"hierarchical-clustering-for-sample-quality-control","chapter":"Improving the quality of training samples","heading":"Hierarchical clustering for sample quality control","text":"package provides two clustering methods assess sample quality: Agglomerative Hierarchical Clustering (AHC) Self-organizing Maps (SOM). methods different computational complexities. AHC computational complexity \\(\\mathcal{O}(n^2)\\), given number time series \\(n\\), whereas SOM complexity linear. large data, AHC requires substantial memory running time; cases, SOM recommended. section describes run AHC sits. SOM-based technique presented next section.AHC computes dissimilarity two elements dataset. Depending distance functions linkage criteria, algorithm decides two clusters merged iteration. approach helpful exploring samples due visualization power ease use [35]. sits, AHC implemented using sits_cluster_dendro().\nFigure 55: Example hierarchical clustering two class set time series (source: authors).\nsits_cluster_dendro() function one mandatory parameter (samples), samples evaluated. Optional parameters include bands, dist_method, linkage. dist_method parameter specifies calculate distance two time series. recommend metric uses dynamic time warping (DTW) [36], DTW reliable method measuring differences satellite image time series [37]. options available sits based provided package dtwclust, include dtw_basic, dtw_lb, dtw2. Please check ?dtwclust::tsclust information DTW distances.linkage parameter defines distance metric clusters. recommended linkage criteria : complete ward.D2. Complete linkage prioritizes within-cluster dissimilarities, producing clusters shorter distance samples, results sensitive outliers. alternative, Ward proposes use sum--squares error minimize data variance [38]; method available ward.D2 option linkage parameter. cut dendrogram, sits_cluster_dendro() function computes adjusted rand index (ARI) [39], returning height cut dendrogram maximizes index. example, ARI index indicates six clusters. result sits_cluster_dendro() time series tibble one additional column called “cluster”. function sits_cluster_frequency() provides information composition cluster.cluster frequency table shows cluster predominance either Cerrado Pasture labels, except cluster 3, mix samples labels. confusion may resulted incorrect labeling, inadequacy selected bands spatial resolution, even natural confusion due variability land classes. remove cluster 3, use dplyr::filter(). resulting clusters still contain mixed labels, possibly resulting outliers. case, sits_cluster_clean() removes outliers, leaving frequent label. cleaning samples, resulting set samples likely improve classification results.","code":"\n# Take a set of patterns for 2 classes\n# Create a dendrogram, plot, and get the optimal cluster based on ARI index\nclusters <- sits_cluster_dendro(\n  samples = cerrado_2classes,\n  bands = c(\"NDVI\", \"EVI\"),\n  dist_method = \"dtw_basic\",\n  linkage = \"ward.D2\"\n)\n# Show clusters samples frequency\nsits_cluster_frequency(clusters)#>          \n#>             1   2   3   4   5   6 Total\n#>   Cerrado 203  13  23  80   1  80   400\n#>   Pasture   2 176  28   0 140   0   346\n#>   Total   205 189  51  80 141  80   746\n# Remove cluster 3 from the samples\nclusters_new <- dplyr::filter(clusters, cluster != 3)\n# Clear clusters, leaving only the majority label\nclean <- sits_cluster_clean(clusters_new)\n# Show clusters samples frequency\nsits_cluster_frequency(clean)#>          \n#>             1   2   4   5   6 Total\n#>   Cerrado 203   0  80   0  80   363\n#>   Pasture   0 176   0 140   0   316\n#>   Total   203 176  80 140  80   679"},{"path":"improving-the-quality-of-training-samples.html","id":"using-som-for-sample-quality-control","chapter":"Improving the quality of training samples","heading":"Using SOM for sample quality control","text":"sits provides clustering technique based self-organizing maps (SOM) alternative hierarchical clustering quality control training samples. SOM dimensionality reduction technique [40], high-dimensional data mapped two-dimensional map, keeping topological relations data patterns. shown Figure 56, SOM 2D map composed units called neurons. neuron weight vector, dimension training samples. start, neurons assigned small random value trained competitive learning. algorithm computes distances member training set neurons finds neuron closest input, called best matching unit.\nFigure 56: SOM 2D map creation (Source: Santos et al. (2021). Reproduction fair use doctrine).\ninput data quality assessment set training samples, high-dimensional data; example, time series 25 instances 4 spectral bands 100 dimensions. projecting high-dimensional dataset 2D SOM map, units map (called neurons) compete sample. time series mapped one neurons. Since number neurons smaller number classes, neuron associated many time series. resulting 2D map set clusters. Given SOM preserves topological structure neighborhoods multiple dimensions, clusters contain training samples given label usually neighbors 2D space. neighbors neuron SOM map provide information intraclass interclass variability, used detect noisy samples. methodology using SOM sample quality assessment discussed detail reference paper [41].\nFigure 57: Using SOM class noise reduction (Source: Santos et al. (2021). Reproduction fair use doctrine).\n","code":""},{"path":"improving-the-quality-of-training-samples.html","id":"creating-the-som-map","chapter":"Improving the quality of training samples","heading":"Creating the SOM map","text":"perform SOM-based quality assessment, first step run sits_som_map(), uses kohonen R package compute SOM grid [42], controlled five parameters. grid size given grid_xdim grid_ydim. starting learning rate alpha, decreases interactions. measure separation samples, use distance (either “dtw” “euclidean”). number iterations set rlen. using sits_som_map() machines multiprocessing support OpenMP protocol, setting laerning mode parameter mode “patch” improves processing time. MacOS Windows, please use “online”.suggest using Dynamic Time Warping (“dtw”) metric distance measure. technique used measure similarity two temporal sequences may vary speed timing [43]. core idea DTW find optimal alignment two sequences allowing non-linear mapping one sequence onto another. time series analysis, DTW matches two series slightly sync. property useful land use studies matching time series agricultural areas [44].\nFigure 58: SOM map Cerrado samples (source: authors).\noutput sits_som_map() list three elements: () data, original set time series two additional columns time series: id_sample (original id sample) id_neuron (id neuron belongs); (b) labelled_neurons, tibble information neurons. neuron, gives prior posterior probabilities labels occur samples assigned ; (c) SOM grid. plot SOM grid, use plot(). neurons labelled using majority voting.SOM grid shows classes associated neurons close , although exceptions. Pasture neurons far main cluster transition open savanna pasture areas always well defined depends climate latitude. Also, neurons associated Soy_Fallow dispersed map, indicating possible problems distinguishing class agricultural classes. SOM map can used remove outliers, shown .","code":"\n# Clustering time series using SOM\nsom_cluster <- sits_som_map(samples_cerrado_mod13q1_2bands,\n  grid_xdim = 15,\n  grid_ydim = 15,\n  alpha = 1.0,\n  distance = \"dtw\",\n  rlen = 20\n)\n# Plot the SOM map\nplot(som_cluster)"},{"path":"improving-the-quality-of-training-samples.html","id":"measuring-confusion-between-labels-using-som","chapter":"Improving the quality of training samples","heading":"Measuring confusion between labels using SOM","text":"second step SOM-based quality assessment understanding confusion labels. function sits_som_evaluate_cluster() groups neurons majority label produces tibble. Neurons grouped clusters, many clusters labels. results shows percentage samples label cluster. Ideally, samples cluster label. practice, cluster contain samples different label. information helps measuring confusion samples.Many labels associated clusters samples different label. confusion labels arises sample labeling subjective can biased. many cases, interpreters use high-resolution data identify samples. However, actual images classified captured satellites lower resolution. case study, MOD13Q1 image pixels 250 m resolution. , correspondence labeled locations high-resolution images mid low-resolution images direct. confusion sample label can visualized bar plot using plot(), shown . bar plot shows confusion labels associated natural vegetation typical Brazilian Cerrado (Savanna, Savanna_Parkland, Rocky_Savanna). mixture due large variability natural vegetation Cerrado biome, makes difficult draw sharp boundaries classes. confusion also visible agricultural classes. Millet_Cotton class particularly difficult one since many samples assigned class confused Soy_Cotton Fallow_Cotton.\nFigure 59: Confusion classes measured SOM (source: authors).\n","code":"\n# Produce a tibble with a summary of the mixed labels\nsom_eval <- sits_som_evaluate_cluster(som_cluster)\n# Show the result\nsom_eval#> # A tibble: 66 × 4\n#>    id_cluster cluster        class          mixture_percentage\n#>         <int> <chr>          <chr>                       <dbl>\n#>  1          1 Dense_Woodland Dense_Woodland            78.1   \n#>  2          1 Dense_Woodland Pasture                    5.56  \n#>  3          1 Dense_Woodland Rocky_Savanna              8.95  \n#>  4          1 Dense_Woodland Savanna                    3.88  \n#>  5          1 Dense_Woodland Silviculture               3.48  \n#>  6          1 Dense_Woodland Soy_Corn                   0.0249\n#>  7          2 Dunes          Dunes                    100     \n#>  8          3 Fallow_Cotton  Dense_Woodland             0.169 \n#>  9          3 Fallow_Cotton  Fallow_Cotton             49.5   \n#> 10          3 Fallow_Cotton  Millet_Cotton             13.9   \n#> # ℹ 56 more rows\n# Plot the confusion between clusters\nplot(som_eval)"},{"path":"improving-the-quality-of-training-samples.html","id":"detecting-noisy-samples-using-som","chapter":"Improving the quality of training samples","heading":"Detecting noisy samples using SOM","text":"third step quality assessment uses discrete probability distribution associated neuron, included labeled_neurons tibble produced sits_som_map(). approach associates probabilities frequency occurrence. homogeneous neurons (one label high frequency) assumed composed good quality samples. Heterogeneous neurons (two classes significant frequencies) likely contain noisy samples. algorithm computes two values sample:prior probability: probability label assigned sample correct, considering frequency samples neuron. example, neuron 20 samples, 15 labeled Pasture 5 Forest, samples labeled Forest assigned prior probability 25%. indicates Forest samples neuron may good quality.prior probability: probability label assigned sample correct, considering frequency samples neuron. example, neuron 20 samples, 15 labeled Pasture 5 Forest, samples labeled Forest assigned prior probability 25%. indicates Forest samples neuron may good quality.posterior probability: probability label assigned sample correct, considering neighboring neurons. Take case -mentioned neuron whose samples labeled Pasture prior probability 75%. happens neighboring neurons Forest majority label? answer question, use Bayesian inference estimate samples noisy based surrounding neurons [45].posterior probability: probability label assigned sample correct, considering neighboring neurons. Take case -mentioned neuron whose samples labeled Pasture prior probability 75%. happens neighboring neurons Forest majority label? answer question, use Bayesian inference estimate samples noisy based surrounding neurons [45].identify noisy samples, take result sits_som_map() function first argument function sits_som_clean_samples(). function finds samples noisy, clean, need examined user. requires prior_threshold posterior_threshold parameters according following rules:prior probability sample less prior_threshold, sample assumed noisy tagged “remove”;prior probability greater equal prior_threshold posterior probability calculated Bayesian inference greater equal posterior_threshold, sample assumed noisy thus tagged “clean”;prior probability greater equal prior_threshold posterior probability less posterior_threshold, situation sample part majority level assigned neuron, label consistent neighbors. anomalous condition tagged “analyze”. Users encouraged inspect samples find whether fact noisy .default value prior_threshold posterior_threshold 60%. sits_som_clean_samples() additional parameter (keep), indicates samples kept set based prior posterior probabilities. default keep c(\"clean\", \"analyze\"). result cleaning, 900 samples considered noisy thus removed.samples class highest confusion others(Millet_Cotton) removed. samples class Silviculture (planted forests) also removed since confused natural forests woodlands SOM map. analysis includes calculating SOM map confusion matrix new set, shown following example.\nFigure 60: Cluster confusion plot samples cleaned SOM (source: authors).\nexpected, new confusion map shows significant improvement previous one. result interpreted carefully since may due different effects. direct interpretation Millet_Cotton Silviculture easily separated classes, given current attributes (time series NDVI EVI indices MODIS images). situations, users consider improving number samples less represented classes, including MODIS bands, working higher resolution satellites. results SOM method interpreted based users’ understanding ecosystems agricultural practices study region.SOM-based analysis discards samples can confused samples classes. removing noisy samples uncertain classes, dataset obtains better validation score since less confusion classes. Users analyse results care. discarded samples low-quality ones. Confusion samples different classes can result inconsistent labeling lack capacity satellite data distinguish chosen classes. many samples discarded, current example, revising whole classification schema advisable. aim selecting training data always match reality ground power remote sensing data identify differences. analysis procedure can replace actual user experience knowledge study region.","code":"\nnew_samples <- sits_som_clean_samples(\n  som_map = som_cluster,\n  prior_threshold = 0.6,\n  posterior_threshold = 0.6,\n  keep = c(\"clean\", \"analyze\")\n)\n# Print the new sample distribution\nsummary(new_samples)#> # A tibble: 9 × 3\n#>   label            count   prop\n#>   <chr>            <int>  <dbl>\n#> 1 Dense_Woodland    8519 0.220 \n#> 2 Dunes              550 0.0142\n#> 3 Pasture           5509 0.142 \n#> 4 Rocky_Savanna     5508 0.142 \n#> 5 Savanna           7651 0.197 \n#> 6 Savanna_Parkland  1619 0.0418\n#> 7 Soy_Corn          4595 0.119 \n#> 8 Soy_Cotton        3515 0.0907\n#> 9 Soy_Fallow        1309 0.0338\n# Evaluate the mixture in the SOM clusters of new samples\nnew_cluster <- sits_som_map(\n  data = new_samples,\n  grid_xdim = 15,\n  grid_ydim = 15,\n  alpha = 1.0,\n  rlen = 20,\n  distance = \"dtw\"\n)\nnew_cluster_mixture <- sits_som_evaluate_cluster(new_cluster)\n# Plot the mixture information.\nplot(new_cluster_mixture)"},{"path":"improving-the-quality-of-training-samples.html","id":"reducing-sample-imbalance","chapter":"Improving the quality of training samples","heading":"Reducing sample imbalance","text":"Many training samples Earth observation data analysis imbalanced. situation arises distribution samples associated label uneven. One example Cerrado dataset used Chapter. three frequent labels (Dense Woodland, Savanna, Pasture) include 53% samples, three least frequent labels (Millet-Cotton, Silviculture, Dunes) comprise 2.5% dataset. Sample imbalance undesirable property training set since machine learning algorithms tend accurate classes many samples. instances belonging minority group misclassified often belonging majority group. Thus, reducing sample imbalance can positively affect classification accuracy [46].function sits_reduce_imbalance() deals training set imbalance; increases number samples least frequent labels, reduces number samples frequent labels. Oversampling requires generating synthetic samples. package uses SMOTE method estimates new samples considering cluster formed nearest neighbors minority label. SMOTE takes two samples cluster produces new one randomly interpolating [47].perform undersampling, sits_reduce_imbalance() builds SOM map majority label based required number samples selected. dimension SOM set ceiling(sqrt(new_number_samples/4)) allow reasonable number neurons group similar samples. calculating SOM map, algorithm extracts four samples per neuron generate reduced set samples approximates variation original one.sits_reduce_imbalance() algorithm two parameters: n_samples_over n_samples_under. first parameter indicates minimum number samples per class. classes samples less value oversampled. second parameter controls maximum number samples per class; classes samples value undersampled. following example uses sits_reduce_imbalance() Cerrado samples. generate balanced dataset classes minimum 1000 maximum 1500 samples. use sits_som_evaluate_cluster() estimate confusion classes balanced dataset.\nFigure 61: Confusion cluster balanced dataset (source: authors).\nshown Figure 61, balanced dataset shows less confusion per label unbalanced one. case, many classes confused others original confusion map now better represented. Reducing sample imbalance tried alternative reducing number samples classes using SOM. general, users balance training data better performance.","code":"\n# Reducing imbalances in the Cerrado dataset\nbalanced_samples <- sits_reduce_imbalance(\n  samples = samples_cerrado_mod13q1_2bands,\n  n_samples_over = 1000,\n  n_samples_under = 1500,\n  multicores = 4\n)\n# Print the balanced samples\n# Some classes have more than 1500 samples due to the SOM map\n# Each label has between 10% and 6% of the full set\nsummary(balanced_samples)#> # A tibble: 12 × 3\n#>    label            count   prop\n#>    <chr>            <int>  <dbl>\n#>  1 Dense_Woodland    1596 0.0974\n#>  2 Dunes             1000 0.0610\n#>  3 Fallow_Cotton     1000 0.0610\n#>  4 Millet_Cotton     1000 0.0610\n#>  5 Pasture           1592 0.0971\n#>  6 Rocky_Savanna     1476 0.0901\n#>  7 Savanna           1600 0.0976\n#>  8 Savanna_Parkland  1564 0.0954\n#>  9 Silviculture      1000 0.0610\n#> 10 Soy_Corn          1588 0.0969\n#> 11 Soy_Cotton        1568 0.0957\n#> 12 Soy_Fallow        1404 0.0857\n# Clustering time series using SOM\nsom_cluster_bal <- sits_som_map(\n  data = balanced_samples,\n  grid_xdim = 15,\n  grid_ydim = 15,\n  alpha = 1.0,\n  distance = \"dtw\",\n  rlen = 20,\n  mode = \"pbatch\"\n)\n# Produce a tibble with a summary of the mixed labels\nsom_eval <- sits_som_evaluate_cluster(som_cluster_bal)\n# Show the result\nplot(som_eval)"},{"path":"improving-the-quality-of-training-samples.html","id":"conclusion","chapter":"Improving the quality of training samples","heading":"Conclusion","text":"quality training data critical improving accuracy maps resulting machine learning classification methods. address challenge, sits package provides three methods improving training samples. large datasets, recommend using imbalance-reducing SOM-based algorithms. SOM-based method identifies potential mislabeled samples outliers require investigation. results demonstrate positive impact overall classification accuracy.complexity diversity planet defy simple label names hard boundaries. Due representational data handling issues, classification systems limited number categories, inevitably fail adequately describe nuances planet’s landscapes. representation systems thus limited application-dependent. stated Janowicz [48]: “geographical concepts situated context-dependent can described different, equally valid, points view; thus, ontological commitments arbitrary large extent”.availability big data satellite image time series challenge. principle, image time series can capture subtle changes land classification. Experts must conceive classification systems training data collections understanding time series information relates actual land change. Methods quality analysis, presented Chapter, replace user understanding informed choices.","code":""},{"path":"machine-learning-for-data-cubes.html","id":"machine-learning-for-data-cubes","chapter":"Machine learning for data cubes","heading":"Machine learning for data cubes","text":"","code":""},{"path":"machine-learning-for-data-cubes.html","id":"machine-learning-classification","chapter":"Machine learning for data cubes","heading":"Machine learning classification","text":"Machine learning classification type supervised learning algorithm trained predict class input data point belongs . goal machine learning models approximate function \\(y = f(x)\\) maps input \\(x\\) class \\(y\\). model defines mapping \\(y = f(x;\\theta)\\) learns value parameters \\(\\theta\\) result best function approximation [49]. difference different algorithms approach building mapping classifies input data.\nsits, machine learning used classify individual time series using time-first approach. package includes two kinds methods time series classification:Machine learning algorithms explicitly consider temporal structure time series. treat time series vector high-dimensional feature space, taking time series instance independent others. include random forest (sits_rfor()), support vector machine (sits_svm()), extreme gradient boosting (sits_xgboost()), multilayer perceptron (sits_mlp()).Machine learning algorithms explicitly consider temporal structure time series. treat time series vector high-dimensional feature space, taking time series instance independent others. include random forest (sits_rfor()), support vector machine (sits_svm()), extreme gradient boosting (sits_xgboost()), multilayer perceptron (sits_mlp()).Deep learning methods temporal relations observed values time series taken account. models specifically designed time series. temporal order values time series relevant classification model. class models, sits supports 1D convolution neural networks (sits_tempcnn()) temporal attention-based encoders (sits_tae() sits_lighttae()).Deep learning methods temporal relations observed values time series taken account. models specifically designed time series. temporal order values time series relevant classification model. class models, sits supports 1D convolution neural networks (sits_tempcnn()) temporal attention-based encoders (sits_tae() sits_lighttae()).Based experience sits, random forest, extreme gradient boosting, temporal deep learning models outperform SVM multilayer perceptron models. reason dates provide information others temporal behavior land classes. instance, monitoring deforestation, dates corresponding forest removal actions informative earlier later dates. Similarly, dates may capture large portion variation crop mapping. Therefore, classification methods consider temporal order samples likely capture seasonal behavior image time series. Random forest extreme gradient boosting methods use individual measures nodes decision trees can also capture specific events deforestation.following examples show train machine learning methods apply classify single time series. use set samples_matogrosso_mod13q1, containing time series samples Brazilian Mato Grosso state obtained MODIS MOD13Q1 product. 1,892 samples nine classes (Cerrado, Forest, Pasture, Soy_Corn, Soy_Cotton, Soy_Fallow, Soy_Millet). time series covers 12 months (23 data points) six bands (NDVI, EVI, BLUE, RED, NIR, MIR). samples arranged along agricultural year, starting September ending August. dataset used paper “Big Earth observation time series analysis monitoring Brazilian agriculture” [50], available R package sitsdata.","code":""},{"path":"machine-learning-for-data-cubes.html","id":"common-interface-to-machine-learning-and-deep-learning-models","chapter":"Machine learning for data cubes","heading":"Common interface to machine learning and deep learning models","text":"sits_train() function provides standard interface machine learning models. function takes two mandatory parameters: training data (samples) ML algorithm (ml_method). model estimated, can classify individual time series data cubes sits_classify(). follows, show apply method classify single time series. , Chapter Image classification data cubes, discuss classify data cubes.Since sits aimed remote sensing users machine learning experts, provides set default values classification models. settings chosen based testing authors. Nevertheless, users can control parameters model. Novice users can rely default values, experienced ones can fine-tune model parameters meet needs. Model tuning discussed end Chapter.set time series organized tibble taken input classifier, result tibble one additional column (predicted), contains information labels assigned interval. results can shown text format using function sits_show_prediction() graphically using plot().","code":""},{"path":"machine-learning-for-data-cubes.html","id":"random-forest","chapter":"Machine learning for data cubes","heading":"Random forest","text":"Random forest machine learning algorithm uses ensemble learning method classification tasks. algorithm consists multiple decision trees, trained different subset training data different subset features. make prediction, decision tree forest independently classifies input data. final prediction made based majority vote decision trees. randomness algorithm comes random subsets data features used train decision tree, helps reduce overfitting improve accuracy model. classifier measures importance feature classification task, can helpful feature selection data visualization. -depth discussion robustness random forest method satellite image time series classification, please see Pelletier et al [51].\nFigure 62: Random forest algorithm (Source: Venkata Jagannath Wikipedia - licenced CC--SA 4.0).\nsits provides sits_rfor(), uses R randomForest package [52]; main parameter num_trees, number trees grow default value 100. model can visualized using plot().\nFigure 63: important variables random forest model (source: authors).\nimportant explanatory variables NIR (near infrared) band date 17 (2007-05-25) MIR (middle infrared) band date 22 (2007-08-13). NIR value end May captures growth second crop double cropping classes. Values MIR band end period (late July late August) capture bare soil signatures distinguish agricultural natural classes. corresponds summertime ground drier harvesting crops.\nFigure 64: Classification time series using random forest (source: authors).\nresult shows area started forest 2000, deforested 2004 2005, used pasture 2006 2007, double-cropping agriculture 2009 onwards. behavior consistent expert evaluation land change process region Amazonia.Random forest robust outliers can deal irrelevant inputs [33]. method tends overemphasize variables performance tends stabilize part trees grown [33]. cases abrupt change occurs, deforestation mapping, random forest (properly trained) emphasize temporal instances bands capture quick change.","code":"\n# Train the Mato Grosso samples with random forest model\nrfor_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_rfor(num_trees = 100)\n)\n# Plot the most important variables of the model\nplot(rfor_model)\n# Classify using random forest model and plot the result\npoint_class <- sits_classify(\n  data = point_mt_mod13q1,\n  ml_model = rfor_model\n)\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))\nknitr::include_graphics(\"./images/mlrforplot.png\")"},{"path":"machine-learning-for-data-cubes.html","id":"support-vector-machine","chapter":"Machine learning for data cubes","heading":"Support vector machine","text":"support vector machine (SVM) classifier generalization linear classifier finds optimal separation hyperplane minimizes misclassification [53]. Since set samples \\(n\\) features defines n-dimensional feature space, hyperplanes linear \\({(n-1)}\\)-dimensional boundaries define linear partitions space. classes linearly separable feature space, optimal solution defined maximal margin hyperplane, separating hyperplane farthest training observations [54]. maximal margin computed smallest distance observations hyperplane. solution hyperplane coefficients depends samples define maximum margin criteria, -called support vectors.\nFigure 65: Maximum-margin hyperplane margins SVM trained samples two classes. Samples margin called support vectors. (Source: Larhmam Wikipedia - licensed CC--SA-4.0).\ndata linearly separable, SVM includes kernel functions map original feature space higher dimensional space, providing nonlinear boundaries original feature space. Despite linear boundary enlarged feature space, new classification model generally translates hyperplane nonlinear boundary original attribute space. Kernels efficient computational strategy produce nonlinear boundaries input attribute space; thus, improve training-class separation. SVM one widely used algorithms machine learning applications applied classify remote sensing data [55].sits, SVM implemented wrapper e1071 R package uses LIBSVM implementation [56]. sits package adopts one--one method multiclass classification. \\(q\\) class problem, method creates \\({q(q-1)/2}\\) SVM binary models, one class pair combination, testing unknown input vectors throughout models. voting scheme computes overall result.example shows apply SVM classify time series using default values. main parameters kernel, controls whether use nonlinear transformation (default radial), cost, measures punishment wrongly-classified samples (default 10), cross, sets value k-fold cross validation (default 10).\nFigure 66: Classification time series using SVM (source: authors).\nSVM classifier less stable less robust outliers random forest method. example, tends misclassify data. 2008, likely correct land class still Pasture rather Soy_Millet produced algorithm, Soy_Cotton class 2012 also inconsistent previous latter classification Soy_Corn.","code":"\n# Train an SVM model\nsvm_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_svm()\n)\n# Classify using the SVM model and plot the result\npoint_class <- sits_classify(\n  data = point_mt_mod13q1,\n  ml_model = svm_model\n)\n# Plot the result\nplot(point_class, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"extreme-gradient-boosting","chapter":"Machine learning for data cubes","heading":"Extreme gradient boosting","text":"XGBoost (eXtreme Gradient Boosting) [57] implementation gradient boosted decision trees designed speed performance. ensemble learning method, meaning combines predictions multiple models produce final prediction. XGBoost builds trees one time, new tree helps correct errors made previously trained tree. tree builds new model correct errors made previous models. Using gradient descent, algorithm iteratively adjusts predictions tree focusing instances previous trees made errors. Models added sequentially improvements can made.Although random forest boosting use trees classification, significant differences. random forest builds multiple decision trees parallel merges together accurate stable prediction, XGBoost builds trees one time, new tree helps correct errors made previously trained tree. XGBoost often preferred speed performance, particularly large datasets, well-suited problems precision paramount. Random Forest, hand, simpler implement, interpretable, can robust overfitting, making good choice general-purpose applications.\nFigure 67: Flow chart XGBoost algorithm (Source: Guo et al., Applied Sciences, 2020. - licenced CC--SA 4.0).\nboosting method starts weak predictor improves performance sequentially fitting better model iteration. fits simple classifier training data uses residuals fit build predictor. Typically, base classifier regression tree. Although random forest boosting use trees classification, significant differences. performance random forest generally increases number trees becomes stable. Boosting trees apply finer divisions previous results improve performance [33]. recent papers show outperforms random forest remote sensing image classification [58]. However, result generalizable since quality training dataset controls actual performance.sits, XGBoost method implemented sits_xbgoost() function, based XGBoost R package, five hyperparameters require tuning. sits_xbgoost() function takes user choices input cross-validation determine suitable values predictor.learning rate eta varies 0.0 1.0 kept small (default 0.3) avoid overfitting. minimum loss value gamma specifies minimum reduction required make split. default 0; increasing makes algorithm conservative. max_depth value controls maximum depth trees. Increasing value make model complex likely overfit (default 6). subsample parameter controls percentage samples supplied tree. default 1 (maximum). Setting lower values means xgboost randomly collects part data instances grow trees, thus preventing overfitting. nrounds parameter controls maximum number boosting interactions; default 100, proven enough cases. follow convergence algorithm, users can turn verbose parameter . general, results using extreme gradient boosting algorithm similar random forest method.\nFigure 68: Classification time series using XGBoost (source: authors).\n","code":"\n# Train using  XGBoost\nxgb_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_xgboost(verbose = 0)\n)\n# Classify using SVM model and plot the result\npoint_class_xgb <- sits_classify(\n  data = point_mt_mod13q1,\n  ml_model = xgb_model\n)\nplot(point_class_xgb, bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"deep-learning-using-multilayer-perceptron","chapter":"Machine learning for data cubes","heading":"Deep learning using multilayer perceptron","text":"support deep learning methods, sits uses torch R package, takes Facebook torch C++ library back-end. Machine learning algorithms use R torch package similar developed using PyTorch. simplest deep learning method multilayer perceptron (MLP), feedforward artificial neural networks. MLP consists three kinds nodes: input layer, set hidden layers, output layer. input layer dimension number features dataset. hidden layers attempt approximate best classification function. output layer decides class assigned input.sits, MLP models can built using sits_mlp(). Since established model generic classification satellite image time series, designing MLP models requires parameter customization. important decisions number layers model number neurons per layer. values set layers parameter, list integer values. size list number layers, element indicates number nodes per layer.choice number layers depends inherent separability dataset classified. datasets classes different signatures, shallow model (three layers) may provide appropriate responses. complex situations require models deeper hierarchy. Models many hidden layers may take long time train may converge. suggest start three layers test different options number neurons per layer increasing number layers. experience, using three five layers reasonable compromise training data good quality. increase number layers improve model.MLP models also need include activation function. activation function node defines output node given input set inputs. Following standard practices [49], use relu activation function.optimization method (optimizer) represents gradient descent algorithm used. methods aim maximize objective function updating parameters opposite direction gradient objective function [59]. Since gradient descent plays key role deep learning model fitting, developing optimizers important topic research [60]. Many optimizers proposed literature, recent results reviewed Schmidt et al. [61]. Adamw optimizer provides good baseline reliable performance general deep learning applications [62]. default, deep learning algorithms sits use Adamw.Another relevant parameter list dropout rates (dropout). Dropout technique randomly dropping units neural network training [63]. randomly discarding neurons, dropout reduces overfitting. Since cascade neural nets aims improve learning data acquired, discarding neurons may seem like waste resources. practice, dropout prevents early convergence local minimum [49]. suggest users experiment different dropout rates, starting small values (10-30%) increasing required.following example shows use sits_mlp(). default parameters chosen based modified version [64], proposes using multilayer perceptron baseline time series classification. parameters : () Three layers 512 neurons , specified parameter layers; (b) Using “relu” activation function; (c) dropout rates 40%, 30%, 20% layers; (d) “optimizer_adamw” optimizer (default value); (e) number training steps (epochs) 100; (f) batch_size 64, indicates many time series used input given step; (g) validation percentage 20%, means 20% samples randomly set aside validation.simplify output, verbose option turned . model generated, plot training history.\nFigure 69: Evolution training accuracy MLP model (source: authors).\n, classify 16-year time series using multilayer perceptron model.\nFigure 70: Classification time series using MLP (source: authors).\ntheory, multilayer perceptron model can capture subtle changes random forest XGBoost specific case, result similar . Although model mixes Soy_Corn Soy_Millet classes, distinction temporal signatures quite subtle. Also, case, suggests need improve number samples. example, MLP model shows increase sensitivity compared previous models. recommend compare different configurations since MLP model sensitive changes parameters.","code":"\n# Train using an MLP model\n# This is an example of how to set parameters\n# First-time users should test default options first\nmlp_model <- sits_train(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_mlp(\n    optimizer        = torch::optim_adamw,\n    layers           = c(512, 512, 512),\n    dropout_rates    = c(0.40, 0.30, 0.20),\n    epochs           = 80,\n    batch_size       = 64,\n    verbose          = FALSE,\n    validation_split = 0.2\n  )\n)\n# Show training evolution\nplot(mlp_model)\n# Classify using MLP model and plot the result\npoint_mt_mod13q1 |>\n  sits_classify(mlp_model) |>\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"temporal-convolutional-neural-network-tempcnn","chapter":"Machine learning for data cubes","heading":"Temporal Convolutional Neural Network (TempCNN)","text":"Convolutional neural networks (CNN) deep learning methods apply convolution filters (sliding windows) input data sequentially. Temporal Convolutional Neural Network (TempCNN) neural network architecture specifically designed process sequential data time series. case time series, 1D CNN applies moving temporal window time series produce another time series result convolution.TempCNN architecture satellite image time series classification proposed Pelletier et al. [65]. three 1D convolutional layers final softmax layer classification (see Figure 71). authors combine different methods avoid overfitting reduce vanishing gradient effect, including dropout, regularization, batch normalization. TempCNN reference paper [65], authors favourably compare model Recurrent Neural Network proposed Russwurm Körner [66]. Figure 71 shows architecture TempCNN model. TempCNN applies one-dimensional convolutions input sequence capture temporal dependencies, allowing network learn long-term dependencies input sequence. layer model captures temporal dependencies different scale. Due multi-scale approach, TempCNN can capture complex temporal patterns data produce accurate predictions.\nFigure 71: Structure tempCNN architecture (Source: Pelletier et al. (2019). Reproduction fair use doctrine).\nfunction sits_tempcnn() implements model. first parameter optimizer used backpropagation phase gradient descent. default adamw considered stable reliable optimization function. parameter cnn_layers controls number 1D-CNN layers size filters applied layer; default values three CNNs 128 units. parameter cnn_kernels indicates size convolution kernels; default kernels size 7. Activation 1D-CNN layers uses “relu” function. dropout rates 1D-CNN layer controlled individually parameter cnn_dropout_rates. validation_split controls size test set relative full dataset. recommend setting aside least 20% samples validation.\nFigure 72: Training evolution TempCNN model (source: authors).\nUsing TempCNN model, classify 16-year time series.\nFigure 73: Classification time series using TempCNN (source: authors).\n\nFigure 74: Classification time series using TempCNN (source: authors).\nresult important differences previous ones. TempCNN model indicates Soy_Cotton class likely one 2004. result possibly wrong, shows time series 2004 different Forest Pasture classes. One possible explanation forest degradation 2004, leading signature mix forest bare soil. case, including forest degradation samples improve training data. experience, TempCNN models reliable way classifying image time series [67]. Recent work compares different models also provides evidence TempCNN models satisfactory behavior, especially case crop classes [68].","code":"\nlibrary(torchopt)\n# Train using tempCNN\ntempcnn_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_tempcnn(\n    optimizer            = torch::optim_adamw,\n    cnn_layers           = c(256, 256, 256),\n    cnn_kernels          = c(7, 7, 7),\n    cnn_dropout_rates    = c(0.2, 0.2, 0.2),\n    epochs               = 80,\n    batch_size           = 64,\n    validation_split     = 0.2,\n    verbose              = FALSE\n  )\n)\n# Show training evolution\nplot(tempcnn_model)\n# Classify using TempCNN model and plot the result\npoint_mt_mod13q1 |>\n  sits_classify(tempcnn_model) |>\n  plot(bands = c(\"NDVI\", \"EVI\"))\nknitr::include_graphics(\"./images/mltcnnplot.png\")"},{"path":"machine-learning-for-data-cubes.html","id":"attention-based-models","chapter":"Machine learning for data cubes","heading":"Attention-based models","text":"Attention-based deep learning models class models use mechanism inspired human attention focus specific parts input processing. models shown effective various tasks machine translation, image captioning, speech recognition.basic idea behind attention-based models allow model selectively focus different input parts different times. can done introducing mechanism assigns weights element input, indicating relative importance element current processing step. model can use compute weighted sum input. results capture model’s attention specific parts input.Attention-based models become one used deep learning architectures problems involve sequential data inputs, e.g., text recognition automatic translation. general idea inputs alike applications language translation. Consider English sentence “Look lonely people”. sound translation system needs relate words “look” “people” key parts sentence ensure link captured translation. specific type attention models, called transformers, enables recognition complex relationships input output sequences [69].basic structure transformers neural network algorithms. encoder transforms textual input values numerical vectors decoder processes vectors provide suitable answers. difference values handled internally. MLP, inputs treated equally first; based iterative matching training test data, backpropagation technique feeds information back initial layers identify suitable combination inputs produces best output.Convolutional nets (CNN) combine input values close time (1D) space (2D) produce higher-level information helps distinguish different components input data. text recognition, initial choice deep learning studies use recurrent neural networks (RNN) handle input sequences.However, neither MLPs, CNNs, RNNs able capture structure complex inputs natural language. success transformer-based solutions accounts substantial improvements natural language processing.two main differences transformer models algorithms positional encoding self-attention. Positional encoding assigns index input value, ensuring relative locations inputs maintained throughout learning processing phases. Self-attention compares every word sentence every word sentence, including . way, learns contextual information relation words. conception validated large language models BERT [70] GPT-3 [71].application attention-based models satellite image time series analysis proposed Garnot et al. [72] Russwurm Körner [68]. self-attention network can learn focus specific time steps image features relevant distinguishing different classes. algorithm tries identify combination individual temporal observations relevant identify class. example, crop identification use observations capture onset growing season, date maximum growth, end growing season. case deforestation, algorithm tries identify dates forest cut. Attention-based models means identify events characterize land class.first model proposed Garnot et al. full transformer-based model [72]. Considering image time series classification easier natural language processing, Garnot et al. also propose simplified version full transformer model [73]. simpler model uses reduced way compute attention matrix, reducing time training classification without loss quality result.sits, full transformer-based model proposed Garnot et al. [72] implemented using sits_tae(). default parameters proposed authors. default optimizer optim_adamw, also used sits_tempcnn() function.\nFigure 75: Training evolution Temporal Self-Attention model (source: authors).\n, classify 16-year time series using TAE model.\nFigure 76: Classification time series using TAE (source: authors).\nGarnot co-authors also proposed Lightweight Temporal Self-Attention Encoder (LTAE) [73], authors claim can achieve high classification accuracy fewer parameters compared neural network models. good choice applications computational resources limited. sits_lighttae() function implements algorithm. important parameter set learning rate lr. Values ranging 0.001 0.005 produce good results. See also section model tuning.\nFigure 77: Training evolution Lightweight Temporal Self-Attention model (source: authors).\n, classify 16-year time series using LightTAE model.\nFigure 78: Classification time series using LightTAE (source: authors).\nbehaviour sits_tae() sits_lighttae() similar sits_tempcnn(). points possible need classes training data better represent transition period 2004 2010. One possibility training data associated Pasture class consistent time series years 2005 2008. However, transition Forest Pasture 2004 Pasture Agriculture 2009-2010 subject uncertainty since classifiers agree resulting classes. general, deep learning temporal-aware models sensitive class variability random forest extreme gradient boosters.","code":"\n# Train a machine learning model using TAE\ntae_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_tae(\n    epochs               = 80,\n    batch_size           = 64,\n    optimizer            = torch::optim_adamw,\n    validation_split     = 0.2,\n    verbose              = FALSE\n  )\n)\n# Show training evolution\nplot(tae_model)\n# Classify using DL model and plot the result\npoint_mt_mod13q1 |>\n  sits_classify(tae_model) |>\n  plot(bands = c(\"NDVI\", \"EVI\"))\n# Train a machine learning model using TAE\nltae_model <- sits_train(\n  samples_matogrosso_mod13q1,\n  sits_lighttae(\n    epochs = 80,\n    batch_size = 64,\n    optimizer = torch::optim_adamw,\n    opt_hparams = list(lr = 0.001),\n    validation_split = 0.2\n  )\n)\n# Show training evolution\nplot(ltae_model)\n# Classify using DL model and plot the result\npoint_mt_mod13q1 |>\n  sits_classify(ltae_model) |>\n  plot(bands = c(\"NDVI\", \"EVI\"))"},{"path":"machine-learning-for-data-cubes.html","id":"deep-learning-model-tuning","chapter":"Machine learning for data cubes","heading":"Deep learning model tuning","text":"Model tuning process selecting best set hyperparameters specific application. using deep learning models image classification, highly recommended step enable better fit algorithm training data. Hyperparameters parameters model learned training instead set prior training affect behavior model training. Examples include learning rate, batch size, number epochs, number hidden layers, number neurons layer, activation functions, regularization parameters, optimization algorithms.Deep learning model tuning involves selecting best combination hyperparameters results optimal performance model given task. done training evaluating model different sets hyperparameters select set gives best performance.Deep learning algorithms try find optimal point representing best value prediction function , given input \\(X\\) data points, predicts result \\(Y\\). case, \\(X\\) multidimensional time series, \\(Y\\) vector probabilities possible output classes. complex situations, best prediction function time-consuming estimate. reason, deep learning methods rely gradient descent methods speed predictions converge faster exhaustive search [74]. gradient descent methods use optimization algorithm adjusted hyperparameters learning regularization rates [61]. learning rate controls numerical step gradient descent function, regularization rate controls model overfitting. Adjusting values optimal setting requires using model tuning methods.reduce learning curve, sits provides default values machine learning deep learning methods, ensuring reasonable baseline performance. However, refininig model hyperparameters might necessary, especially complex models sits_lighttae() sits_tempcnn(). end, package provides sits_tuning() function.straightforward approach model tuning run grid search; involves defining range hyperparameter testing possible combinations. approach leads combinatorial explosion thus recommended. Instead, Bergstra Bengio propose randomly chosen trials [75]. paper shows randomized trials efficient grid search trials, selecting adequate hyperparameters fraction computational cost. sits_tuning() function follows Bergstra Bengio using random search chosen hyperparameters.Experiments image time series show optimizers may better performance specific problem land classification. reason, authors developed torchopt R package, includes several recently proposed optimizers, including Madgrad [76], Yogi [77]. Using sits_tuning() function allows testing optimizers available torch torch_opt packages.sits_tuning() function takes following parameters:samples: Training dataset used model.samples_validation: Optional dataset containing time series used validation. missing, next parameter used.validation_split: samples_validation used, parameter defines proportion time series training dataset used validation (default 20%).ml_method(): Deep learning method (either sits_mlp(), sits_tempcnn(), sits_tae() sits_lighttae()).params: Defines optimizer hyperparameters calling sits_tuning_hparams(), shown example .trials: Number trials run random search.multicores: Number cores used procedure.progress: Show progress bar?sits_tuning_hparams() function inside sits_tuning() allows defining optimizers hyperparameters, including lr (learning rate), eps (controls numerical stability), weight_decay (controls overfitting). default values eps weight_decay sits deep learning functions 1e-08 1e-06, respectively. default lr sits_lighttae() sits_tempcnn() 0.005.Users different ways randomize hyperparameters, including:choice() (list options);uniform (uniform distribution);randint (random integers uniform distribution);normal(mean, sd) (normal distribution);beta(shape1, shape2) (beta distribution);loguniform(max, min) (loguniform distribution).suggest use log-uniform distribution search wide range values span several orders magnitude. common hyperparameters like learning rates, can vary small values (e.g., 0.0001) larger values (e.g., 1.0) logarithmic manner. default, sits_tuning() uses loguniform distribution 10^-2 10^-4 learning rate distribution 10^-2 10^-8 weight decay.result tibble different values accuracy, kappa, decision matrix, hyperparameters. best results obtain accuracy values 0.978 0.970, shown . best result obtained learning rate 0.0013 weight decay 3.73e-07. worst result accuracy 0.891, shows importance tuning procedure.large datasets, tuning process time-consuming. Despite cost, recommended achieve best performance. general, tuning hyperparameters models sits_tempcnn() sits_lighttae() result slight performance improvement default parameters overall accuracy. performance gain stronger less well represented classes, significant gains producer’s user’s accuracies possible. detecting change less frequent classes, tuning can make substantial difference results.","code":"\ntuned <- sits_tuning(\n  samples = samples_matogrosso_mod13q1,\n  ml_method = sits_lighttae(),\n  params = sits_tuning_hparams(\n    optimizer = torch::optim_adamw,\n    opt_hparams = list(\n      lr = loguniform(10^-2, 10^-4),\n      weight_decay = loguniform(10^-2, 10^-8)\n    )\n  ),\n  trials = 40,\n  multicores = 6,\n  progress = FALSE\n)\n# Obtain accuracy, kappa, lr, and weight decay for the 5 best results\n# Hyperparameters are organized as a list\nhparams_5 <- tuned[1:5, ]$opt_hparams\n# Extract learning rate and weight decay from the list\nlr_5 <- purrr::map_dbl(hparams_5, function(h) h$lr)\nwd_5 <- purrr::map_dbl(hparams_5, function(h) h$weight_decay)\n\n# Create a tibble to display the results\nbest_5 <- tibble::tibble(\n  accuracy = tuned[1:5, ]$accuracy,\n  kappa = tuned[1:5, ]$kappa,\n  lr = lr_5,\n  weight_decay = wd_5\n)\n# Print the best five combination of hyperparameters\nbest_5#> # A tibble: 5 × 4\n#>   accuracy kappa       lr weight_decay\n#>      <dbl> <dbl>    <dbl>        <dbl>\n#> 1    0.978 0.974 0.00136  0.000000373 \n#> 2    0.975 0.970 0.00269  0.0000000861\n#> 3    0.973 0.967 0.00162  0.00218     \n#> 4    0.970 0.964 0.000378 0.00000868  \n#> 5    0.970 0.964 0.00198  0.00000275"},{"path":"machine-learning-for-data-cubes.html","id":"considerations-on-model-choice","chapter":"Machine learning for data cubes","heading":"Considerations on model choice","text":"results taken indication method performs better. crucial factor achieving good result quality training data [31]. Experience shows classification quality depends training samples well model matches samples. examples ML classifying large areas, please see papers authors [7], [50], [78], [79].specific case satellite image time series, Russwurm et al. present comparative study seven deep neural networks classification agricultural crops, using random forest baseline [68]. data composed Sentinel-2 images Britanny, France. results indicate slight difference best model (attention-based transformer model) TempCNN random forest. Attention-based models obtain accuracy ranging 80-81%, TempCNN gets 78-80%, random forest obtains 78%. Based result also authors’ experience, make following recommendations:Random forest provides good baseline image time series classification included users’ assessments.Random forest provides good baseline image time series classification included users’ assessments.XGBoost worthy alternative random forest. principle, XGBoost sensitive data variations cost possible overfitting.XGBoost worthy alternative random forest. principle, XGBoost sensitive data variations cost possible overfitting.TempCNN reliable model reasonable training time, close state---art deep learning classifiers image time series.TempCNN reliable model reasonable training time, close state---art deep learning classifiers image time series.Attention-based models (TAE LightTAE) can achieve best overall performance well-designed balanced training sets hyperparameter tuning.Attention-based models (TAE LightTAE) can achieve best overall performance well-designed balanced training sets hyperparameter tuning.best means improving classification performance provide accurate reliable training dataset. Accuracy improvements resulting using deep learning methods instead random forest xgboost order 3-5%, gains using good training data improve results 10-30%. basic rule, make sure good quality samples training classification.","code":""},{"path":"classification-of-raster-data-cubes.html","id":"classification-of-raster-data-cubes","chapter":"Classification of raster data cubes","heading":"Classification of raster data cubes","text":"Chapter discusses classify data cubes providing step--step example. study area state Rondonia, Brazil, underwent substantial deforestation last decades. objective case study detect deforested areas.","code":""},{"path":"classification-of-raster-data-cubes.html","id":"data-cube-for-case-study","chapter":"Classification of raster data cubes","heading":"Data cube for case study","text":"examples chapter use pre-built data cube Sentinel-2 images, available package sitsdata. images SENTINEL-2-L2A collection Microsoft Planetary Computer (MPC). data consists bands BO2, B8A, B11, indexes NDVI, EVI NBR small area \\(1200 \\times 1200\\) pixels state Rondonia. explained Chapter Earth observation data cubes, must inform sits parse file names obtain tile, date, band information. Image files named according convention “satellite_ sensor_tile_band_date” (e.g., SENTINEL-2_MSI_20LKP_BO2_2020_06_04.tif) default format sits.\nFigure 79: Color composite image cube date 2023-07-16 (© EU Copernicus Sentinel Programme; source: Microsoft).\n","code":"\n# Files are available in a local directory\ndata_dir <- system.file(\"extdata/Rondonia-20LMR/\",\n  package = \"sitsdata\"\n)\n# Read data cube\nrondonia_20LMR <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir\n)\n\n# Plot the cube\nplot(rondonia_20LMR, date = \"2022-07-16\", band = \"NDVI\")"},{"path":"classification-of-raster-data-cubes.html","id":"training-data-for-the-case-study","chapter":"Classification of raster data cubes","heading":"Training data for the case study","text":"case study uses training dataset samples_deforestation_rondonia, available package sitsdata. dataset consists 6007 samples collected Sentinel-2 images covering state Rondonia. nine classes: Clear_Cut_Bare_Soil, Clear_Cut_Burned_Area, Mountainside_Forest, Forest, Riparian_Forest, Clear_Cut_Vegetation, Water, Wetland, Seasonally_Flooded. time series contains values Sentinel-2/2A bands B02, B03, B04, B05, B06, B07, B8A, B08, B11 B12, 2022-01-05 2022-12-23 16-day intervals. samples intended detect deforestation events collected remote sensing experts using visual interpretation. fIt helpful plot basic patterns associated samples understand training set better. function sits_patterns() uses generalized additive model (GAM) predict smooth, idealized approximation time series associated class bands. Since data cube used classification 10 bands, obtain indexes NDVI, EVI NBR showing patterns.\nFigure 80: Patterns associated training samples (source: authors).\npatterns show different temporal responses selected classes. match typical behavior deforestation Amazon. cases, forest cut start dry season (May/June). end dry season, clear-cut areas burned clean remains; action reflected steep fall response B11 values burned area samples August. (….) areas native trees cut vegatation remain (“Clear_Cut_Vegetation”) values B8A band increase period.","code":"\nlibrary(sitsdata)\n# Obtain the samples\ndata(\"samples_deforestation_rondonia\")\n# Show the contents of the samples\nsummary(samples_deforestation_rondonia)#> # A tibble: 9 × 3\n#>   label                 count   prop\n#>   <chr>                 <int>  <dbl>\n#> 1 Clear_Cut_Bare_Soil     944 0.157 \n#> 2 Clear_Cut_Burned_Area   983 0.164 \n#> 3 Clear_Cut_Vegetation    603 0.100 \n#> 4 Forest                  964 0.160 \n#> 5 Mountainside_Forest     211 0.0351\n#> 6 Riparian_Forest        1247 0.208 \n#> 7 Seasonally_Flooded      731 0.122 \n#> 8 Water                   109 0.0181\n#> 9 Wetland                 215 0.0358\nsamples_deforestation_rondonia |>\n  sits_apply(NDVI = (B08 - B04) / (B08 + B04)) |>\n  sits_apply(NBR = (B08 - B12) / (B08 + B12)) |>\n  sits_apply(EVI = 2.5 * (B08 - B04) / ((B08 + 6.0 * B04 - 7.5 * B02) + 1.0)) |>\n  sits_select(bands = c(\"NDVI\", \"EVI\", \"NBR\")) |>\n  sits_patterns() |>\n  plot()"},{"path":"classification-of-raster-data-cubes.html","id":"training-machine-learning-models","chapter":"Classification of raster data cubes","heading":"Training machine learning models","text":"next step train machine learning model illustrate CPU-based classification. build random forest model using sits_train() create plot find important variables model.\nFigure 81: relevant variables Random Forest model (source: authors).\nfigure shows EVI index values dates 9 (“2022-05-13”) 15 (“2022-08-17”) informative variables random forest model. bands dates represent inflection points image time series.","code":"\n# set the seed to get the same result\nset.seed(03022024)\n# Train model using random forest model\nrfor_model <- sits_train(\n  samples_deforestation_rondonia,\n  ml_method = sits_rfor()\n)\nplot(rfor_model)"},{"path":"classification-of-raster-data-cubes.html","id":"classification-of-machine-learning-models-in-cpus","chapter":"Classification of raster data cubes","heading":"Classification of machine learning models in CPUs","text":"default, classification algorithms sits use CPU-based parallel processing, done internally package. algorithms adaptable; requirement users inform configuration machines. achieve efficiency, sits implements fault-tolerant multitasking procedure, using cluster independent workers linked virtual machine. avoid communication overhead, large payloads read stored independently; direct interaction main process workers kept minimum. Details CPU-based parallel processing sits can found Technical annex.classify data cubes sets time series, use sits_classify(), uses parallel processing speed performance, described end Chapter. relevant parameters : () data, either data cube set time series; (b) ml_model, trained model using one machine learning methods provided; (c) multicores, number CPU cores used processing; (d) memsize, memory available classification; (e) output_dir, directory results stored; (f) version, version control. follow processing steps, turn parameters verbose print information progress get progress bar. classification result data cube set probability layers, one output class. probability layer contains model’s assessment likely pixel belongs related class. probability cube can visualized plot(). example, show probabilities associated label “Forest”.\nFigure 82: Probabilities class Forest (source: authors).\nprobability cube provides information output values algorithm class. probability maps contain outliers misclassified pixels. labeled map generated pixel-based time series classification method exhibits several misclassified pixels, small patches surrounded different class. occurrence outliers common issue arises due inherent nature classification approach. Regardless resolution, mixed pixels prevalent images, class exhibits considerable data variability. result, factors can lead outliers likely misclassified. overcome limitation, sits employs post-processing smoothing techniques leverage spatial context probability cubes refine results. techniques discussed Chapter Bayesian smoothing post-processing. follows, generate smoothed cube illustrate procedure.\nFigure 83: Smoothened probabilities class Forest (source: authors).\ngeneral, users perform post-processing smoothing obtaining probability maps raster format. post-processing operation, apply sits_label_classification() obtain map likely class pixel. pixel, sits_label_classification() function takes label highest probability assigns resulting map. output labelled map classes.\nFigure 84: Final map deforestation obtained random forest model(source: authors).\n","code":"\n# Classify data cube to obtain a probability cube\nrondonia_20LMR_probs <- sits_classify(\n  data = rondonia_20LMR,\n  ml_model = rfor_model,\n  output_dir = \"./tempdir/chp9\",\n  version = \"rf-raster\",\n  multicores = 4,\n  memsize = 16\n)\n\nplot(rondonia_20LMR_probs, labels = \"Forest\", palette = \"YlGn\")\n# Smoothen a  probability cube\nrondonia_20LMR_bayes <- sits_smooth(\n  cube = rondonia_20LMR_probs,\n  output_dir = \"./tempdir/chp9\",\n  version = \"rf-raster\",\n  multicores = 4,\n  memsize = 16\n)\nplot(rondonia_20LMR_bayes, labels = c(\"Forest\"), palette = \"YlGn\")\n# Generate a thematic map\nrondonia_20LMR_class <- sits_label_classification(\n  cube = rondonia_20LMR_bayes,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp9\",\n  version = \"rf-raster\"\n)\n\n# Plot the thematic map\nplot(rondonia_20LMR_class,\n  legend_text_size = 0.7\n)"},{"path":"classification-of-raster-data-cubes.html","id":"training-and-running-deep-learning-models","chapter":"Classification of raster data cubes","heading":"Training and running deep learning models","text":"next examples show run deep learning models sits. case study uses Temporal CNN model [65], described Chapter Machine learning data cubes. first show need model tuning, applying model data cube classification.","code":""},{"path":"classification-of-raster-data-cubes.html","id":"deep-learning-model-tuning-1","chapter":"Classification of raster data cubes","heading":"Deep learning model tuning","text":"example, use sits_tuning() find good hyperparameters train sits_tempcnn() algorithm Rondonia dataset. hyperparameters sits_tempcnn() method include size layers, convolution kernels, dropout rates, learning rate, weight decay. Please refer description Temporal CNN algorithm Chapter Machine learning data cubesThe result sits_tuning() tibble different values accuracy, kappa, decision matrix, hyperparameters. five best results obtain accuracy values 0.939 0.908, shown . best result obtained learning rate 3.76e-04 weight decay 1.5e-04, three CNN layers size 256, kernel size 5, dropout rates 0.2.","code":"\ntuned_tempcnn <- sits_tuning(\n  samples = samples_deforestation_rondonia,\n  ml_method = sits_tempcnn(),\n  params = sits_tuning_hparams(\n    cnn_layers = choice(c(256, 256, 256), c(128, 128, 128), c(64, 64, 64)),\n    cnn_kernels = choice(c(3, 3, 3), c(5, 5, 5), c(7, 7, 7)),\n    cnn_dropout_rates = choice(\n      c(0.15, 0.15, 0.15), c(0.2, 0.2, 0.2),\n      c(0.3, 0.3, 0.3), c(0.4, 0.4, 0.4)\n    ),\n    optimizer = torch::optim_adamw,\n    opt_hparams = list(\n      lr = loguniform(10^-2, 10^-4),\n      weight_decay = loguniform(10^-2, 10^-8)\n    )\n  ),\n  trials = 50,\n  multicores = 4\n)\n# Obtain accuracy, kappa, cnn_layers, cnn_kernels, and cnn_dropout_rates the best result\ncnn_params <- tuned_tempcnn[1, c(\"accuracy\", \"kappa\", \"cnn_layers\", \"cnn_kernels\", \"cnn_dropout_rates\"), ]\n# Learning rates and weight decay are organized as a list\nhparams_best <- tuned_tempcnn[1, ]$opt_hparams[[1]]\n# Extract learning rate and weight decay\nlr_wd <- tibble::tibble(\n  lr_best = hparams_best$lr,\n  wd_best = hparams_best$weight_decay\n)\n# Print the best parameters\ndplyr::bind_cols(cnn_params, lr_wd)#> # A tibble: 1 × 7\n#>   accuracy kappa cnn_layers       cnn_kernels cnn_dropout_rates  lr_best wd_best\n#>      <dbl> <dbl> <chr>            <chr>       <chr>                <dbl>   <dbl>\n#> 1    0.939 0.929 c(256, 256, 256) c(5, 5, 5)  c(0.2, 0.2, 0.2)  0.000376 1.53e-4"},{"path":"classification-of-raster-data-cubes.html","id":"classification-in-gpus-using-parallel-processing","chapter":"Classification of raster data cubes","heading":"Classification in GPUs using parallel processing","text":"Deep learning time series classification methods sits, include sits_tempcnn(), sits_mlp(), sits_lightae() sits_tae(), written using torch package, adaptation pyTorch R environment. algorithms can use CUDA-compatible NVDIA GPU one available properly configured. Please refer torch installation guide details configure torch use GPUs. GPU available, algorithms run regular CPUs, using paralellization methods described traditional machine learning methods. Typically, 10-fold performance increase running torch based methods GPUs relative processing time GPU.illustrate use GPUs, take data cube training data used previous examples use Temporal CNN method. first step obtain deep learning model using hyperparameters produced tuning procedure shown earlier. runAfter training model, classify data cube. GPU available, users need provide additional parameter gpu_memory sits_classify(). information used sits optimize access GPU speed processing.classification, can smooth probability cube label resulting smoothed probabilities obtain classified map.\nFigure 85: Final map deforestation obtained using TempCNN model (source: authors).\n","code":"\ntcnn_model <- sits_train(\n  samples_deforestation_rondonia,\n  sits_tempcnn(\n    cnn_layers = c(256, 256, 256),\n    cnn_kernels = c(5, 5, 5),\n    cnn_dropout_rates = c(0.2, 0.2, 0.2),\n    opt_hparams = list(\n      lr = 0.000376,\n      weight_decay = 0.000153\n    )\n  )\n)\nrondonia_20LMR_probs_tcnn <- sits_classify(\n  rondonia_20LMR,\n  ml_model = tcnn_model,\n  output_dir = \"./tempdir/chp9\",\n  version = \"tcnn-raster\",\n  gpu_memory = 16,\n  multicores = 6,\n  memsize = 24\n)\n# Smoothen the probability map\nrondonia_20LMR_bayes_tcnn <- sits_smooth(\n  rondonia_20LMR_probs_tcnn,\n  output_dir = \"./tempdir/chp9\",\n  version = \"tcnn-raster\",\n  multicores = 6,\n  memsize = 24\n)\n# Obtain the final labelled map\nrondonia_20LMR_class_tcnn <- sits_label_classification(\n  rondonia_20LMR_bayes_tcnn,\n  output_dir = \"./tempdir/chp9\",\n  version = \"tcnn-raster\",\n  multicores = 6,\n  memsize = 24\n)\n# plot the final classification map\nplot(rondonia_20LMR_class_tcnn,\n  legend_text_size = 0.7\n)"},{"path":"classification-of-raster-data-cubes.html","id":"map-reclassification","chapter":"Classification of raster data cubes","heading":"Map reclassification","text":"Reclassification remote sensing map refers changing classes assigned different pixels image. purpose reclassification modify information contained image better suit specific use case. sits, reclassification involves assigning new classes pixels based additional information reference map. Users define rules according desired outcome. rules applied classified map produce new map updated classes.illustrate reclassification sits, take classified data cube stored sitsdata package. discussed Chapter Earth observation data cubes, sits can create data cube classified image file. Users need provide original data source collection, directory data stored (data_dir), information retrieve data cube parameters file names (parse_info), labels used classification.\nFigure 86: Original classification map (source: authors).\nmap shows total extent deforestation clear cuts estimated sits random forest algorithm area Rondonia, Brazil, based time series Sentinel-2 images period 2020-06-04 2021-08-26. Suppose want estimate deforestation occurred June 2020 August 2021. need reference map containing information forest cuts 2020.example, use reference PRODES deforestation map Amazonia created Brazil’s National Institute Space Research (INPE). map produced visual interpretation. PRODES measures deforestation every year, starting August one year July following year. contains classes represent natural world (Forest, Water, NonForest, NonForest2) classes capture yearly deforestation increments. classes named “dYYYY” “rYYYY”; first refers deforestation given year (e.g., “d2008” deforestation August 2007 July 2008); second places satellite data sufficient determine land class (e.g., “r2010” 2010). map available package sitsdata, shown .Since labels deforestation map specialized part default sits color table, define legend better visualization different deforestation classes.Using new legend, can visualize PRODES deforestation map.\nFigure 87: Deforestation map produced PRODES (source: authors).\nTaking PRODES map reference, can include new labels classified map produced sits using sits_reclassify(). new class name Defor_2020 applied pixels PRODES considers deforested July 2020. also include Non_Forest class include pixels PRODES takes covered native vegetation, wetlands rocky areas. PRODES classes used mask sits deforestation map.sits_reclassify() operation requires parameters: () cube, classified data cube whose pixels reclassified; (b) mask, reference data cube used mask; (c) rules, named list. names rules list new label. new label associated mask vector includes labels reference map joined. sits_reclassify() compares original reference map pixel pixel. pixel reference map whose labels one rules, algorithm relabels original map. result reclassified map original labels plus new labels masked using reference map.\nFigure 88: Deforestation map sits masked PRODES map (source: authors).\nreclassified map split deforestation mid-2020 (using PRODES map) areas classified sits taken deforested mid-2020 mid-2021. allows experts measure much deforestation occurred period according sits compare result PRODES map.sits_reclassify() function restricted comparing deforestation maps. can used case requires masking result based reference map.","code":"\n# Open classification map\ndata_dir <- system.file(\"extdata/Rondonia-Class\", package = \"sitsdata\")\nrondonia_class <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  parse_info = c(\n    \"satellite\", \"sensor\",\n    \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  ),\n  bands = \"class\",\n  labels = c(\n    \"1\" = \"Water\", \"2\" = \"Clear_Cut_Burned_Area\",\n    \"3\" = \"Clear_Cut_Bare_Soil\",\n    \"4\" = \"Clear_Cut_Vegetation\",\n    \"5\" = \"Forest\",\n    \"6\" = \"Bare_Soil\",\n    \"7\" = \"Wetland\"\n  )\n)\n\nplot(rondonia_class,\n  legend_text_size = 0.7\n)\ndata_dir <- system.file(\"extdata/PRODES\", package = \"sitsdata\")\nprodes_2021 <- sits_cube(\n  source = \"USGS\",\n  collection = \"LANDSAT-C2L2-SR\",\n  data_dir = data_dir,\n  parse_info = c(\n    \"product\", \"sensor\",\n    \"tile\", \"start_date\", \"end_date\",\n    \"band\", \"version\"\n  ),\n  bands = \"class\",\n  version = \"v20220606\",\n  labels = c(\n    \"1\" = \"Forest\", \"2\" = \"Water\", \"3\" = \"NonForest\",\n    \"4\" = \"NonForest2\", \"6\" = \"d2007\", \"7\" = \"d2008\",\n    \"8\" = \"d2009\", \"9\" = \"d2010\", \"10\" = \"d2011\",\n    \"11\" = \"d2012\", \"12\" = \"d2013\", \"13\" = \"d2014\",\n    \"14\" = \"d2015\", \"15\" = \"d2016\", \"16\" = \"d2017\",\n    \"17\" = \"d2018\", \"18\" = \"r2010\", \"19\" = \"r2011\",\n    \"20\" = \"r2012\", \"21\" = \"r2013\", \"22\" = \"r2014\",\n    \"23\" = \"r2015\", \"24\" = \"r2016\", \"25\" = \"r2017\",\n    \"26\" = \"r2018\", \"27\" = \"d2019\", \"28\" = \"r2019\",\n    \"29\" = \"d2020\", \"31\" = \"r2020\", \"32\" = \"Clouds2021\",\n    \"33\" = \"d2021\", \"34\" = \"r2021\"\n  )\n)\n# Use the RColorBrewer palette \"YlOrBr\" for the deforestation years\ncolors <- grDevices::hcl.colors(n = 15, palette = \"YlOrBr\")\n# Define the legend for the deforestation map\ndef_legend <- c(\n  \"Forest\" = \"forestgreen\", \"Water\" = \"dodgerblue3\",\n  \"NonForest\" = \"bisque2\", \"NonForest2\" = \"bisque2\",\n  \"d2007\" = colors[1], \"d2008\" = colors[2],\n  \"d2009\" = colors[3], \"d2010\" = colors[4],\n  \"d2011\" = colors[5], \"d2012\" = colors[6],\n  \"d2013\" = colors[7], \"d2014\" = colors[8],\n  \"d2015\" = colors[9], \"d2016\" = colors[10],\n  \"d2017\" = colors[11], \"d2018\" = colors[12],\n  \"d2019\" = colors[13], \"d2020\" = colors[14],\n  \"d2021\" = colors[15], \"r2010\" = \"lightcyan\",\n  \"r2011\" = \"lightcyan\", \"r2012\" = \"lightcyan\",\n  \"r2013\" = \"lightcyan\", \"r2014\" = \"lightcyan\",\n  \"r2015\" = \"lightcyan\", \"r2016\" = \"lightcyan\",\n  \"r2017\" = \"lightcyan\", \"r2018\" = \"lightcyan\",\n  \"r2019\" = \"lightcyan\", \"r2020\" = \"lightcyan\",\n  \"r2021\" = \"lightcyan\", \"Clouds2021\" = \"lightblue2\"\n)\nsits_view(prodes_2021, legend = def_legend)\n# Reclassify cube\nrondonia_def_2021 <- sits_reclassify(\n  cube = rondonia_class,\n  mask = prodes_2021,\n  rules = list(\n    \"Non_Forest\" = mask %in% c(\"NonForest\", \"NonForest2\"),\n    \"Deforestation_Mask\" = mask %in% c(\n      \"d2007\", \"d2008\", \"d2009\",\n      \"d2010\", \"d2011\", \"d2012\",\n      \"d2013\", \"d2014\", \"d2015\",\n      \"d2016\", \"d2017\", \"d2018\",\n      \"d2019\", \"d2020\",\n      \"r2010\", \"r2011\", \"r2012\",\n      \"r2013\", \"r2014\", \"r2015\",\n      \"r2016\", \"r2017\", \"r2018\",\n      \"r2019\", \"r2020\", \"r2021\"\n    ),\n    \"Water\" = mask == \"Water\"\n  ),\n  memsize = 8,\n  multicores = 2,\n  output_dir = \"./tempdir/chp9\",\n  version = \"reclass\"\n)\n\n# Plot the reclassified map\nplot(rondonia_def_2021,\n  legend_text_size = 0.7\n)"},{"path":"bayesian-smoothing-for-post-processing.html","id":"bayesian-smoothing-for-post-processing","chapter":"Bayesian smoothing for post-processing","heading":"Bayesian smoothing for post-processing","text":"","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"introduction-1","chapter":"Bayesian smoothing for post-processing","heading":"Introduction","text":"Machine learning algorithms rely training samples derived “pure” pixels, hand-picked users represent desired output classes. Given presence mixed pixels images regardless resolution, considerable data variability within class, classifiers often produce results outliers misclassified pixels. Therefore, post-processing techniques become crucial refine labels classified image [80]. Post-processing methods reduce salt--pepper border effects, single pixels small groups pixels classified differently larger surrounding areas; effects lead visual discontinuity inconsistency. mitigating errors minimizing noise, post-processing improves quality initial classification results, bringing significant gain overall accuracy interpretability final output [81].sits package uses time-first, space-later approach. Since machine learning classifiers sits mostly pixel-based, necessary complement spatial smoothing methods. methods improve accuracy land classification incorporating spatial contextual information classification process. smoothing method available sits uses Empirical Bayes approach, adjusted specific properties land classification. assumption class probabilities local level similar provide baseline comparison pixel values produced classifier. Based two elements, Bayesian smoothing adjusts probabilities pixels, considering spatial dependence.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"the-need-for-post-processing","chapter":"Bayesian smoothing for post-processing","heading":"The need for post-processing","text":"main idea behind post-processing method pixel-based classification take account neighborhood pixels. Consider figure blow shows class assignment produced random forest algorithm image time series. classified map produced taking, pixel, class higher probability produced algorithm. resulting map many noisy areas high spatial variability class assignments. happens frequently two cases: () small clusters pixels one class inside larger area different class; (b) transition zones classes. general, images heterogeneous landscapes high spatial variability many mixed pixels, whose spectral response combines different types land cover single ground resolved cell. example, many pixels border areas classes Forest \nClear_Cut_Bare_Soil wrongly assigned Clear_Cut_Vegetation class. wrong assignment occurs pixels mixed response. Inside ground cell captured sensor single pixel value, trees bare soil areas. results undesirable need corrected post-processing.\nFigure 89: Detail labelled map produced pixel-based random forest without smoothing (source: authors)\nmaintain consistency coherence class representations, minimise small variations misclassifications. incorporate spatial coherence post-processing step accomplish . probabilities associated pixel change based statistical inference, depends values neighbourhood. Using recalculated probabilities pixel, get better version final classified map. Consider figure , result Bayesian smoothing random forest algorithm outcomes. noisy border pixels two large areas class removed. also removed small clusters pixels belonging one class inside larger areas classes. outcome uniform map, like ones created visual interpretation object-based analysis. Details like narrow vegetation corridors small forest roads might missing smoothed image. However, improved spatial consistency final map compensates losses, due removal misclassified pixels mixed spectral responses.\nFigure 90: Detail labelled map produced pixel-based random forest smoothing (source: uthors)\n","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"empirical-bayesian-estimation","chapter":"Bayesian smoothing for post-processing","heading":"Empirical Bayesian estimation","text":"Bayesian estimate based probabilities produced classifiers. Let \\(p_{,k} \\geq 0\\) prior probability \\(\\)-th pixel belonging class \\(k \\\\{1, \\ldots, m\\}\\). probabilities \\(p_{,k}\\) classifier’s output, subject noise, outliers, classification errors. estimation aims remove effects obtain values approximate actual class probability better. convert class probability values \\(p_{,k}\\) log-odds values using logit function, transform probability values ranging \\(0\\) \\(1\\) values negative infinity infinity. conversion probabilities logit values helpful support assumption normal distribution data.\\[\n    x_{,k} = \\ln \\left(\\frac{p_{,k}}{1 - p_{,k}}\\right)\n\\]\nassume logit prior probability pixels \\(\\) associated class \\(k\\) described Gaussian distribution function\\[\\begin{equation}\nx_{,k} = \\log\\left( \\frac{\\pi_{,k}}{1-\\pi_{,k}} \\right) \\sim N(m_{,k}, s^2_{,k})\n\\end{equation}\\]\\(m_{,k}\\) represents local mean value \\(s^2_{,k}\\) local class variance. local mean variance computed based local neighborhood point. express likelihood conditional Gaussian distribution logit \\(x_{,k}\\) observed values \\(p_{,k}\\) \\(\\mu_{,k}\\):\n\\[\\begin{equation}\n(x_{,k} | \\mu_{,k}) = \\log(p_{,k}/(1-p_{,k})) \\sim N(\\mu_{,k}, \\sigma^2).\n\\end{equation}\\]equation, \\(\\mu_{,k}\\) posterior expected mean logit probability associated \\(-th\\) pixel. variance \\(\\sigma^2_{k}\\) estimated based user expertise taken hyperparameter control smoothness resulting estimate. standard Bayesian updating [82] leads posterior distribution can expressed weighted mean\\[\n{E}[\\mu_{,k} | x_{,k}] =\n\\Biggl [ \\frac{s^2_{,k}}{\\sigma^2_{k} +s^2_{,k}} \\Biggr ] \\times\nx_{,k} +\n\\Biggl [ \\frac{\\sigma^2_{k}}{\\sigma^2_{k} +s^2_{,k}} \\Biggr ] \\times m_{,k},\n\\]\n:\\(x_{,k}\\) logit value pixel \\(\\) class \\(k\\).\\(m_{,k}\\) average logit values pixels class \\(k\\)\nneighborhood pixel \\(\\).\\(s^2_{,k}\\) variance logit values pixels class \\(k\\)\nneighborhood pixel \\(\\).\\(\\sigma^2_{k}\\) user-derived hyperparameter estimates variance class \\(k\\), expressed logits.equation weighted average value \\(x_{,k}\\) pixel mean \\(m_{,k}\\) neighboring pixels. variance \\(s^2_{,k}\\) neighbors high, algorithm gives weight pixel value \\(x_{,k}\\). class variance \\(\\sigma^2_k\\) increases, results gives weight neighborhood mean \\(m_{,k}\\).Bayesian smoothing land classification assumes image patches similar characteristics dominant class. dominant class higher average probabilities lower variance classes. pixel assigned different class likely exhibit high local variance regions. result, post-processing adjust class pixel match dominant class.usually prior information specify \\(m_{,k}\\) \\(s^2_{,k}\\). , adopt Empirical Bayes (EB) approach obtain estimates prior parameters considering pixel neighborhood. However, using standard symmetrical neighborhood pixel, based uniquely distance locations, produce reasonable results border pixels. reason, EB estimates uses non-isotropic neighbourhood, explained .","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"using-non-isotropic-neighborhoods","chapter":"Bayesian smoothing for post-processing","heading":"Using non-isotropic neighborhoods","text":"fundamental idea behind Bayesian smoothing land classification individual pixels area related close . pixel usually class neighbors. closeness relations expressed similar values class probability. find pixel assigned Water surrounded pixels labeled Forest, pixel may wrongly labelled. check pixel mislabeled, look class probabilities pixels neighbors. possible situations:outlier class probability distribution different neighbors. example, probability belonging Water class 80% Forest 20%. also consider Water pixels smaller variance, since water areas strong signal multispectral images, post-processing method change pixel’s label.outlier class probability distribution different neighbors. example, probability belonging Water class 80% Forest 20%. also consider Water pixels smaller variance, since water areas strong signal multispectral images, post-processing method change pixel’s label.outlier class probability distribution similar neighbors. Consider case pixel 47% probability Water 43% probability Forest. small difference indicates need look neighborhood improve information produced classifier. cases, post-processing estimate may change pixel’s label.outlier class probability distribution similar neighbors. Consider case pixel 47% probability Water 43% probability Forest. small difference indicates need look neighborhood improve information produced classifier. cases, post-processing estimate may change pixel’s label.Pixels border two areas different classes pose challenge. neighbors belong class pixel. address issue, employ non-isotropic definition neighborhood estimate prior class distribution. instance, consider boundary pixel neighborhood defined 7 x 7 window, located along border Forest Grassland classes. estimate prior probability pixel labeled Forest, take account neighbors one side border likely correctly classified Forest. Pixels opposite side border disregarded, since unlikely belong spatial process. practice, use half pixels 7 x 7 window, opting higher probability named Forest. prior probability Grassland class, reverse selection consider opposite side border.Although choice neighborhood may seem unconventional, consistent assumption non-continuity spatial processes describing class. dense forest patch, example, pixels strong spatial autocorrelation values Forest class; however, spatial autocorrelation doesn’t extend across border land classes.","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"effect-of-the-hyperparameter","chapter":"Bayesian smoothing for post-processing","heading":"Effect of the hyperparameter","text":"parameter \\(\\sigma^2_k\\) controls level smoothness. \\(\\sigma^2_k\\) zero, value \\({E}[\\mu_{,k} | x_{,k}]\\) equal pixel value \\(x_{,k}\\). parameter \\(\\sigma^2_k\\) expresses confidence inherent variability distribution values class \\(k\\). smaller parameter \\(\\sigma^2_k\\), trust estimated probability values produced classifier class \\(k\\). Conversely, higher values \\(\\sigma^2_k\\) indicate lower confidence classifier outputs improved confidence local averages.Consider following two-class example. Take pixel probability \\(0.4\\) (logit \\(x_{,1} = -0.4054\\)) class probability \\(0.6\\) (logit \\(x_{,2} = 0.4054\\)) class B. Without post-processing, pixel labeled class B. Consider local average \\(0.6\\) (logit \\(m_{,1} = 0.4054\\)) class \\(0.4\\) (logit \\(m_{,2} = -0.4054\\)) class B. case outlier classified originally class B midst set class pixels.Given situation, apply proposed method. Suppose local variance logits \\(s^2_{,1} = 5\\) class \\(s^2_{,2} = 10\\) class B. difference expected local variability class smaller class B. complete estimate, need set parameter \\(\\sigma^2_{k}\\), representing belief variability probability values class.Setting \\(\\sigma^2_{k}\\) based confidence local variability class around pixel \\({}\\). considered local variability high, can take \\(\\sigma^2_1\\) class \\(\\sigma^2_2\\) class B 10. case, Bayesian estimated probability class \\(0.52\\) class B \\(0.48\\) pixel relabeled class .contrast, consider local variability high set \\(\\sigma^2\\) 5 classes B, Bayesian probability estimate \\(0.48\\) class \\(0.52\\) class B. case, original class kept. Therefore, result sensitive subjective choice hyperparameter. example , show use local logit variance set appropriate values \\(\\sigma^2\\).","code":""},{"path":"bayesian-smoothing-for-post-processing.html","id":"running-bayesian-smoothing","chapter":"Bayesian smoothing for post-processing","heading":"Running Bayesian smoothing","text":"now show run Bayesian smoothing data cube covering area Sentinel-2 tile “20LLQ” period 2020-06-04 2021-08-26. training data six classes: () Forest natural tropical forest; (b) Water lakes rivers; (c) “Wetlands” areas water covers soil wet season; (d) Clear_Cut_Burned_Area areas fires cleared land tree removal; (e) Clear_Cut_Bare_Soil forest completely removed; (f) Clear_Cut_Vegetation vegetation remains trees removed. simplify example, input probability cube generated random forest model. recover probability data cube plot results machine learning method classes Forest, Clear_Cut_Bare_Soil, Clear_Cut_Vegetation, Clear_Cut_Burned_Area.\nFigure 91: Probability map produced classes Forest Clear_Cut_Bare_Soil (source: authors).\n\nFigure 92: Probability map produced classes Forest Clear_Cut_Bare_Soil (source: authors).\nprobability map Forest shows high values associated compact patches linear stretches riparian areas. Class Clear_Cut_Bare_Soil mostly composed dense areas high probability whose geometrical boundaries result forest cuts. Areas class Clear_Cut_Vegetation less well-defined others; expected since transitional class natural forest areas bare soil. Patches associated class Clear_Cut_Burned_Area include homogeneous areas high probability areas mixed response. Since classes different behaviours, post-processing procedure enable users control handle outliers border pixels class.next step show labelled map resulting raw class probabilites. produce classification map taking class higher probability pixel, without considering spatial context. many places -called “salt--pepper” effect result misclassified pixels. non-smoothed labelled map shows need post-processing, since contains significant number outliers areas mixed labelling.\nFigure 93: Classified map without smoothing (source: authors).\n","code":"\n# define the classes of the probability cube\nlabels <- c(\n  \"1\" = \"Water\",\n  \"2\" = \"Clear_Cut_Burned_Area\",\n  \"3\" = \"Clear_Cut_Bare_Soil\",\n  \"4\" = \"Clear_Cut_Vegetation\",\n  \"5\" = \"Forest\",\n  \"6\" = \"Wetland\"\n)\n# directory where the data is stored\ndata_dir <- system.file(\"extdata/Rondonia-20LLQ/\", package = \"sitsdata\")\n# create a probability data cube from a file\nrondonia_20LLQ_probs <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  bands = \"probs\",\n  labels = labels,\n  parse_info = c(\n    \"satellite\", \"sensor\", \"tile\",\n    \"start_date\", \"end_date\", \"band\", \"version\"\n  )\n)\n\n# plot the probabilities for water and forest\nplot(rondonia_20LLQ_probs,\n  labels = c(\"Forest\", \"Clear_Cut_Bare_Soil\")\n)\nplot(rondonia_20LLQ_probs,\n  labels = c(\"Clear_Cut_Vegetation\", \"Clear_Cut_Burned_Area\")\n)\n# Generate the thematic map\nrondonia_20LLQ_class <- sits_label_classification(\n  cube = rondonia_20LLQ_probs,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp10\",\n  version = \"no_smooth\"\n)\n\n# Plot the result\nplot(rondonia_20LLQ_class,\n  legend_text_size = 0.8, legend_position = \"outside\"\n)"},{"path":"bayesian-smoothing-for-post-processing.html","id":"assessing-the-local-logit-variance","chapter":"Bayesian smoothing for post-processing","heading":"Assessing the local logit variance","text":"determine appropriate settings \\(\\sigma^2_{k}\\) hyperparameter class perform Bayesian smoothing, useful calculate local logit variances class. pixel, estimate local variance \\(s^2_{,k}\\) considering non-isotropic neighborhood. local logit variances estimated sits_variance(); main parameters : () cube, probability data cube; (b) window_size, dimension local neighbourhood; (c) neigh_fraction, percentage pixels neighbourhood used calculate variance. example uses half pixels \\(7\\times 7\\) window estimate variance. chosen pixels highest probability pixels representative actual class distribution. output values logit variances vicinity pixel.choice \\(7 \\times 7\\) window size compromise enough values estimate parameters normal distribution need capture local effects class patches small sizes. Classes Water tend spatially limited; bigger window size result invalid values respective normal distributions.\nFigure 94: Variance map classes Forest Clear_Cut_Bare_Soil (source: authors).\n\nFigure 95: Variance map clases Clear_Cut_Vegetation Clear_Cut_Burned_Area (source: authors).\nComparing variance maps probability maps, one sees areas high probability classes Forest Clear_Cut_Bare_Soil mostly made compact patches. Recall two dominant classes area, deforestation process converts forest bare soil. Many areas high logit variance classes related border pixels mixed response. Areas large patches high logit variance classes associated lower class probabilities relevant final result.contrast, transitional classes Clear_Cut_Vegetation Clear_Cut_Burned_Area different spatial pattern probability logit variance. first high spatial variability, since pixels class arise forest completely removed remaining vegetation trees cut. extent remaining vegetation trees removed uniform. reason, many areas high local logit variance class Clear_Cut_Vegetation located mixed patches inside pixels class Forest border Forest Clear_Cut_Bare_Soil. situation consistent earlier observation transitional classes may appear artificial effects mixed pixels borders classes.Instances class ClearCut_Burned_Area arise following forest fire. pixels class tend form mid-sized large spatial clusters, forest fires start propagate. desirable preserve contiguity burned areas remove pixels classes inside clusters. Isolated points class ClearCut_Burned_Area can removed without significant information loss.distinct patterns classes measured quantitatively summary() function. variance cubes, function provides information logit variance values higher inter-quartile values.summary statistics show local variance values low, expected result. Areas low variance correspond pixel neighborhoods high logit values one classes low logit values others. High values local variances relevant areas confusion classes.","code":"\n# calculate variance\nrondonia_20LLQ_var <- sits_variance(\n  cube = rondonia_20LLQ_probs,\n  window_size = 7,\n  neigh_fraction = 0.50,\n  output_dir = \"./tempdir/chp10\",\n  multicores = 4,\n  memsize = 16\n)\nplot(rondonia_20LLQ_var,\n  labels = c(\"Forest\", \"Clear_Cut_Bare_Soil\"),\n  palette = \"Spectral\",\n  rev = TRUE\n)\nplot(rondonia_20LLQ_var,\n  labels = c(\"Clear_Cut_Vegetation\", \"Clear_Cut_Burned_Area\"),\n  palette = \"Spectral\",\n  rev = TRUE\n)\n# get the summary of the logit variance\nsummary(rondonia_20LLQ_var)#>      Water Clear_Cut_Burned_Area Clear_Cut_Bare_Soil Clear_Cut_Vegetation\n#> 75%   4.22                  0.25                0.40               0.5500\n#> 80%   4.74                  0.31                0.49               0.6800\n#> 85%   5.07                  0.38                0.64               0.8700\n#> 90%   5.36                  0.51                0.87               1.1810\n#> 95%   5.88                  0.76                1.68               1.8405\n#> 100% 22.10                  8.74               12.79              14.0800\n#>       Forest Wetland\n#> 75%   1.2600  0.2800\n#> 80%   2.0020  0.3400\n#> 85%   3.0715  0.4300\n#> 90%   4.2700  0.5700\n#> 95%   5.1400  1.2105\n#> 100% 21.1800  8.8700"},{"path":"bayesian-smoothing-for-post-processing.html","id":"using-the-variance-to-select-values-of-hyperparameters","chapter":"Bayesian smoothing for post-processing","heading":"Using the variance to select values of hyperparameters","text":"make following recommendations setting \\(\\sigma^2_{k}\\) parameter, based local logit variance:Set \\(\\sigma^2_{k}\\) parameter high values (95%-100% range) increase neighborhood influence compared probability values pixel. choice produce denser spatial clusters remove “salt--pepper” outliers.Set \\(\\sigma^2_{k}\\) parameter high values (95%-100% range) increase neighborhood influence compared probability values pixel. choice produce denser spatial clusters remove “salt--pepper” outliers.Set \\(\\sigma^2_{k}\\) parameter low values (75%-80% range) reduce neighborhood influence, classes want preserve original spatial shapes.Set \\(\\sigma^2_{k}\\) parameter low values (75%-80% range) reduce neighborhood influence, classes want preserve original spatial shapes.Consider case forest areas watersheds. expert wishes compact areas classified forests without many outliers inside , set \\(\\sigma^2\\) parameter class Forest high. comparison, avoid small watersheds similar neighbors relabeled, advisable avoid strong influence neighbors, setting \\(\\sigma^2\\) low possible. contrast, transitional classes Clear_Cut_Vegetation likely associated outliers; use large \\(\\sigma^2_{k}\\) .remove outliers classification errors, run smoothing procedure sits_smooth() parameters: () cube, probability cube produced sits_classify(); (b) window_size, local window compute neighborhood probabilities; (d) neigh_fraction, fraction local neighbors used calculate local statistics; (e) smoothness, vector estimates prior variance class; (f) multicores, number CPU cores used processing; (g) memsize, memory available classification; (h) output_dir, directory results stored; () version, version control. resulting cube can visualized plot().parameters window_size neigh_fraction control many pixels neighborhood Bayesian estimator use calculate local statistics. example, setting window size \\(7\\) neigh_fraction \\(0.50\\) (defaults) ensures \\(25\\) samples used estimate local statistics. smoothness values classes set recommended .\nFigure 96: Probability maps bayesian smoothing (source: authors).\nBayesian smoothing removed local variability associated misclassified pixels differ neighbors, specially case transitional classes Clear_Cut_Vegetation. smoothing impact best appreciated comparing labeled map produced without smoothing one follows procedure, shown .\nFigure 97: Final classification map Bayesian smoothing 7 x 7 window, using high smoothness values (source: authors).\nsmoothed map, outliers inside forest areas class borders removed. salt--pepper effect associated transitional classes also replaced coherent estimates. smoothed map shown much improvements compared non-smoothed one. conclusion, post-processing desirable step classification process. Bayesian smoothing improves borders objects created classification removes outliers result pixel-based classification. reliable method used situations.","code":"\n# Compute Bayesian smoothing\nrondonia_20LLQ_smooth <- sits_smooth(\n  cube = rondonia_20LLQ_probs,\n  window_size = 7,\n  neigh_fraction = 0.50,\n  smoothness = c(\n    \"Water\" = 5.0,\n    \"Clear_Cut_Burned_Area\" = 9.5,\n    \"Clear_Cut_Bare_Soil\" = 0.5,\n    \"Clear_Cut_Vegetation\" = 15,\n    \"Forest\" = 2.5,\n    \"Wetland\" = 0.40\n  ),\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp10\"\n)\n\n# Plot the result\nplot(rondonia_20LLQ_smooth, labels = c(\"Clear_Cut_Vegetation\", \"Forest\"))\n# Generate the thematic map\nrondonia_20LLQ_class_v2 <- sits_label_classification(\n  cube = rondonia_20LLQ_smooth,\n  multicores = 4,\n  memsize = 12,\n  output_dir = \"./tempdir/chp10\",\n  version = \"smooth\"\n)\n\nplot(rondonia_20LLQ_class_v2,\n  legend_text_size = 0.7\n)"},{"path":"validation-and-accuracy-measurements.html","id":"validation-and-accuracy-measurements","chapter":"Validation and accuracy measurements","heading":"Validation and accuracy measurements","text":"","code":""},{"path":"validation-and-accuracy-measurements.html","id":"introduction-2","chapter":"Validation and accuracy measurements","heading":"Introduction","text":"Statistically robust transparent approaches assessing accuracy essential parts land classification process. sits package supports “good practice” recommendations designing implementing accuracy assessment change map estimating area based reference sample data. recommendations address three components: sampling design, reference data collection, accuracy estimates [83].\n.\nsampling design implemented random stratified approach, ensuring every land use land cover class population included sample. Sampling designs use established statistical methods aimed providing unbiased estimates. Based chosen design, sits supports selection random samples per class. samples evaluated accurately using high-quality reference data, ideally collected field visits using high-resolution imagery. way, get reference classification accurate map classification evaluated.accuracy assessment reported error matrix. supports estimates overall accuracy, user’s producer’s accuracy. Based error matrix, possible estimate class’s proportion adjust classification errors. estimated area includes confidence intervals.","code":""},{"path":"validation-and-accuracy-measurements.html","id":"example-data-set","chapter":"Validation and accuracy measurements","heading":"Example data set","text":"study area state Rondonia (RO) Brazilian Amazon, total area . According official Brazilian government statistics, 2021, tropical forests RO, corresponds 53% state’s total area. Significant human occupation started 1970, led settlement projects promoted Brazil’s military government [84]. Small large-scale cattle ranching occupies deforested areas. Deforestation Rondonia highly fragmented, partly due original occupation small settlers. fragmentation poses considerable challenges automated methods distinguish clear-cut highly degraded areas. visual interpreters rely upon experience field knowledge, researchers must carefully train automated methods achieve distinction.used Sentinel-2 Sentinel-2A ARD (analysis ready) images 2022-01-01 2022-12-31. Using 10 spectral bands, produced regular data cube 16-day interval, 23 instances per year. best pixels period selected obtain low cloud cover possible. Persistent cloud cover pixels remaining period temporally interpolated obtain estimated values. result, pixel associated valid time series. fully cover RO, used 41 MGRS tiles; final data cube 1.1 TB.work considered nine LUCC classes: () stable natural land cover, including Forest Water; (b) events associated clear-cuts, including Clear_Cut_Vegetation, Clear_Cut_Bare_Soil, Clear_Cut_Burned_Area; (c) natural areas seasonal variability, Wetland, Seasonally_Flooded_Forest, Riparian_Forest; (d) stable forest areas subject topographic effects, including Mountainside_Forest.chapter, take classification map starting point accuracy assessment. map can retrieved sitsdata package follows.\nFigure 98: Classified mosaic land cover Rondonia, Brazil 2022 (source: authors).\n","code":"\n# define the classes of the probability cube\nlabels <- c(\n  \"1\" = \"Clear_Cut_Bare_Soil\",\n  \"2\" = \"Clear_Cut_Burned_Area\",\n  \"3\" = \"Mountainside_Forest\",\n  \"4\" = \"Forest\",\n  \"5\" = \"Riparian_Forest\",\n  \"6\" = \"Clear_Cut_Vegetation\",\n  \"7\" = \"Water\",\n  \"8\" = \"Seasonally_Flooded\",\n  \"9\" = \"Wetland\"\n)\n\n# directory where the data is stored\ndata_dir <- system.file(\"extdata/Rondonia-Class-2022-Mosaic/\", package = \"sitsdata\")\n# create a probability data cube from a file\nrondonia_2022_class <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  bands = \"class\",\n  labels = labels,\n  version = \"mosaic\"\n)\n# plot the classification map\nplot(rondonia_2022_class)"},{"path":"validation-and-accuracy-measurements.html","id":"stratified-sampling-design-and-allocation","chapter":"Validation and accuracy measurements","heading":"Stratified sampling design and allocation","text":"sampling design outlines method selecting subset map, serves foundation accuracy assessment. subset needs satisfy compromise statistical practical consideration. subset needs provide enough data statistically-valid quality assessment, also ensure element sample can evaluated correctly. Selection sample size thus combines expected level user’s accuracy class viable choice size location.Following recommended best practices estimating accuracy LUCC maps [83], sits uses Cochran’s method stratified random sampling [85]. method divides population homogeneous subgroups, strata, applying random sampling within stratum. case LUCC, take classification map basis stratification. area occupied class considered homogeneous subgroup. Cochran’s method stratified random sampling helps increase precision estimates reducing overall variance, particularly significant variability strata relatively less variability within stratum.determine overall number samples measure accuracy, use following formula [85]:\\[\nn = \\left( \\frac{\\sum_{=1}^L W_i S_i}{S(\\hat{O})} \\right)^2\n\\]\n\\(L\\) number classes\\(S(\\hat{O})\\) expected standard error accuracy estimate\\(S_i\\) standard deviation estimated area class \\(\\)\\(W_i\\) mapped proportion area class \\(\\)standard deviation per class (stratum) estimated based expected user’s accuracy \\(U_i\\) class \\[\nS_i = \\sqrt{U_i(1 - U_i)}\n\\]Therefore, total number samples depends assumptions user’s accuracies \\(U_i\\) expected standard error \\(S(\\hat{O})\\). sample size estimated, several methods allocating samples per class[83]. One option proportional allocation, sample size stratum proportional stratum’s size population. land use mapping, classes often small areas compared frequent ones. Using proportional allocation, rare classes small sample sizes decreasing accuracy. Another option equal allocation, classes number samples; however, equal allocation may fail capture natural variation classes large areas.alternatives proportional equal allocation, [83] suggests ad-hoc approaches class assigned minimum number samples. proposes three allocations 50, 75 100 sample units allocated less common classes, proportional allocation used frequent ones. allocation methods considered suggestions, users flexible select alternative sampling designs.allocation methods proposed [83] supported function sits_sampling_design(), following parameters:cube: classified data cube;expected_ua: named vector expected user’s accuracies class;alloc_options: fixed sample allocation rare classes;std_err: expected standard error accuracy estimate;rare_class_prop: proportional area limit determine rare classes.case Rondonia, following sampling design adopted.next step chose one options sampling design generate set points stratified sampling. points can used accuracy assessment. achieved function sits_stratified_sampling() takes following parameters:cube: classified data cube;sampling_design: output function sits_sampling_design();alloc: one sampling allocation options produced sits_sampling_design();overhead: additional proportion number samples per class (see );multicores: number cores run function parallel;shp_file: name shapefile save results later use (optional);progress: show progress bar?example , chose “alloc_120” option sampling design generate set stratified samples. output function sf object points location (latitude longitude) class assigned map. can also generate SHP file sample information. script shows usee sits_stratified_sampling() also convert sf object CSV file.Using CSV file (optional shapefile) users can visualize points standard GIS QGIS. point, indicate correct class. way, obtain confusion matrix used accuracy assessment. overhead parameter useful users discard border doubtful pixels interpreter confident class assignment. discarding points whose attribution uncertain, improve quality assessment.sampling points labelled QGIS (similar), users produce CSV file, SHP file, data frame, sf object, least three columns: latitude, longitude label. See next section example use data set accuracay assessment.","code":"\nro_sampling_design <- sits_sampling_design(\n  cube = rondonia_2022_class,\n  expected_ua = c(\n    \"Clear_Cut_Bare_Soil\" = 0.75,\n    \"Clear_Cut_Burned_Area\" = 0.70,\n    \"Mountainside_Forest\" = 0.70,\n    \"Forest\" = 0.75,\n    \"Riparian_Forest\" = 0.70,\n    \"Clear_Cut_Vegetation\" = 0.70,\n    \"Water\" = 0.70,\n    \"Seasonally_Flooded\" = 0.70,\n    \"Wetland\" = 0.70\n  ),\n  alloc_options = c(120, 100),\n  std_err = 0.01,\n  rare_class_prop = 0.1\n)\n# show sampling desing\nro_sampling_design#>                       prop        expected_ua std_dev equal alloc_120 alloc_100\n#> Clear_Cut_Bare_Soil   0.3841309   0.75        0.433   210   438       496      \n#> Clear_Cut_Burned_Area 0.004994874 0.7         0.458   210   120       100      \n#> Clear_Cut_Vegetation  0.009201698 0.7         0.458   210   120       100      \n#> Forest                0.538726    0.75        0.433   210   614       696      \n#> Mountainside_Forest   0.004555433 0.7         0.458   210   120       100      \n#> Riparian_Forest       0.005482552 0.7         0.458   210   120       100      \n#> Seasonally_Flooded    0.007677294 0.7         0.458   210   120       100      \n#> Water                 0.007682599 0.7         0.458   210   120       100      \n#> Wetland               0.03754864  0.7         0.458   210   120       100      \n#>                       alloc_prop\n#> Clear_Cut_Bare_Soil   727       \n#> Clear_Cut_Burned_Area 9         \n#> Clear_Cut_Vegetation  17        \n#> Forest                1019      \n#> Mountainside_Forest   9         \n#> Riparian_Forest       10        \n#> Seasonally_Flooded    15        \n#> Water                 15        \n#> Wetland               71\nro_samples_sf <- sits_stratified_sampling(\n  cube = rondonia_2022_class,\n  sampling_design = ro_sampling_design,\n  alloc = \"alloc_120\",\n  multicores = 4,\n  shp_file = \"./tempdir/chp11/ro_samples.shp\"\n)#> Writing layer `ro_samples' to data source \n#>   `./tempdir/chp11/ro_samples.shp' using driver `ESRI Shapefile'\n#> Writing 2261 features with 1 fields and geometry type Point.\n# save sf object as CSV file\nsf::st_write(ro_samples_sf,\n  \"./tempdir/chp11/ro_samples.csv\",\n  layer_options = \"GEOMETRY=AS_XY\",\n  append = FALSE\n)#> Writing layer `ro_samples' to data source \n#>   `./tempdir/chp11/ro_samples.csv' using driver `CSV'\n#> options:        GEOMETRY=AS_XY \n#> Writing 2261 features with 1 fields and geometry type Point."},{"path":"validation-and-accuracy-measurements.html","id":"accuracy-assessment-of-classified-images","chapter":"Validation and accuracy measurements","heading":"Accuracy assessment of classified images","text":"measure accuracy classified images, sits_accuracy() uses area-weighted technique, following best practices proposed Olofsson et al. [86]. need area-weighted estimates arises land classes evenly distributed space. applications (e.g., deforestation) interest lies assessing much image changed, area mapped deforested likely small fraction total area. users disregard relative importance small areas change taking place, overall accuracy estimate inflated unrealistic. reason, Olofsson et al. argue “mapped areas adjusted eliminate bias attributable map classification error, error-adjusted area estimates accompanied confidence intervals quantify sampling variability estimated area” [86].motivation, measuring accuracy classified images, sits_accuracy() follows procedure set Olofsson et al. [86]. Given classified image validation file, first step calculates confusion matrix traditional way, .e., identifying commission omission errors. calculates unbiased estimator proportion area cell \\(,j\\) error matrix\\[\n\\hat{p_{,j}} = W_i\\frac{n_{,j}}{n_i},\n\\]\ntotal area map \\(A_{tot}\\), mapping area class \\(\\) \\(A_{m,}\\) proportion area mapped class \\(\\) \\(W_i = {A_{m,}}/{A_{tot}}\\). Adjusting area size allows producing unbiased estimation total area class \\(j\\), defined stratified estimator\n\\[\n\\hat{A_j} = A_{tot}\\sum_{=1}^KW_i\\frac{n_{,j}}{n_i}.\n\\]unbiased area estimator includes effect false negatives (omission error) considering effect false positives (commission error). area estimates also allow unbiased estimate user’s producer’s accuracy class. Following Olofsson et al. [86], provide 95% confidence interval \\(\\hat{A_j}\\).produce adjusted area estimates classified maps, sits_accuracy() uses following parameters:data: classified data cube;validation: CSV file, SHP file, GPKG file, sf object data frame containing least three columns: latitude, longitude label, containing set well-selected labeled points obtained samples suggested sits_stratified_sample().example , use validation set produced researchers produced Rondonia data set, described . selected data set serve example sits_accuracy() illustrate pitfalls using visual interpretation results image time series classification. case, validation team used image single date late 2022 assess results. choice adequate assessing results time series classification. many cases, including example used chapter, training set includes transitional classes Clear_Cut_Burned_Area Clear_Cut_Vegetation. associated samples refer events occur specific times year. area may start year Forest land cover, cut burned peak dry season later completely clean. classifier recognize signs burned area signal event occurred. using single date evaluate classification results, correct estimate classifier missed interpreter. reason, results shown merely illustrative reflect correct accuracy assessment.validation team used QGIS produce CSV file validation data, used assess area accuracy using best practices recommended [83].confusion matrix also available, follows.results show challenges conducting validation assessments image time series. stable classes like Forest Clear_Cut_Bare_Soil exhibit high user’s accuracy (UA) producer’s accuracy (PA), transitional classes (Clear_Cut_Burned_Area Clear_Cut_Vegetation) low PA. discrepancy true reflection classification accuracy, rather result inadequate visual interpretation practices. mentioned earlier, visual interpretation quality assessment utilised single date, method traditionally used single images, ineffective image time series.detailed examination confusion matrix reveals clear distinction natural areas (e.g., Forest Riparian_Forest) areas associated deforestation (e.g., Clear_Cut_Bare_Soil Clear_Cut_Burned_Area). low producer’s accuracy values transitional classes Clear_Cut_Burned_Area Clear_Cut_Vegetation artefacts validation procedure. Validation relied one date near end calendar year, causing transitional classes overlooked.chapter provides example recommended statistical methods designing stratified samples accuracy assessment. However, sampling methods depend perfect near-perfect validation end-users. Ensuring best practices accuracy assessment involves well-designed sample set sample interpretation aligns classifier’s training set.","code":"\n# Get ground truth points\nvalid_csv <- system.file(\"extdata/Rondonia-Class-2022-Mosaic/rondonia_samples_validation.csv\",\n  package = \"sitsdata\"\n)\n# Calculate accuracy according to Olofsson's method\narea_acc <- sits_accuracy(rondonia_2022_class,\n  validation = valid_csv,\n  multicores = 4\n)\n# Print the area estimated accuracy\narea_acc#> Area Weighted Statistics\n#> Overall Accuracy = 0.84\n#> \n#> Area-Weighted Users and Producers Accuracy\n#>                       User Producer\n#> Clear_Cut_Bare_Soil   0.82     1.00\n#> Clear_Cut_Burned_Area 0.88     0.08\n#> Mountainside_Forest   0.69     0.05\n#> Forest                0.85     1.00\n#> Riparian_Forest       0.66     0.58\n#> Clear_Cut_Vegetation  0.82     0.24\n#> Water                 0.97     0.67\n#> Seasonally_Flooded    0.86     0.68\n#> Wetland               0.87     0.69\n#> \n#> Mapped Area x Estimated Area (ha)\n#>                       Mapped Area (ha) Error-Adjusted Area (ha)\n#> Clear_Cut_Bare_Soil          9537617.8                7787913.8\n#> Clear_Cut_Burned_Area         124018.1                1383784.0\n#> Mountainside_Forest           113107.2                1665469.0\n#> Forest                      13376070.4               11377193.6\n#> Riparian_Forest               136126.7                 155704.6\n#> Clear_Cut_Vegetation          228469.7                 766171.1\n#> Water                         190751.9                 275599.8\n#> Seasonally_Flooded            190620.2                 241225.8\n#> Wetland                       932298.3                1176018.6\n#>                       Conf Interval (ha)\n#> Clear_Cut_Bare_Soil            321996.87\n#> Clear_Cut_Burned_Area          278746.61\n#> Mountainside_Forest            299925.62\n#> Forest                         333181.28\n#> Riparian_Forest                 60452.25\n#> Clear_Cut_Vegetation           186476.04\n#> Water                           78786.79\n#> Seasonally_Flooded              58098.50\n#> Wetland                        163726.86\narea_acc$error_matrix#>                        \n#>                         Clear_Cut_Bare_Soil Clear_Cut_Burned_Area\n#>   Clear_Cut_Bare_Soil                   415                    65\n#>   Clear_Cut_Burned_Area                   1                    42\n#>   Mountainside_Forest                     1                     0\n#>   Forest                                  0                     0\n#>   Riparian_Forest                         4                     0\n#>   Clear_Cut_Vegetation                    1                    17\n#>   Water                                   0                     0\n#>   Seasonally_Flooded                      0                     0\n#>   Wetland                                 0                     2\n#>                        \n#>                         Mountainside_Forest Forest Riparian_Forest\n#>   Clear_Cut_Bare_Soil                     0      0               0\n#>   Clear_Cut_Burned_Area                   0      0               0\n#>   Mountainside_Forest                    22      9               0\n#>   Forest                                 95    680               3\n#>   Riparian_Forest                         4      5             111\n#>   Clear_Cut_Vegetation                    0      0               0\n#>   Water                                   0      0               3\n#>   Seasonally_Flooded                      0      0               1\n#>   Wetland                                 0      0               1\n#>                        \n#>                         Clear_Cut_Vegetation Water Seasonally_Flooded Wetland\n#>   Clear_Cut_Bare_Soil                     10     3                  1      15\n#>   Clear_Cut_Burned_Area                    1     0                  1       3\n#>   Mountainside_Forest                      0     0                  0       0\n#>   Forest                                  19     2                  0       3\n#>   Riparian_Forest                         43     0                  0       0\n#>   Clear_Cut_Vegetation                    82     0                  0       0\n#>   Water                                    0   121                  1       0\n#>   Seasonally_Flooded                       0     1                118      18\n#>   Wetland                                  4     0                  6      88"},{"path":"uncertainty-and-active-learning.html","id":"uncertainty-and-active-learning","chapter":"Uncertainty and active learning","heading":"Uncertainty and active learning","text":"Land classification tasks unique characteristics differ machine learning domains, image recognition natural language processing. main challenge land classification describe diversity planet’s landscapes handful labels. However, diversity world’s ecosystem makes classification systems biased approximations reality. stated Murphy: “gradation properties world means smallish number categories never map perfectly onto objects” [87]. reason, sits provides tools improve classifications using process called active learning.Active learning iterative process sample selection, labeling, model retraining. following steps provide general overview use active learning:Collect initial training samples: Start collecting small set representative training samples cover range land classes interest.Train machine learning model: Use initial training samples train machine learning model classify remote sensing data.Classify data cube using model.Identify areas uncertainty.Select samples re-labeling: Select set unlabeled samples model uncertain , .e., model least confident classifying.Label selected samples: user labels selected samples, adding training set.Retrain model: model retrained using newly labeled samples, process repeats , starting step 2.Stop classification accuracy satisfactory: iterative process continues classification accuracy reaches satisfactory level.traditional classification methods, experts provide set training samples use machine learning algorithm produce map. contrast, active learning approach puts human loop [88]. iteration, unlabeled set samples presented user, assigns classes includes training set [89]. process repeated expert satisfied result, shown Figure 99.\nFigure 99: Active learning approach (Source: Crawford et al. (2013). Reproduction fair use doctrine).\nActive learning aims reduce bias errors sample selection , , improve accuracy result. interaction, experts asked review pixels machine learning classifier indicates high uncertainty value. Sources classification uncertainty include missing classes mislabeled samples. sits, active learning supported functions sits_uncertainty() sits_uncertainty_sampling().","code":""},{"path":"uncertainty-and-active-learning.html","id":"measuring-uncertainty","chapter":"Uncertainty and active learning","heading":"Measuring uncertainty","text":"Uncertainty refers degree doubt ambiguity accuracy classification results. Several sources uncertainty can arise land classification using satellite data, including:Classification errors: can occur classification algorithm misinterprets spectral, spatial temporal characteristics input data, leading misclassification land classes.Ambiguity classification schema: definition land classes can ambiguous subjective, leading inconsistencies classification results.Variability landscape: Natural human-induced variations landscape can make difficult accurately classify land areas.Limitations data: quality quantity input data can influence accuracy classification results.Quantifying uncertainty land classification important ensuring results reliable valid decision-making. Various methods, confusion error matrices, can used estimate visualize level uncertainty classification results. Additionally, incorporating uncertainty estimates decision-making processes can help identify regions investigation data collection needed.function sits_uncertainty() calculates uncertainty cube based probabilities produced classifier. takes probability cube input. uncertainty measure relevant context active learning. helps increase quantity quality training samples providing information model’s confidence. supported types uncertainty ‘entropy’, ‘least’, ‘margin’, ‘ratio’.Least confidence sampling difference uncertainty (100% confidence) probability likely class, normalized number classes. Let \\(P_1()\\) higher class probability pixel \\(\\). least confidence sampling expressed \\[\n\\theta_{LC} = (1 - P_1()) * \\frac{n}{n-1}.\n\\]margin confidence sampling difference two confident predictions, expressed 0% (uncertainty) 100% (maximum uncertainty). Let \\(P_1()\\) \\(P_2()\\) two higher class probabilities pixel \\(\\). , margin confidence expressed \\[\n\\theta_{MC} = 1 - (P_1() - P_2()).\n\\]ratio confidence measure ratio two confident predictions, expressed range 0% (uncertainty) 100% (maximum uncertainty). Let \\(P_1()\\) \\(P_2()\\) two higher class probabilities pixel \\(\\). , ratio confidence expressed \n\\[\n\\theta_{RC} = \\frac{P_2()}{P_1()}.\n\\]Entropy measure uncertainty used Claude Shannon classic work “Mathematical Theory Communication”. related amount variability probabilities associated pixel. lower variability, lower entropy. Let \\(P_k()\\) probability class \\(k\\) pixel \\(\\). entropy calculated \n\\[\n\\theta_{E} = \\frac{-\\sum_{k=1}^K P_k() * log_2(P_k())}{log_2{n}}.\n\\]parameters sits_uncertainty() : cube, probability data cube; type, uncertainty measure (default least). processing functions, multicores number cores run function memsize maximum overall memory (GB) run function, output_dir output directory image files, version result version.","code":""},{"path":"uncertainty-and-active-learning.html","id":"using-uncertainty-measures-for-active-learning","chapter":"Uncertainty and active learning","heading":"Using uncertainty measures for active learning","text":"following case study shows uncertainty measures can used context active learning. study area subset one Sentinel-2 tile state Rondonia, Brazil. work aims detect deforestation Brazilian Amazonia.study area close Samuel Hydroelectric Dam, located Madeira River Brazilian state Rondônia. Building dam led loss 56,000 ha native forest. dam’s construction caused displacement several indigenous communities traditional populations, leading social cultural disruption. Additionally, flooding large forest areas resulted losing habitats biodiversity, including several endangered species. dam altered natural flow Madeira River, leading changes water quality temperature affecting aquatic life depends river. changes river flow also impacted navigation transportation activities local communities [90].first step produce regular data cube chosen area 2020-06-01 2021-09-01. reduce processing time storage, use three bands (B02, B8A, B11) plus cloud band, take small area inside tile. obtaining regular cube, plot study area two dates temporal interval data cube. first image taken beginning dry season 2020-07-04, inundation area dam covered shallow water.\nFigure 100: Area Rondonia near Samuel dam (source: authors).\nsecond image 2020-11-09 shows inundation area dries dry season. early November 2020, end dry season, inundation area dry response similar bare soil burned areas. Madeira River can seen running dried inundation area.\nFigure 101: Area Rondonia near Samuel dam November 2021 (source: authors).\nthird image 2021-08-08. early August 2021, wet season, inundation area covered shallow water layer. Several burned clear-cut areas can also seen August 2021 image compared July 2020 one. Given contrast wet dry seasons, correct land classification area hard.\nFigure 102: Area Rondonia near Samuel dam August 2021 (source: authors).\nnext step classify study area using training set 480 times series collected state Rondonia (Brazil) detecting deforestation. training set uses 4 classes (Burned_Area, Forest,Highly_Degraded, andCleared_Area`). cube classified using Random Forest model, post-processed Bayesian smoothing, labeled.\nFigure 103: Classified map area Rondonia near Samuel dam (source: authors).\nresulting map correctly identifies forest area deforestation. However, wrongly classifies area covered Samuel hydroelectric dam. reason lack samples classes related surface water wetlands. improve classification, need improve samples. , first step calculate uncertainty classification.\nFigure 104: Uncertainty map classification Rondonia near Samuel dam (source: authors).\nexpected, places highest uncertainty covered surface water associated wetlands. places likely misclassified. reason, sits provides sits_uncertainty_sampling(), takes uncertainty cube input produces tibble locations WGS84 high uncertainty. function three parameters: n, number uncertain points included; min_uncert, minimum value uncertainty pixels included list; sampling_window, defines window one sample selected. aim sampling_window improve spatial distribution new samples avoiding points neighborhood included. running function, can use sits_view() visualize location samples.\nFigure 105: Location uncertain pixel classification Rondonia near Samuel dam (source: authors).\nvisualization shows samples located areas covered Samuel data. Thus, designate samples Wetlands. detailed evaluation, recommended practice, requires analysing samples exploration software QGIS individually labeling sample. case, take direct approach illustration purposes.\nFigure 106: New land classification Rondonia near Samuel dam (source: authors).\nresults show significant quality gain earlier classification. still areas confusion exposed soils inside inundation area, classified burned areas. also useful show uncertainty map associated second model.\nFigure 107: Uncertainty map classification Rondonia near Samuel dam - improved model (source: authors).\nnew uncertainty map shows, significant improvement quality classification. remaining areas high uncertainty affected contrast wet dry seasons close inundation area. areas low-laying places sometimes covered water sometimes bare soil areas throughout year, depending intensity rainy season. improve classification quality, obtain new samples uncertain areas, label , add samples. general, Chapter shows, combining uncertainty measurements active learning recommended practice improving classification results.","code":"\n# Select a S2 tile\ns2_cube_ro <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  tiles = \"20LMR\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"SCL\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2021-09-01\"),\n  progress = FALSE\n)\n\n# Select a small area inside the tile\nroi <- c(\n  lon_max = -63.25790, lon_min = -63.6078,\n  lat_max = -8.72290, lat_min = -8.95630\n)\n# Regularize the small area cube\ns2_reg_cube_ro <- sits_regularize(\n  cube = s2_cube_ro,\n  output_dir = \"./tempdir/chp12/\",\n  res = 20,\n  roi = roi,\n  period = \"P16D\",\n  multicores = 4,\n  progress = FALSE\n)\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-07-04\"\n)\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-11-09\"\n)\nplot(s2_reg_cube_ro, red = \"B11\", green = \"B8A\", blue = \"B02\", date = \"2021-08-08\")\nlibrary(sitsdata)\n# Load the training set\ndata(\"samples_prodes_4classes\")\n# Select the same three bands used in the data cube\nsamples_4classes_3bands <- sits_select(\n  data = samples_prodes_4classes,\n  bands = c(\"B02\", \"B8A\", \"B11\")\n)\n\n# Train a random forest model\nrfor_model <- sits_train(\n  samples = samples_4classes_3bands,\n  ml_method = sits_rfor()\n)\n\n# Classify the small area cube\ns2_cube_probs <- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = rfor_model,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 15,\n  multicores = 5\n)\n\n# Post-process the probability cube\ns2_cube_bayes <- sits_smooth(\n  cube = s2_cube_probs,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the post-processed  probability cube\ns2_cube_label <- sits_label_classification(\n  cube = s2_cube_bayes,\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_label)\n# Calculate the uncertainty cube\ns2_cube_uncert <- sits_uncertainty(\n  cube = s2_cube_bayes,\n  type = \"margin\",\n  output_dir = \"./tempdir/chp12/\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert)\n# Find samples with high uncertainty\nnew_samples <- sits_uncertainty_sampling(\n  uncert_cube = s2_cube_uncert,\n  n = 20,\n  min_uncert = 0.5,\n  sampling_window = 10\n)\n\n# View the location of the samples\nsits_view(new_samples)\n# Label the new samples\nnew_samples$label <- \"Wetland\"\n# Obtain the time series from the regularized cube\nnew_samples_ts <- sits_get_data(\n  cube = s2_reg_cube_ro,\n  samples = new_samples\n)\n\n# Join the new samples with the original ones with 4 classes\nsamples_round_2 <- dplyr::bind_rows(\n  samples_4classes_3bands,\n  new_samples_ts\n)\n\n# Train a RF model with the new sample set\nrfor_model_v2 <- sits_train(\n  samples = samples_round_2,\n  ml_method = sits_rfor()\n)\n\n# Classify the small area cube\ns2_cube_probs_v2 <- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = rfor_model_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Post-process the probability cube\ns2_cube_bayes_v2 <- sits_smooth(\n  cube = s2_cube_probs_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Label the post-processed  probability cube\ns2_cube_label_v2 <- sits_label_classification(\n  cube = s2_cube_bayes_v2,\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\n# Plot the second version of the classified cube\nplot(s2_cube_label_v2)\n# Calculate the uncertainty cube\ns2_cube_uncert_v2 <- sits_uncertainty(\n  cube = s2_cube_bayes_v2,\n  type = \"margin\",\n  output_dir = \"./tempdir/chp12/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert_v2)"},{"path":"ensemble-prediction-from-multiple-models.html","id":"ensemble-prediction-from-multiple-models","chapter":"Ensemble prediction from multiple models","heading":"Ensemble prediction from multiple models","text":"Ensemble prediction powerful technique combining predictions multiple models produce accurate robust predictions. Errors individual models cancel reduced combined predictions models. result, ensemble predictions can lead better overall accuracy reduce risk overfitting. can especially useful working complex uncertain data. combining predictions multiple models, users can identify features factors important making accurate predictions. using ensemble methods, choosing diverse models different sources error essential ensure ensemble predictions precise robust.sits package provides sits_combine_predictions() estimate ensemble predictions using probability cubes produced sits_classify() optionally post-processed sits_smooth(). two ways make ensemble predictions multiple models:Averaging: approach, predictions model averaged produce final prediction. method works well models similar accuracy errors.Averaging: approach, predictions model averaged produce final prediction. method works well models similar accuracy errors.Uncertainty: Predictions different models compared terms uncertainties pixel--pixel basis; predictions lower uncertainty chosen likely valid.Uncertainty: Predictions different models compared terms uncertainties pixel--pixel basis; predictions lower uncertainty chosen likely valid.follows, use sample dataset data cube used Chapter Image classification data cubes illustrate produce ensemble prediction. dataset samples_deforestation_rondonia consists 6007 samples collected Sentinel-2 images covering state Rondonia. time series contains values Sentinel-2/2A spectral bands year 2022 16-day intervals. data cube subset Sentinel-2 tile “20LMR” contains spectral bands, plus spectral indices “NVDI”, “EVI” “NBR” year 2022.first step recover data cube available sitsdata package, select spectral bands.\nFigure 108: Subset Sentinel-2 tile 20LMR ((©: EU Copernicus Sentinel Programme; source: Microsoft).\ntrain three models: Random Forests (RF), Light Temporal Attention Encoder (LTAE), Temporal Convolution Neural Networks (TempCNN), classify cube , combine results. example uses spectral bands. first run RF classification.Based variance values, apply smoothness hyperparameter according recommendations proposed . choose values \\(\\sigma^2_{k}\\) reflect prior expectation spatial patterns class. classes Clear_Cut_Vegetation Clear_Cut_Burned_Area, produce denser spatial clusters remove “salt--pepper” outliers, take \\(\\sigma^2_{k}\\) values 95%-100% range. case frequent classes Forest Clear_Cut_Bare_Soil want preserve original spatial shapes much possible; logic applies less frequent classes Water Wetland. reason, set \\(\\sigma^2_{k}\\) values 75%-80% range classes. class spatial patterns correspond prior expectations.\nFigure 109: Land classification Rondonia using random forest algorithm (source: authors).\nnext step classify area using tempCNN algorithm, shown .\nFigure 110: Land classification Rondonia using tempCNN (source: authors).\nthird model Light Temporal Attention Encoder (LTAE), discussed.use rationale selecting smoothness parameter Bayesian smoothing operation cases .\nFigure 111: Land classification Rondonia using tempCNN (source: authors).\nunderstand differences results, useful compare resulting class areas produced different algorithms.study area presents many challenges land classification, given presence wetlands, riparian forests seasonally-flooded areas. results show algorithms obtain quite different results, since model different sensitivities. RF method biased towards frequent classes, especially Clear_Cut_Bare_Soil Forest. area estimated RF class Clear_Cut_Burned_Area smallest three models. pixels assigned LTAE TCNN burned areas assigned RF areas bare soil. RF algorithm tends conservative. reason RF decision-making uses values single attributes (values single band given time instance), LTAE TCNN consider relations instances time series. Since RF model sensitive response images end period, tends focus values indicate presence forests bare soils dry season, peaks August. LTAE model balanced overall separation classes entire attribute space, produces larger estimates riparian seasonally flooded forest methods. contrast, LTAE TCNN make mistakes RF including flooded areas center-left part image left side rives Clear_Cut_Vegetation right label riparian flooded forests.Given differences complementaries three predicted outcomes, combining using sits_combine_predictions() useful. function takes following arguments: () cubes, list cubes combined. cubes probability cubes generated optionally may smoothened; (b) type, indicates combine probability maps. options average, performs weighted mean probabilities, uncertainty, uses uncertainty cubes combine predictions; (c) weights, vector weights used combine predictions average selected; (d) uncertainty_cubes, list uncertainty cubes associated predictions; (e) multicores, number cores used; (f) memsize, RAM used classification; (g) output_dir, directory classified raster files written.\nFigure 112: Land classification Rondonia using average probabilities produced Random Forest SVM algorithms (source: authors).\ncan also consider class areas produced ensemble combination compare original estimates.expected, ensemble map combines information three models. Taking RF model prediction base, reduction areas classes Clear_Cut_Bare_Soil Forest, confirming tendency RF model overemphasize frequent classes. LTAE TempCNN models sensitive class variations capture time-varying classes Riparian_Forest Clear_Cut_Burned_Area detail RF model. However, TempCNN LTAE tend confuse deforestation-related class Clear_Cut_Vegetation natural class Riparian_Forest RF model. effect evident left bank Madeira river centre-left region image. Also, LTAE TempCNN maps grainy spatial variability RF map.average map provides compromise RF’s strong empahsis frequent classes tendency deep learning methods produce outliers based temporal relationship. average map less grainy spatially consistent LTAE TempCNN maps, introducing variability present RF map.chapter shows possibilities ensemble prediction. many ways get better results presented . Increasing number spectral bands improve final accuracy. Also, Bayesian smoothing deep learning models rely default parameters; rather needs rely variance analysis, increase spatial window provide informed hyperparameters. general, ensemble prediction consider situations one satisfied results individual models. Combining model output increses reliability result thus shouls considered situations similar classes present.","code":"\n# Files are available in a local directory\ndata_dir <- system.file(\"extdata/Rondonia-20LMR/\", package = \"sitsdata\")\n# Read data cube\nro_cube_20LMR <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir\n)\n# reduce the number of bands\nro_cube_20LMR <- sits_select(\n  data = ro_cube_20LMR,\n  bands = c(\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B11\", \"B12\", \"B8A\")\n)\n# plot one time step of the cube\nplot(ro_cube_20LMR, blue = \"B02\", green = \"B8A\", red = \"B11\", date = \"2022-08-17\")\n# train a random forest model\nrfor_model <- sits_train(samples_deforestation_rondonia, sits_rfor())\n# classify the data cube\nro_cube_20LMR_rfor_probs <- sits_classify(\n  ro_cube_20LMR,\n  rfor_model,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"rfor\"\n)\n\nro_cube_20LMR_rfor_variance <- sits_variance(\n  ro_cube_20LMR_rfor_probs,\n  window_size = 9,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"rfor\"\n)\nsummary(ro_cube_20LMR_rfor_variance)#>      Clear_Cut_Bare_Soil Clear_Cut_Burned_Area Clear_Cut_Vegetation  Forest\n#> 75%                 4.73                4.8225                0.380  0.9000\n#> 80%                 5.29                5.3020                0.460  1.2500\n#> 85%                 5.64                5.6400                0.570  1.9915\n#> 90%                 5.98                5.9900                0.830  4.0500\n#> 95%                 6.62                6.6605                4.261  6.3800\n#> 100%               18.44               16.1800               13.390 23.4400\n#>      Mountainside_Forest Riparian_Forest Seasonally_Flooded   Water Wetland\n#> 75%               0.8000          0.9800               0.35  1.0300    4.71\n#> 80%               2.2000          1.4520               0.45  1.5100    5.23\n#> 85%               4.0415          2.6115               0.65  2.3800    5.63\n#> 90%               5.4400          4.3800               1.08  3.8000    5.97\n#> 95%               6.4200          6.0200               3.15  7.5715    6.49\n#> 100%             12.5200         29.5500              18.67 51.5200   17.74\nro_cube_20LMR_rfor_bayes <- sits_smooth(\n  ro_cube_20LMR_rfor_probs,\n  output_dir = \"./tempdir/chp13\",\n  smoothness = c(\n    \"Clear_Cut_Bare_Soil\" = 5.25,\n    \"Clear_Cut_Burned_Area\" = 15.0,\n    \"Clear_Cut_Vegetation\" = 12.0,\n    \"Forest\" = 1.8,\n    \"Mountainside_Forest\" = 6.5,\n    \"Riparian_Forest\" = 6.0,\n    \"Seasonally_Flooded\" = 3.5,\n    \"Water\" = 1.5,\n    \"Wetland\" = 5.5\n  ),\n  multicores = 6,\n  memsize = 24,\n  version = \"rfor\"\n)\nro_cube_20LMR_rfor_class <- sits_label_classification(\n  ro_cube_20LMR_rfor_bayes,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"rfor\"\n)\nplot(ro_cube_20LMR_rfor_class,\n  legend_text_size = 0.7, legend_position = \"outside\"\n)\n# train a tempcnn model\ntcnn_model <- sits_train(\n  samples_deforestation_rondonia,\n  sits_tempcnn()\n)\n\n# classify the data cube\nro_cube_20LMR_tcnn_probs <- sits_classify(\n  ro_cube_20LMR,\n  tcnn_model,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 2,\n  memsize = 8,\n  gpu_memory = 8,\n  version = \"tcnn\"\n)\n\nro_cube_20LMR_tcnn_variance <- sits_variance(\n  ro_cube_20LMR_tcnn_probs,\n  window_size = 9,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"tcnn\"\n)\nsummary(ro_cube_20LMR_tcnn_variance)\nro_cube_20LMR_tcnn_bayes <- sits_smooth(\n  ro_cube_20LMR_tcnn_probs,\n  output_dir = \"./tempdir/chp13\",\n  window_size = 11,\n  smoothness = c(\n    \"Clear_Cut_Bare_Soil\" = 1.5,\n    \"Clear_Cut_Burned_Area\" = 20.0,\n    \"Clear_Cut_Vegetation\" = 25.0,\n    \"Forest\" = 4.0,\n    \"Mountainside_Forest\" = 3.0,\n    \"Riparian_Forest\" = 40.0,\n    \"Seasonally_Flooded\" = 30.0,\n    \"Water\" = 1.0,\n    \"Wetland\" = 2.0\n  ),\n  multicores = 2,\n  memsize = 6,\n  version = \"tcnn\"\n)\nro_cube_20LMR_tcnn_class <- sits_label_classification(\n  ro_cube_20LMR_tcnn_bayes,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 2,\n  memsize = 6,\n  version = \"tcnn\"\n)\nplot(ro_cube_20LMR_tcnn_class,\n  legend_text_size = 0.7, legend_position = \"outside\"\n)\n# train a tempcnn model\nltae_model <- sits_train(samples_deforestation_rondonia, sits_lighttae())\n\n# classify the data cube\nro_cube_20LMR_ltae_probs <- sits_classify(\n  ro_cube_20LMR,\n  ltae_model,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 2,\n  memsize = 8,\n  gpu_memory = 8,\n  version = \"ltae\"\n)\n\nro_cube_20LMR_ltae_variance <- sits_variance(\n  ro_cube_20LMR_ltae_probs,\n  window_size = 9,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 6,\n  memsize = 24,\n  version = \"ltae\"\n)\nsummary(ro_cube_20LMR_ltae_variance)\nro_cube_20LMR_ltae_bayes <- sits_smooth(\n  ro_cube_20LMR_tcnn_probs,\n  output_dir = \"./tempdir/chp13\",\n  window_size = 11,\n  smoothness = c(\n    \"Clear_Cut_Bare_Soil\" = 1.2,\n    \"Clear_Cut_Burned_Area\" = 10.0,\n    \"Clear_Cut_Vegetation\" = 15.0,\n    \"Forest\" = 4.0,\n    \"Mountainside_Forest\" = 8.0,\n    \"Riparian_Forest\" = 25.0,\n    \"Seasonally_Flooded\" = 30.0,\n    \"Water\" = 0.3,\n    \"Wetland\" = 1.8\n  ),\n  multicores = 2,\n  memsize = 6,\n  version = \"ltae\"\n)\nro_cube_20LMR_ltae_class <- sits_label_classification(\n  ro_cube_20LMR_ltae_bayes,\n  output_dir = \"./tempdir/chp13\",\n  multicores = 2,\n  memsize = 6,\n  version = \"ltae\"\n)\nplot(ro_cube_20LMR_ltae_class,\n  legend_text_size = 0.7, legend_position = \"outside\"\n)\n# get the summary of the map produced by RF\nsum1 <- summary(ro_cube_20LMR_rfor_class) |>\n  dplyr::select(\"class\", \"area_km2\")\ncolnames(sum1) <- c(\"class\", \"rfor\")\n# get the summary of the map produced by TCNN\nsum2 <- summary(ro_cube_20LMR_tcnn_class) |>\n  dplyr::select(\"class\", \"area_km2\")\ncolnames(sum2) <- c(\"class\", \"tcnn\")\n# get the summary of the map produced by LTAE\nsum3 <- summary(ro_cube_20LMR_ltae_class) |>\n  dplyr::select(\"class\", \"area_km2\")\ncolnames(sum3) <- c(\"class\", \"ltae\")\n# compare class areas of non-smoothed and smoothed maps\ndplyr::inner_join(sum1, sum2, by = \"class\") |>\n  dplyr::inner_join(sum3, by = \"class\")#> # A tibble: 9 × 4\n#>   class                     rfor    tcnn    ltae\n#>   <chr>                    <dbl>   <dbl>   <dbl>\n#> 1 Clear_Cut_Bare_Soil    80       67      66    \n#> 2 Clear_Cut_Burned_Area   1.7      4.4     4.5  \n#> 3 Clear_Cut_Vegetation   19       18      18    \n#> 4 Forest                280      240     240    \n#> 5 Mountainside_Forest     0.0088   0.065   0.051\n#> 6 Riparian_Forest        47       45      44    \n#> 7 Seasonally_Flooded     70      120     120    \n#> 8 Water                  63       67      67    \n#> 9 Wetland                14       11      11\n# Combine the two predictions by taking the average of the probabilities for each class\nro_cube_20LMR_average_probs <- sits_combine_predictions(\n  cubes = list(\n    ro_cube_20LMR_tcnn_bayes,\n    ro_cube_20LMR_rfor_bayes,\n    ro_cube_20LMR_ltae_bayes\n  ),\n  type = \"average\",\n  version = \"average-rfor-tcnn-ltae\",\n  output_dir = \"./tempdir/chp13/\",\n  weights = c(0.33, 0.34, 0.33),\n  memsize = 16,\n  multicores = 4\n)\n# Label the average probability cube\nro_cube_20LMR_average_class <- sits_label_classification(\n  cube = ro_cube_20LMR_average_probs,\n  output_dir = \"./tempdir/chp13/\",\n  version = \"average-rfor-tcnn-ltae\",\n  memsize = 16,\n  multicores = 4\n)\n# Plot the second version of the classified cube\nplot(ro_cube_20LMR_average_class,\n  legend_text_size = 0.7, legend_position = \"outside\"\n)\n# get the summary of the map produced by LTAE\nsum4 <- summary(ro_cube_20LMR_average_class) |>\n  dplyr::select(\"class\", \"area_km2\")\ncolnames(sum4) <- c(\"class\", \"ave\")\n# compare class areas of non-smoothed and smoothed maps\ndplyr::inner_join(sum1, sum2, by = \"class\") |>\n  dplyr::inner_join(sum3, by = \"class\") |>\n  dplyr::inner_join(sum4, by = \"class\")#> # A tibble: 9 × 5\n#>   class                     rfor    tcnn    ltae     ave\n#>   <chr>                    <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 Clear_Cut_Bare_Soil    80       67      66      70    \n#> 2 Clear_Cut_Burned_Area   1.7      4.4     4.5     4    \n#> 3 Clear_Cut_Vegetation   19       18      18      16    \n#> 4 Forest                280      240     240     250    \n#> 5 Mountainside_Forest     0.0088   0.065   0.051   0.036\n#> 6 Riparian_Forest        47       45      44      46    \n#> 7 Seasonally_Flooded     70      120     120     110    \n#> 8 Water                  63       67      67      67    \n#> 9 Wetland                14       11      11      11"},{"path":"object-based-time-series-image-analysis.html","id":"object-based-time-series-image-analysis","chapter":"Object-based time series image analysis","heading":"Object-based time series image analysis","text":"Object-Based Image Analysis (OBIA) approach remote sensing image analysis partitions image closed segments classified analyzed. high-resolution images (1 meter smaller) aim OBIA create objects represent meaningful features real world, like buildings, roads, fields, forests, water bodies. case medium resolution images (Sentinel-2 Landsat) segments represent groups image similar spectral responses general correspond directly individual objects ground. groups pixels called super-pixels. situations, aim OBIA obtain spatial partition image can assigned single class. applicable, OBIA reduces processing time produces labeled maps greater spatial consistency.general sequence processes involved OBIA sits :Segmentation: first step group together pixels similar based distance metric considers values bands time instances. build multitemporal attribute space time/band combination taken independent dimension. Thus, distance metrics segmentation data cube 10 bands 24 time steps use 240-dimension space.Segmentation: first step group together pixels similar based distance metric considers values bands time instances. build multitemporal attribute space time/band combination taken independent dimension. Thus, distance metrics segmentation data cube 10 bands 24 time steps use 240-dimension space.Probability Estimation: image partitioned distinct objects, next step classify segment. satellite image time series, subset time series inside segment classified.Probability Estimation: image partitioned distinct objects, next step classify segment. satellite image time series, subset time series inside segment classified.Labeling: set probabilities obtained time series inside segment, can used labeling. done considering median value probabilities time series inside segment classified. class, take median probability values. , median values classes normalised, likely value assigned class segment.Labeling: set probabilities obtained time series inside segment, can used labeling. done considering median value probabilities time series inside segment classified. class, take median probability values. , median values classes normalised, likely value assigned class segment.","code":""},{"path":"object-based-time-series-image-analysis.html","id":"image-segmentation-in-sits","chapter":"Object-based time series image analysis","heading":"Image segmentation in sits","text":"first step OBIA procedure sits select data cube segmented function performs segmentation. purpose, sits provides generic sits_segment() function, allows users select different segmentation algorithms. sits_segment() function following parameters:cube: regular data cube.seg_fn: function apply segmentationroi: spatial region interest cubestart_date: starting date space-time segmentationend_date: final date space-time segmentationmemsize: memory available processingmulticores: number cores available processingoutput_dir: output directory resulting cubeversion: version resultprogress: show progress bar?sits version 1.4.2, one segmentation function available (sits_slic) implements extended version Simple Linear Iterative Clustering (SLIC) described . future versions sits, expect include additional functions support spatio-temporal segmentation.","code":""},{"path":"object-based-time-series-image-analysis.html","id":"simple-linear-iterative-clustering-algorithm","chapter":"Object-based time series image analysis","heading":"Simple linear iterative clustering algorithm","text":"building multidimensional space, use Simple Linear Iterative Clustering (SLIC) algorithm [91] clusters pixels efficiently generate compact, nearly uniform superpixels. algorithm adapted Nowosad Stepinski [92] work multispectral images. SLIC uses spectral similarity proximity image space segment image superpixels. Superpixels clusters pixels similar spectral responses close together, correspond coherent object parts image. ’s high-level view extended SLIC algorithm:algorithm starts dividing image grid, cell grid become superpixel.algorithm starts dividing image grid, cell grid become superpixel.cell, pixel center becomes initial “cluster center” superpixel.cell, pixel center becomes initial “cluster center” superpixel.pixel, algorithm calculates distance nearby cluster centers. distance includes spatial component (far pixel center superpixel terms x y coordinates) spectral component (different pixel’s spectral values average values superpixel). spectral distance calculated using temporal instances bands.pixel, algorithm calculates distance nearby cluster centers. distance includes spatial component (far pixel center superpixel terms x y coordinates) spectral component (different pixel’s spectral values average values superpixel). spectral distance calculated using temporal instances bands.pixel assigned closest cluster. pixels assigned clusters, algorithm recalculates cluster centers averaging spatial coordinates spectral values pixels within cluster.pixel assigned closest cluster. pixels assigned clusters, algorithm recalculates cluster centers averaging spatial coordinates spectral values pixels within cluster.Steps 3-4 repeated set number iterations, cluster assignments stop changing.Steps 3-4 repeated set number iterations, cluster assignments stop changing.outcome SLIC algorithm set superpixels try capture boundaries objects within image. SLIC implementation sits 1.4.1 uses supercells R package [92]. parameters sits_slic() function :dist_fn: metric used calculate distance values. default, “euclidean” metric used. Alternatives include “jsd” (Jensen-Shannon distance), “dtw” (dynamic time warping) one 46 distance similarity measures implemented R package philentropy [93].avg_fn: function calculate value superpixel. two internal functions implemented C++ - “mean” “median”. also possible provide user-defined R function returns one value based R vector.step: distance, measured number cells, initial superpixels’ centers.compactness: value controls superpixels’ density. Larger values cause clusters compact.minarea: minimal size output superpixels (measured number cells).","code":""},{"path":"object-based-time-series-image-analysis.html","id":"example-of-slic-based-segmentation-and-classification","chapter":"Object-based time series image analysis","heading":"Example of SLIC-based segmentation and classification","text":"show example SLIC-based segmentation, first build data cube, using images available sitsdata package.\nFigure 113: Sentinel-2 image area Rondonia, Brazil (source: authors).\nfollowing example produces segmented image. SLIC algorithm, take initial separation cluster centres (step) 20 pixels, compactness 1, minimum area superpixel (min_area) 20 pixels.useful visualize segments leaflet together RGB image using sits_view().obtaining segments, next step classify . done first training classification model. case study, use SVM model.segment classification procedure applies model number user-defined samples inside segment. samples assigned set probability values, one class. obtain median value probabilities class normalize . output procedure vector data cube containing set classified segments. parameters sits_classify()view classified segments together original image, use plot() sits_view(), following example.conclude OBIA analysis applied image time series worthy efficient technique land classification, combining desirable sharp object boundary properties required land use cover maps analytical power image time series.","code":"\n# directory where files are located\ndata_dir <- system.file(\"extdata/Rondonia-20LMR\", package = \"sitsdata\")\n# Builds a cube based on existing files\ncube_20LMR <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  bands = c(\"B02\", \"B8A\", \"B11\")\n)\nplot(cube_20LMR, red = \"B11\", green = \"B8A\", blue = \"B02\", date = \"2022-07-16\")\n# segment a cube using SLIC\n# Files are available in a local directory\nsegments_20LMR <- sits_segment(\n  cube = cube_20LMR,\n  output_dir = \"./tempdir/chp14\",\n  seg_fn = sits_slic(\n    step = 20,\n    compactness = 1,\n    dist_fun = \"euclidean\",\n    iter = 20,\n    minarea = 20\n  )\n)\nplot(segments_20LMR,\n  red = \"B11\", green = \"B8A\", blue = \"B02\",\n  date = \"2022-07-16\"\n)\nsits_view(segments_20LMR,\n  red = \"B11\", green = \"B8A\", blue = \"B02\",\n  dates = \"2022-07-16\"\n)\nsvm_model <- sits_train(samples_deforestation, sits_svm())\nsegments_20LMR_probs_svm <- sits_classify(\n  data = segments_20LMR,\n  ml_model = svm_model,\n  output_dir = \"./tempdir/chp14\",\n  n_sam_pol = 40,\n  gpu_memory = 16,\n  memsize = 24,\n  multicores = 6,\n  version = \"svm-segments\"\n)\n\nsegments_20LMR_class_svm <- sits_label_classification(\n  segments_20LMR_probs_svm,\n  output_dir = \"./tempdir/chp14\",\n  memsize = 24,\n  multicores = 6,\n  version = \"svm-segments\"\n)\nsits_view(\n  segments_20LMR_class_svm,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  dates = \"2022-07-16\",\n)"},{"path":"data-visualisation-in-sits.html","id":"data-visualisation-in-sits","chapter":"Data visualisation in sits","heading":"Data visualisation in sits","text":"Chapter contains discussion plotting visualisation data cubes sits.","code":""},{"path":"data-visualisation-in-sits.html","id":"plotting","chapter":"Data visualisation in sits","heading":"Plotting","text":"plot() function produces graphical display data cubes, time series, models, SOM maps. type data, dedicated version plot() function. See ?plot.sits details. Plotting time series, models SOM outputs uses ggplot2 package; maps plotted using tmap package. plotting images classified maps, users can control output, appropriate parameters type image. chapter, provide examples options available plotting different types maps.Plotting visualisation function sits use COG overview available. COG overviews reduced-resolution versions main image, stored within file. Overviews allow quick rendering lower zoom levels, improving performance dealing large images. Usually, single GeoTIFF many overviews, match different zoom levels","code":""},{"path":"data-visualisation-in-sits.html","id":"plotting-false-color-maps","chapter":"Data visualisation in sits","heading":"Plotting false color maps","text":"refer false color maps images plotted color scale. Usually single bands, indexes NDVI DEMs. data sets, parameters plot() :x: data cube containing data visualised;band: band index plotted;pallete: color scheme used false color maps, one RColorBrewer palettes. palettes designed effective map display Prof Cynthia Brewer described Brewer website. default, optical images use RdYlGn scheme, SAR images use Greys, DEM cubes use Spectral.rev: whether color palette reversed; TRUE DEM cubes, FALSE otherwise.scale: global scale parameter used tmap. font sizes, symbol sizes, border widths, line widths controlled value. Default 0.75; users vary parameter see results.first_quantile: 1st quantile stretching images (default = 0.05).last_quantile: last quantile stretching images (default = 0.95).max_cog_size: cloud-oriented geotiff files (COG), sets maximum number lines columns COG overview used plotting.following optional parameters available allow detailed control plot output:\n- graticules_labels_size: size coordinates labels (default = 0.8).\n- legend_title_size: relative size legend title (default = 1.0).\n- legend_text_size: relative size legend text (default = 1.0).\n- legend_bg_color: color legend background (default = “white”).\n- legend_bg_alpha: legend opacity (default = 0.5).\n- legend_position: place legend (options = “inside” “outside” “inside” default).following example shows plot NDVI index data cube. data cube covers part MGRS tile 20LMR contains bands “B02”, “B03”, “B04”, “B05”, “B06”, “B07”, “B08”, “B11”, “B12”, “B8A”, “EVI”, “NBR”, “NDVI” period 2022-01-05 2022-12-23. use parameters defaults.\nFigure 114: Sentinel-2 NDVI index covering tile 20LMR (© EU Copernicus Sentinel Programme; source: Microsoft modified authors).\n","code":"\n# set the directory where the data is\ndata_dir <- system.file(\"extdata/Rondonia-20LMR\", package = \"sitsdata\")\n# read the data cube\nro_20LMR <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir\n)\n# plot the NDVI for date 2022-08-01\nplot(ro_20LMR,\n  band = \"NDVI\",\n  date = \"2022-08-01\",\n  palette = \"Greens\",\n  legend_position = \"outside\",\n  scale = 1.0\n)"},{"path":"data-visualisation-in-sits.html","id":"plotting-rgb-color-composite-maps","chapter":"Data visualisation in sits","heading":"Plotting RGB color composite maps","text":"RGB color composite maps, parameters plot function :x: data cube containing data visualised;band: band index plotted;date: date plotted (must part cube timeline);red: band index associated red color;green: band index associated green color;blue: band index associated blue color;scale: global scale parameter used tmap. font sizes, symbol sizes, border widths, line widths controlled value. Default 0.75; users vary parameter see results.first_quantile: 1st quantile stretching images (default = 0.05).last_quantile: last quantile stretching images (default = 0.95).max_cog_size: cloud-oriented geotiff files (COG), sets maximum number lines columns COG overview used plotting.optional parameters listed previous section also available. example follows:\nFigure 115: Sentinel-2 color composite covering tile 20LMR (© EU Copernicus Sentinel Programme; source: Microsoft modified authors).\n","code":"\n# plot the NDVI for date 2022-08-01\nplot(ro_20LMR,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2022-08-01\",\n  palette = \"Greens\",\n  scale = 1.0\n)"},{"path":"data-visualisation-in-sits.html","id":"plotting-classified-maps","chapter":"Data visualisation in sits","heading":"Plotting classified maps","text":"Classified maps pose additional challenge plotting association labels colors. case, sits allows three alternatives:Predefined color scheme: sits includes well-established color schemes IBGP, UMD, ESA_CCI_LC, WORLDCOVER. predefined color table associates labels commonly used LUCC classification colors. Users can also create color schemas. Please see section “Colors Work sits chapter.legend: case, users provide named vector labels colors, shown example .palette: RColorBrewer categorical palette, assigned labels color table.parameters plot() applied classified data cube :x: data cube containing classified map;legend: legend associated colors classes, NULL default.palette: color palette used undefined colors, Spectral default.scale: global scale parameter used tmap.optional parameters listed previous section also available. example plotting classified data cube default color scheme, please see section “Reading classified images local data cube” “Earth observation data cubes” chapter. follows show similar case using legend.\nFigure 116: Classified data cube year 2020/2021 Rondonia, Brazil (© EU Copernicus Sentinel Programme; source: authors).\n","code":"\n# Create a cube based on a classified image\ndata_dir <- system.file(\"extdata/Rondonia-20LLP\",\n  package = \"sitsdata\"\n)\n# Read the classified cube\nrondonia_class_cube <- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  bands = \"class\",\n  labels = c(\n    \"1\" = \"Burned\", \"2\" = \"Cleared\",\n    \"3\" = \"Degraded\", \"4\" = \"Natural_Forest\"\n  ),\n  data_dir = data_dir\n)\n# Plot the classified cube\nplot(rondonia_class_cube,\n  legend = c(\n    \"Burned\" = \"#a93226\",\n    \"Cleared\" = \"#f9e79f\",\n    \"Degraded\" = \"#d4efdf\",\n    \"Natural_Forest\" = \"#1e8449\"\n  ),\n  scale = 1.0,\n  legend_position = \"outside\"\n)"},{"path":"data-visualisation-in-sits.html","id":"visualization-of-data-cubes-in-interactive-maps","chapter":"Data visualisation in sits","heading":"Visualization of data cubes in interactive maps","text":"Data cubes samples can also shown interactive maps using sits_view(). function creates tiled overlays different kinds data cubes, allowing comparison original, intermediate final results. also includes background maps. following example creates interactive map combining original data cube classified map.","code":"\nsits_view(rondonia_class_cube,\n  legend = c(\n    \"Burned\" = \"#a93226\",\n    \"Cleared\" = \"#f9e79f\",\n    \"Degraded\" = \"#d4efdf\",\n    \"Natural_Forest\" = \"#1e8449\"\n  )\n)"},{"path":"data-visualisation-in-sits.html","id":"how-colors-work-in-sits","chapter":"Data visualisation in sits","heading":"How colors work in sits","text":"examples provided book, color legend taken predefined color pallete provided sits. default color definition file used sits 220 class names, can shown using sits_colors()colors grouped typical legends used Earth observation community, include “IGBP”, “UMD”, “ESA_CCI_LC”, “WORLDCOVER”, “PRODES”, “PRODES_VISUAL”, “TERRA_CLASS”, “TERRA_CLASS_PT”. following commands shows colors associated IGBP legend [94].\nFigure 117: Colors used sits package represeny IGBP legend (source: authors).\ndefault color table can extended using sits_colors_set(). example user-defined color table, consider definition covers level 1 Anderson Classification System used US National Land Cover Data, obtained defining set colors associated new legend. colors defined HEX values color names consist single string; multiple names need connected underscore(“_“).\nFigure 118: Example defining colors Anderson Land Classification Scheme(source: authors).\noriginal default sits color table can restored using sits_colors_reset().","code":"#> [1] \"Returning all available colors\"#> # A tibble: 241 × 2\n#>    name                             color  \n#>    <chr>                            <chr>  \n#>  1 Evergreen_Broadleaf_Forest       #1E8449\n#>  2 Evergreen_Broadleaf_Forests      #1E8449\n#>  3 Tree_Cover_Broadleaved_Evergreen #1E8449\n#>  4 Forest                           #1E8449\n#>  5 Forests                          #1E8449\n#>  6 Closed_Forest                    #1E8449\n#>  7 Closed_Forests                   #1E8449\n#>  8 Mountainside_Forest              #229C59\n#>  9 Mountainside_Forests             #229C59\n#> 10 Open_Forest                      #53A145\n#> # ℹ 231 more rows\n# Display default `sits` colors\nsits_colors_show(legend = \"IGBP\")\n# Define a color table based on the Anderson Land Classification System\nus_nlcd <- tibble::tibble(name = character(), color = character())\nus_nlcd <- us_nlcd |>\n  tibble::add_row(name = \"Urban_Built_Up\", color = \"#85929E\") |>\n  tibble::add_row(name = \"Agricultural_Land\", color = \"#F0B27A\") |>\n  tibble::add_row(name = \"Rangeland\", color = \"#F1C40F\") |>\n  tibble::add_row(name = \"Forest_Land\", color = \"#27AE60\") |>\n  tibble::add_row(name = \"Water\", color = \"#2980B9\") |>\n  tibble::add_row(name = \"Wetland\", color = \"#D4E6F1\") |>\n  tibble::add_row(name = \"Barren_Land\", color = \"#FDEBD0\") |>\n  tibble::add_row(name = \"Tundra\", color = \"#EBDEF0\") |>\n  tibble::add_row(name = \"Snow_and_Ice\", color = \"#F7F9F9\")\n# Load the color table into `sits`\nsits_colors_set(colors = us_nlcd, legend = \"US_NLCD\")\n# Show the new legend\nsits_colors_show(legend = \"US_NLCD\")"},{"path":"data-visualisation-in-sits.html","id":"exporting-colors-to-qgis","chapter":"Data visualisation in sits","heading":"Exporting colors to QGIS","text":"simplify process importing data QGIS, color palette used display classified maps sits can exported QGIS style using sits_colors_qgis. function takes two parameters: () cube, classified data cube; (b) file, file QGIS style XML written . case study, first retrieve plot classified data cube export colors QGIS XML style.\nFigure 119: Classified data cube year 2022 Rondonia, Brazil (© EU Copernicus Sentinel Programme; source: authors).\nfile read QGIS TIFF file whose location informed data cube, follows.color schema can exported QGIS follows.","code":"\n# Create a cube based on a classified image\ndata_dir <- system.file(\"extdata/Rondonia-Class-2022-Mosaic\",\n  package = \"sitsdata\"\n)\n\n# labels of the classified image\nlabels <- c(\n  \"1\" = \"Clear_Cut_Bare_Soil\",\n  \"2\" = \"Clear_Cut_Burned_Area\",\n  \"3\" = \"Clear_Cut_Vegetation\",\n  \"4\" = \"Forest\",\n  \"5\" = \"Mountainside_Forest\",\n  \"6\" = \"Riparian_Forest\",\n  \"7\" = \"Seasonally_Flooded\",\n  \"8\" = \"Water\",\n  \"9\" = \"Wetland\"\n)\n# read classified data cube\nro_class <- sits_cube(\n  source = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  data_dir = data_dir,\n  bands = \"class\",\n  labels = labels,\n  version = \"mosaic\"\n)\n# Plot the classified cube\nplot(ro_class, scale = 1.0)\n# Show the location of the classified map\nro_class[[\"file_info\"]][[1]]$path#> [1] \"/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/sitsdata/extdata/Rondonia-Class-2022-Mosaic/SENTINEL-2_MSI_MOSAIC_2022-01-05_2022-12-23_class_mosaic.tif\"\n# Export the color schema to QGIS\nsits_colors_qgis(ro_class, file = \"./tempdir/chp15/qgis_style.xml\")"},{"path":"technical-annex.html","id":"technical-annex","chapter":"Technical annex","heading":"Technical annex","text":"Chapter contains technical details algorithms available sits. intended support want understand package works also want contribute development.","code":""},{"path":"technical-annex.html","id":"adding-functions-to-the-sits-api","chapter":"Technical annex","heading":"Adding functions to the sits API","text":"","code":""},{"path":"technical-annex.html","id":"general-principles","chapter":"Technical annex","heading":"General principles","text":"New functions build sits API follow general principles .target audience sits community remote sensing experts Earth Sciences background want use state---art data analysis methods minimal investment programming skills. design sits API considers typical workflow land classification using satellite image time series thus provides clear direct set functions, easy learn master.target audience sits community remote sensing experts Earth Sciences background want use state---art data analysis methods minimal investment programming skills. design sits API considers typical workflow land classification using satellite image time series thus provides clear direct set functions, easy learn master.reason, welcome contributors provide useful additions existing API, new ML/DL classification algorithms. case new API function, making pull request please raise issue stating rationale new function.reason, welcome contributors provide useful additions existing API, new ML/DL classification algorithms. case new API function, making pull request please raise issue stating rationale new function.functions sits use S3 programming model strong emphasis generic methods wich specialized depending input data type. See example implementation sits_bands() function.functions sits use S3 programming model strong emphasis generic methods wich specialized depending input data type. See example implementation sits_bands() function.Please include contributed code using S4 programming model. break structure logic existing code. Convert code S4 S3.Please include contributed code using S4 programming model. break structure logic existing code. Convert code S4 S3.Use generic functions much possible, improve modularity maintenance. code decision points using -else clauses, , X; else Y consider using generic functions.Use generic functions much possible, improve modularity maintenance. code decision points using -else clauses, , X; else Y consider using generic functions.Functions use torch package use R6 model compatible package. See example, code sits_tempcnn.R api_torch.R. convert pyTorch code R include straightforward. Please see Technical Annex sits -line book.Functions use torch package use R6 model compatible package. See example, code sits_tempcnn.R api_torch.R. convert pyTorch code R include straightforward. Please see Technical Annex sits -line book.sits code relies packages tidyverse work tables list. use dplyr tidyr data selection wrangling, purrr slider loops lists table, lubridate handle dates times.sits code relies packages tidyverse work tables list. use dplyr tidyr data selection wrangling, purrr slider loops lists table, lubridate handle dates times.","code":""},{"path":"technical-annex.html","id":"adherence-to-the-sits-data-types","chapter":"Technical annex","heading":"Adherence to the sits data types","text":"sits package built top three data types: time series tibble, data cubes models. sits functions one types inputs one return values. time series tibble contains data metadata. first six columns contain metadata: spatial temporal information, label assigned sample, data cube data extracted. time_series column contains time series data spatiotemporal location. time series tibbles objects class sits.cube data type designed store metadata image files. principle, images part data cube share geographical region, bands, regularized fit pre-defined temporal interval. Data cubes sits organized tiles. tile element satellite’s mission reference system, example MGRS Sentinel-2 WRS2 Landsat. cube tibble row contains information data covering one tile. row cube tibble contains column named file_info; column contains list stores tibbleThe cube data type specialised raster_cube (ARD images), vector_cube (ARD cube segmentation vectors). probs_cube (probabilities produced classification algorithms raster data), probs_vector_cube(probabilites generated vector classification segments), uncertainty_cube (cubes uncertainty information), class_cube (labelled maps). See code sits_plot.R example specialisation plot handle different classes raster data.ML/DL models sits result sits_train belong ml_model class. addition, models assigned second class, unique ML models (e.g, rfor_model, svm_model) generic DL torch based models (torch_model). class information used plotting models establishing model can run GPUs.","code":""},{"path":"technical-annex.html","id":"literal-values-error-messages-and-testing","chapter":"Technical annex","heading":"Literal values, error messages, and testing","text":"internal sits code literal values, stored YAML configuration files ./inst/extdata/config.yml ./inst/extdata/config_internals.yml. first file contains configuration parameters relevant users, related visualisation plotting; second contains parameters relevant developers. values accessible using .conf function. example, value default size ploting COG files accessed using command .conf[\"plot\", \"max_size\"].Error messages also stored outside code YAML configuration file ./inst/extdata/config_messages.yml. values accessible using .conf function. example, error associated invalid NA value input parameter accessible using th function .conf(\"messages\", \".check_na_parameter\").strive high code coverage (> 90%). Every parameter sits function (including internal ones) checked consistency. Please see api_check.R.","code":""},{"path":"technical-annex.html","id":"supporting-new-stac-based-image-catalogues","chapter":"Technical annex","heading":"Supporting new STAC-based image catalogues","text":"want include STAC-based catalogue yet supported sits, encourage look existing implementations catalogues Microsoft Planetary Computer (MPC), Digital Earth Africa (DEA) AWS. STAC-based catalogues sits associated YAML description files, available directory .inst/exdata/sources. example, YAML file config_source_mpc.yml describes contents MPC collections supported sits. Please first provide YAML file lists detailed contents new catalogue wish include. Follow examples provided.writing YAML file, need consider access query new catalogue. entry point access catalogues sits_cube.stac_cube() function, turn calls sequence functions described generic interface api_source.R. calls API handled functions api_source_stac.R provides interface rstac package handles STAC queries.STAC catalogue different. STAC specification allows providers implement data descriptions specific information. reason, generic API described api_source.R needs specialized provider. Whenever provider needs specific implementations parts STAC protocol, include separate files. example, api_source_mpc.R implements specific quirks MPC platform. Similarly, specific support CDSE (Copernicus Data Space Environment) available api_source_cdse.R.","code":""},{"path":"technical-annex.html","id":"including-new-methods-for-machine-learning","chapter":"Technical annex","heading":"Including new methods for machine learning","text":"section provides guidance experts want include new methods machine learning work connection sits. discussion assumes familiarity R language. Developers consult Hadley Wickham’s excellent book Advanced R, especially Chapter 10 “Function Factories”.machine learning deep learning algorithm sits follow logic; models created sits_train(). function two parameters: () samples, set time series training samples; (b) ml_method, function fits model input data. result function passed sits_classify() classify time series data cubes. structure sits_train() simple, shown .R terms, sits_train() function factory, function makes functions. behavior possible functions first-class objects R. words, can bound name way variables . second propriety R functions capture (enclose) environment created. words, function returned result another function, internal variables used create available inside environment. programming language, technique called “closure”.following definition Wikipedia captures purpose clousures: “Operationally, closure record storing function together environment. environment mapping associating free variable function value reference name bound closure created. closure allows function access captured variables closure’s copies values references, even function invoked outside scope.”sits, properties closures used basis making training classification independent. return sits_train() model contains information classify input values, well information samples used train model.ensure models work fashion, machine learning functions sits also share data structure prediction. data structure created sits_predictors(), transforms time series tibble set values suitable using training data, shown following example.predictors tibble organized combination “X” “Y” values used machine learning algorithms. first two columns sample_id label. columns contain data values, organized band time. machine learning methods time-sensitive, random forest, organization sufficient training. case time-sensitive methods tempCNN, arrangements necessary ensure tensors right dimensions. Please refer sits_tempcnn() source code example adapt prediction table appropriate torch tensor.algorithms require data normalization. Therefore, sits_predictors() code usually combined methods extract statistical information normalize data, example .following example shows implementation LightGBM algorithm, designed efficiently handle large-scale datasets perform fast training inference [95]. Gradient boosting machine learning technique builds ensemble weak prediction models, typically decision trees, create stronger model. LightGBM specifically focuses optimizing training prediction speed, making particularly suitable large datasets. example builds model using lightgbm package. model applied later obtain classification.Since LightGBM gradient boosting model, uses part data testing data improve model’s performance. split training test samples controlled parameter, shown following code extract.include lightgbm package part sits, need create new training function compatible machine learning methods package called sits_train(). compatibility, new function called sits_lightgbm(). implementation uses two functions lightgbm: () lgb.Dataset(), transforms training test samples internal structures; (b) lgb.train(), trains model.parameters lightgbm::lgb.train() : () boosting_type, boosting algorithm; (b) objective, classification objective (c) num_iterations, number runs; (d) max_depth, maximum tree depth; (d) min_samples_leaf, minimum size data one leaf (avoid overfitting); (f) learning_rate, learning rate algorithm; (g) n_iter_no_change, number successive iterations stop training validation metrics improve; (h) validation_split, fraction training data used validation data.code two nested functions: train_fun() predict_fun(). sits_lightgbm() called, train_fun() transforms input samples predictors uses train algorithm, creating model (lgbm_model). model included part function’s closure becomes available classification time. Inside train_fun(), include predict_fun(), applies lgbm_model object classify input values. train_fun object returned closure, using sits_factory_function constructor. function allows model called either part sits_train() called independently, result.result, following calls equivalent.one additional requirement algorithm compatible sits. Data cube processing algorithms sits run parallel. reason, classification model trained, serialized, shown following line. serialized version model exported function closure, can used classification time.classification, predict_fun() called parallel CPU. moment, serialized string transformed back model, run obtain classification, shown code.Therefore, using function factories produce closures, sits keeps classification function independent machine learning deep learning algorithm. policy allows independent proposal, testing, development new classification methods. also enables improvements parallel processing methods without affecting existing classification methods.illustrate separation training classification, new algorithm developed chapter using lightgbm used classify data cube. code one Chapter Introduction example data cube classification, except use lgb_method().\nFigure 120: Classification map Sinop using LightGBM (source: authors).\n","code":"\nsits_train <- function(samples, ml_method) {\n  # train a ml classifier with the given data\n  result <- ml_method(samples)\n  # return a valid machine learning method\n  return(result)\n}\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\npred <- sits_predictors(samples_matogrosso_mod13q1)\npred#> # A tibble: 1,837 × 94\n#>    sample_id label  NDVI1 NDVI2 NDVI3 NDVI4 NDVI5 NDVI6 NDVI7 NDVI8 NDVI9 NDVI10\n#>        <int> <chr>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n#>  1         1 Pastu… 0.500 0.485 0.716 0.654 0.591 0.662 0.734 0.739 0.768  0.797\n#>  2         2 Pastu… 0.364 0.484 0.605 0.726 0.778 0.829 0.762 0.762 0.643  0.610\n#>  3         3 Pastu… 0.577 0.674 0.639 0.569 0.596 0.623 0.650 0.650 0.637  0.646\n#>  4         4 Pastu… 0.597 0.699 0.789 0.792 0.794 0.72  0.646 0.705 0.757  0.810\n#>  5         5 Pastu… 0.388 0.491 0.527 0.660 0.677 0.746 0.816 0.816 0.825  0.835\n#>  6         6 Pastu… 0.350 0.345 0.364 0.429 0.506 0.583 0.660 0.616 0.580  0.651\n#>  7         7 Pastu… 0.490 0.527 0.543 0.583 0.594 0.605 0.616 0.627 0.622  0.644\n#>  8         8 Pastu… 0.435 0.574 0.395 0.392 0.518 0.597 0.648 0.774 0.786  0.798\n#>  9         9 Pastu… 0.396 0.473 0.542 0.587 0.649 0.697 0.696 0.695 0.699  0.703\n#> 10        10 Pastu… 0.354 0.387 0.527 0.577 0.626 0.723 0.655 0.655 0.646  0.536\n#> # ℹ 1,827 more rows\n#> # ℹ 82 more variables: NDVI11 <dbl>, NDVI12 <dbl>, NDVI13 <dbl>, NDVI14 <dbl>,\n#> #   NDVI15 <dbl>, NDVI16 <dbl>, NDVI17 <dbl>, NDVI18 <dbl>, NDVI19 <dbl>,\n#> #   NDVI20 <dbl>, NDVI21 <dbl>, NDVI22 <dbl>, NDVI23 <dbl>, EVI1 <dbl>,\n#> #   EVI2 <dbl>, EVI3 <dbl>, EVI4 <dbl>, EVI5 <dbl>, EVI6 <dbl>, EVI7 <dbl>,\n#> #   EVI8 <dbl>, EVI9 <dbl>, EVI10 <dbl>, EVI11 <dbl>, EVI12 <dbl>, EVI13 <dbl>,\n#> #   EVI14 <dbl>, EVI15 <dbl>, EVI16 <dbl>, EVI17 <dbl>, EVI18 <dbl>, …\n# Data normalization\nml_stats <- sits_stats(samples)\n# extract the training samples\ntrain_samples <- sits_predictors(samples)\n# normalize the training samples\ntrain_samples <- sits_pred_normalize(pred = train_samples, stats = ml_stats)\n# split the data into training and validation datasets\n# create partitions different splits of the input data\ntest_samples <- sits_pred_sample(train_samples,\n  frac = validation_split\n)\n# Remove the lines used for validation\nsel <- !(train_samples$sample_id %in% test_samples$sample_id)\ntrain_samples <- train_samples[sel, ]\n# install \"lightgbm\" package if not available\nif (!require(\"lightgbm\")) install.packages(\"lightgbm\")\n# create a function in sits style for LightGBM algorithm\nsits_lightgbm <- function(samples = NULL,\n                          boosting_type = \"gbdt\",\n                          objective = \"multiclass\",\n                          min_samples_leaf = 10,\n                          max_depth = 6,\n                          learning_rate = 0.1,\n                          num_iterations = 100,\n                          n_iter_no_change = 10,\n                          validation_split = 0.2, ...) {\n  # function that returns MASS::lda model based on a sits sample tibble\n  train_fun <- function(samples) {\n    # Extract the predictors\n    train_samples <- sits_predictors(samples)\n\n    # find number of labels\n    labels <- sits_labels(samples)\n    n_labels <- length(labels)\n    # lightGBM uses numerical labels starting from 0\n    int_labels <- c(1:n_labels) - 1\n    # create a named vector with integers match the class labels\n    names(int_labels) <- labels\n\n    # add number of classes to lightGBM params\n    # split the data into training and validation datasets\n    # create partitions different splits of the input data\n    test_samples <- sits_pred_sample(train_samples,\n      frac = validation_split\n    )\n\n    # Remove the lines used for validation\n    sel <- !(train_samples$sample_id %in% test_samples$sample_id)\n    train_samples <- train_samples[sel, ]\n\n    # transform the training data to LGBM dataset\n    lgbm_train_samples <- lightgbm::lgb.Dataset(\n      data = as.matrix(train_samples[, -2:0]),\n      label = unname(int_labels[train_samples[[2]]])\n    )\n    # transform the test data to LGBM dataset\n    lgbm_test_samples <- lightgbm::lgb.Dataset(\n      data = as.matrix(test_samples[, -2:0]),\n      label = unname(int_labels[test_samples[[2]]])\n    )\n    # set the parameters for the lightGBM training\n    lgb_params <- list(\n      boosting_type = boosting_type,\n      objective = objective,\n      min_samples_leaf = min_samples_leaf,\n      max_depth = max_depth,\n      learning_rate = learning_rate,\n      num_iterations = num_iterations,\n      n_iter_no_change = n_iter_no_change,\n      num_class = n_labels\n    )\n    # call method and return the trained model\n    lgbm_model <- lightgbm::lgb.train(\n      data    = lgbm_train_samples,\n      valids  = list(test_data = lgbm_test_samples),\n      params  = lgb_params,\n      verbose = -1,\n      ...\n    )\n    # serialize the model for parallel processing\n    lgbm_model_string <- lgbm_model$save_model_to_string(NULL)\n    # construct model predict closure function and returns\n    predict_fun <- function(values) {\n      # reload the model (unserialize)\n      lgbm_model <- lightgbm::lgb.load(model_str = lgbm_model_string)\n      # predict probabilities\n      prediction <- stats::predict(lgbm_model,\n        data = as.matrix(values),\n        rawscore = FALSE,\n        reshape = TRUE\n      )\n      # adjust the names of the columns of the probs\n      colnames(prediction) <- labels\n      # retrieve the prediction results\n      return(prediction)\n    }\n    # Set model class\n    class(predict_fun) <- c(\"lightgbm_model\", \"sits_model\", class(predict_fun))\n    return(predict_fun)\n  }\n  result <- sits_factory_function(samples, train_fun)\n  return(result)\n}\nsits_factory_function <- function(data, fun) {\n  # if no data is given, we prepare a\n  # function to be called as a parameter of other functions\n  if (purrr::is_null(data)) {\n    result <- fun\n  } else {\n    # ...otherwise compute the result on the input data\n    result <- fun(data)\n  }\n  return(result)\n}\n# building a model using sits_train\nlgbm_model <- sits_train(samples, sits_lightgbm())\n# building a model directly\nlgbm_model <- sits_lightgbm(samples)\n# serialize the model for parallel processing\nlgbm_model_string <- lgbm_model$save_model_to_string(NULL)\n# unserialize the model\nlgbm_model <- lightgbm::lgb.load(model_str = lgbm_model_string)\ndata(\"samples_matogrosso_mod13q1\", package = \"sitsdata\")\n# Create a data cube using local files\nsinop <- sits_cube(\n  source = \"BDC\",\n  collection = \"MOD13Q1-6.1\",\n  data_dir = system.file(\"extdata/sinop\", package = \"sitsdata\"),\n  parse_info = c(\"X1\", \"X2\", \"tile\", \"band\", \"date\")\n)\n# The data cube has only \"NDVI\" and \"EVI\" bands\n# Select the bands NDVI and EVI\nsamples_2bands <- sits_select(\n  data = samples_matogrosso_mod13q1,\n  bands = c(\"NDVI\", \"EVI\")\n)\n# train lightGBM model\nlgb_model <- sits_train(samples_2bands, sits_lightgbm())\n\n# Classify the data cube\nsinop_probs <- sits_classify(\n  data = sinop,\n  ml_model = lgb_model,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp15\"\n)\n# Perform spatial smoothing\nsinop_bayes <- sits_smooth(\n  cube = sinop_probs,\n  multicores = 2,\n  memsize = 8,\n  output_dir = \"./tempdir/chp15\"\n)\n# Label the smoothed file\nsinop_map <- sits_label_classification(\n  cube = sinop_bayes,\n  output_dir = \"./tempdir/chp15\"\n)\n# plot the result\nplot(sinop_map, title = \"Sinop Classification Map\")"},{"path":"technical-annex.html","id":"how-parallel-processing-works-in-virtual-machines-with-cpus","chapter":"Technical annex","heading":"How parallel processing works in virtual machines with CPUs","text":"section provides overview sits_classify(), sits_smooth(), sits_label_classification() process images parallel. achieve efficiency, sits implements fault-tolerant multitasking procedure big Earth observation data classification. learning curve shortened need learn multiprocessing. Image classification sits done cluster independent workers linked virtual machine. avoid communication overhead, large payloads read stored independently; direct interaction main process workers kept minimum.classification procedure benefits fact images available cloud collections stored COGs (cloud-optimized GeoTIFF). COGs regular GeoTIFF files organized regular square blocks improve visualization access large datasets. Thus, data requests can optimized access portions images. cloud services supported sits use COG files. classification algorithm sits uses COGs ensure optimal data access, reducing /O demand much possible.approach parallel processing sits, depicted Figure 121, following steps:Based block size individual COG files, calculate size chunk must loaded memory, considering number bands timeline’s length. Chunk access optimized efficient transfer data blocks.Divide total memory available chunk size determine many processes can run parallel.core processes chunk produces subset result.Repeat process chunks cube processed.Check subimages produced correctly. problem one subimages, run failure recovery procedure ensure data processed.generating subimages, join obtain result.\nFigure 121: Parallel processing sits (Source: Simoes et al. (2021). Reproduction fair use doctrine).\napproach many advantages. dependencies proprietary software runs virtual machine supports R. Processing done concurrent independent way, communication workers. Failure one worker cause failure big data processing. software prepared resume classification processing last processed chunk, preventing failures memory exhaustion, power supply interruption, network breakdown.reduce processing time, necessary adjust sits_classify(), sits_smooth(), sits_label_classification() according capabilities host environment. memsize parameter controls size main memory (GBytes) used classification. practical approach set memsize maximum memory available virtual machine classification choose multicores largest number cores available. Based memory available size blocks COG files, sits access images optimized way. way, sits tries ensure best possible use available resources.","code":""},{"path":"technical-annex.html","id":"exporting-data-to-json","chapter":"Technical annex","heading":"Exporting data to JSON","text":"data cube time series tibble can exported exchange formats JSON.","code":"\nlibrary(jsonlite)\n# Export the data cube to JSON\njsonlite::write_json(\n  x = sinop,\n  path = \"./data_cube.json\",\n  pretty = TRUE\n)\n\n# Export the time series to JSON\njsonlite::write_json(\n  x = samples_prodes_4classes,\n  path = \"./time_series.json\",\n  pretty = TRUE\n)"},{"path":"technical-annex.html","id":"sits-and-google-earth-engine-apis-a-side-by-side-exploration","chapter":"Technical annex","heading":"SITS and Google Earth Engine APIs: A side-by-side exploration","text":"section presents side--side exploration sits Google Earth\nEngine (gee) APIs, focusing respective capabilities handling\nsatellite data. exploration structured around three key examples:\n(1) creating mosaic, (2) calculating Normalized Difference Vegetation\nIndex (NDVI), (3) performing Land Use Land Cover (LULC) classification.\nexample demonstrates tasks executed using sits gee,\noffering clear view methodologies highlighting similarities\nunique approaches API employs.","code":""},{"path":"technical-annex.html","id":"example-1-creating-a-mosaic","chapter":"Technical annex","heading":"Example 1: Creating a Mosaic","text":"common application among scientists developers field Remote\nSensing creation satellite image mosaics. mosaics formed \ncombining two images, typically used visualization various\napplications. example, demonstrate create image\nmosaic using sits gee APIs.example, Region Interest (ROI) defined using bounding box\nlongitude latitude coordinates. code snippets \nspecifying ROI sits gee environments.sitsgeeNext, load satellite imagery. example, used data Sentinel-2.\nsits, several providers offer Sentinel-2 ARD images. example,\nuse images provided Microsoft Planetary Computer (MPC).sitsgeesits provides search filters collection parameters \nsits_cube() function, whereas gee offers filters methods \nImageCollection object.sits, use sits_mosaic() function create mosaics \nimages. gee, utilize mosaic() method.\nsits_mosaic() function crops mosaic based roi parameter.\ngee, cropping performed using clip() method.\nuse roi used filter images perform\ncropping mosaic. See following code:sitsgeeFinally, results can visualized interactive map.sitsgee","code":"\nroi <- c(\n  \"lon_min\" = -63.410, \"lat_min\" = -9.783,\n  \"lon_max\" = -62.614, \"lat_max\" = -9.331\n)var roi = ee.Geometry.Rectangle([-63.410,-9.783,-62.614,-9.331]);\ndata <- sits_cube(\n  source     = \"MPC\",\n  collection = \"SENTINEL-2-L2A\",\n  bands      = c(\"B02\", \"B03\", \"B04\"),\n  tiles      = c(\"20LNQ\", \"20LMQ\"),\n  start_date = \"2024-08-01\",\n  end_date   = \"2024-08-03\"\n)var data = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n  .filterDate('2024-08-01', '2024-08-03')\n  .filter(ee.Filter.inList('MGRS_TILE', ['20LNQ', '20LMQ']))\n  .select(['B4', 'B3', 'B2']);\nmosaic <- sits_mosaic(\n  cube       = data,\n  roi        = roi,\n  multicores = 4,\n  output_dir = tempdir()\n)var mosaic = data.mosaic().clip(roi);\nsits_view(\n  x     = mosaic,\n  red   = \"B04\",\n  green = \"B03\",\n  blue  = \"B02\"\n)// Define view region\nMap.centerObject(roi, 10);\n\n// Add mosaic Image\nMap.addLayer(mosaic, {\n    min: 0, \n    max: 3000\n}, 'Mosaic');"},{"path":"technical-annex.html","id":"example-2-calculating-ndvi","chapter":"Technical annex","heading":"Example 2: Calculating NDVI","text":"example demonstrates generate time-series Normalized Difference\nVegetation Index (NDVI) using sits gee APIs.example, Region Interest (ROI) defined using sinop_roi.shp\nfile. code snippets specifying file sits \ngee environments.reproduce example, can download shapefile using link.\nsits, can just use . gee, required upload \nfile user space.sitsgeeNext, load satellite imagery. example, use data Landsat-8.\nsits, data retrieved Brazil Data Cube, although\nsources available. gee, data provided platform used.sits, data loaded, necessary transformations make \ndata ready use (e.g., factor, offset, cloud masking) applied\nautomatically. gee, users responsible performing \ntransformations .sitsgeeAfter loading satellite imagery, NDVI can generated. sits, \nfunction allows users specify formula used create new attribute,\ncase, NDVI. gee, callback function used, NDVI \ncalculated image.sitsgeeThe results clipped ROI defined beginning \nexample facilitate visualization.APIs, can define ROI performing \noperation optimize resource usage. However, example, data \ncropped calculation.sitsgeeFinally, results can visualized interactive map.sitsgee","code":"\nroi_data <- \"sinop_roi.shp\"var roi_data = ee.FeatureCollection(\"/path/to/sinop_roi\");\ndata <- sits_cube(\n  source      = \"BDC\",\n  collection  = \"LANDSAT-OLI-16D\",\n  bands       = c(\"RED\", \"NIR08\", \"CLOUD\"),\n  roi         = roi_data,\n  start_date  = \"2019-05-01\",\n  end_date    = \"2019-07-01\"\n)var data = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n  .filterBounds(roi_data)\n  .filterDate(\"2019-05-01\", \"2019-07-01\")\n  .select([\"SR_B4\", \"SR_B5\", \"QA_PIXEL\"]);\n\n// factor and offset\ndata = data.map(function(image) {\n  var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\n  return image.addBands(opticalBands, null, true);\n});\n\ndata = data.map(function(image) {\n  // Select the pixel_qa band\n  var qa = image.select('QA_PIXEL');\n\n  // Create a mask to identify cloud and cloud shadow\n  var cloudMask = qa.bitwiseAnd(1 << 5).eq(0) // Clouds\n           .and(qa.bitwiseAnd(1 << 3).eq(0)); // Cloud shadows\n\n  // Apply the cloud mask to the image\n  return image.updateMask(cloudMask);\n});\ndata_ndvi <- sits_apply(\n  data        = data,\n  NDVI        = (NIR08 - RED) / (NIR08 + RED),\n  output_dir  = tempdir(),\n  multicores  = 4,\n  progress    = TRUE\n)var data_ndvi = data.map(function(image) {\n  var ndvi = image.normalizedDifference([\"SR_B5\", \"SR_B4\"]).rename('NDVI');\n\n  return image.addBands(ndvi);\n});\n\ndata_ndvi = data_ndvi.select(\"NDVI\");\ndata_ndvi <- sits_mosaic(\n  cube       = data_ndvi,\n  roi        = roi_data,\n  output_dir = tempdir(),\n  multicores = 4\n)data_ndvi = data_ndvi.map(function(image) {\n  return image.clip(roi_data);\n});\nsits_view(data_ndvi, band = \"NDVI\", date = \"2019-05-25\", opacity = 1)// Define view region\nMap.centerObject(roi_data, 10);\n\n// Add classification map (colors from sits)\nMap.addLayer(data_ndvi, {\n    min: 0, \n    max: 1, \n    palette: [\"red\", 'white', 'green']\n}, \"NDVI Image\");"},{"path":"technical-annex.html","id":"example-3-land-use-and-land-cover-lulc-classification","chapter":"Technical annex","heading":"Example 3: Land Use and Land Cover (LULC) Classification","text":"example demonstrates perform Land Use Land Cover (LULC)\nclassification using satellite image time series machine-learning models \nsits gee.example defines region interest (ROI) using shapefile named\nsinop_roi.shp. code snippets specifying file \nsits gee environments.reproduce example, can download shapefile using link.\nsits, can just use . gee, required upload \nfile user space.sitsgeeTo train classifier, sample data labels representing behavior \nclass identified necessary. example, use small set\n18 samples. following code snippets show samples defined\nenvironment.sits, labels can type string, whereas gee requires labels \nintegers. accommodate difference, two versions sample set\ncreated: (1) one string labels use sits, (2) another\ninteger labels use gee.download samples, can use following links:\nsamples_sinop_crop sits samples_sinop_crop geesitsgeeNext, load satellite imagery. example, use data MOD13Q1 .\nsits, data retrieved Brazil Data Cube, \nsources also available. gee, platform directly provides data.sits, necessary data transformations classification tasks \nhandled automatically. contrast, gee requires users manually transform\ndata correct format.context ’s important note , gee code, transforming \nimages bands mimics approach used sits non-temporal classifiers.\nHowever, method inherently scalable gee may need adjustments\nlarger datasets bands. Additionally, temporal classifiers like\nTempCNN, transformations necessary must manually implemented \nuser gee.contrast, sits provides consistent API experience, regardless data\nsize machine learning algorithm.sitsgeeIn example, ’ll use Random Forest classifier create LULC map. \ntrain classifier, need sample data linked time-series.step shows extract associate time-series samples.sitsgeeWith time-series data extracted sample, can now train Random\nForest classifiersitsgeeNow, possible generate classification map using trained Random\nForest model.sits, classification process starts probability map.\nmap provides probability class every pixel, offering insights\nclassifier’s performance. also allows refining results using\nmethods like Bayesian probability smoothing. generating probability map,\npossible produce class map, pixel assigned class\nhighest probability.gee, possible generate probabilities, strictly\nrequired produce classification map. Yet, date document,\n---box solution available utilizing probabilities\nenhance classification results, presented sits.sitsgeeThe results clipped ROI defined beginning example \nfacilitate visualization.APIs, ’s possible define ROI processing. However, \napplied example.sitsgeeFinally, results can visualized interactive map.sitsgee","code":"\nroi_data <- \"sinop_roi.shp\"var roi_data = ee.FeatureCollection(\"/path/to/sinop_roi\");\nsamples <- \"samples_sinop_crop.shp\"var samples = ee.FeatureCollection(\"samples_sinop_crop_gee\");\ndata <- sits_cube(\n    source      = \"BDC\",\n    collection  = \"MOD13Q1-6.1\",\n    bands       = c(\"NDVI\"),\n    roi         = roi_data,\n    start_date  = \"2013-09-01\",\n    end_date    = \"2014-08-29\"\n)var data = ee.ImageCollection(\"MODIS/061/MOD13Q1\")\n  .filterBounds(roi_data)\n  .filterDate(\"2013-09-01\", \"2014-09-01\")\n  .select([\"NDVI\"]);\n\n// Transform all images to bands\ndata = data.toBands();\nsamples_ts <- sits_get_data(\n    cube       = data,\n    samples    = samples,\n    multicores = 4\n)var samples_ts = data.sampleRegions({\n  collection: samples,\n  properties: [\"label\"]\n});\nclassifier <- sits_train(\n    samples_ts, sits_rfor(num_trees = 100)\n)var classifier = ee.Classifier.smileRandomForest(100).train({\n  features: samples_ts,\n  classProperty: \"label\",\n  inputProperties: data.bandNames()\n});\nprobabilities <- sits_classify(\n    data       = data,\n    ml_model   = classifier,\n    multicores = 4,\n    roi        = roi_data,\n    output_dir = tempdir()\n)\n\nclass_map <- sits_label_classification(\n    cube       = probabilities,\n    output_dir = tempdir(),\n    multicores = 4\n)var probs_map = data.classify(classifier.setOutputMode(\"MULTIPROBABILITY\"));\nvar class_map = data.classify(classifier);\nclass_map <- sits_mosaic(\n    cube       = class_map,\n    roi        = roi_data,\n    output_dir = tempdir(),\n    multicores = 4\n)class_map = class_map.clip(roi_data);\nsits_view(class_map, opacity = 1)// Define view region\nMap.centerObject(roi_data, 10);\n\n// Add classification map (colors from sits)\nMap.addLayer(class_map, {\n    min: 1,\n    max: 4,\n    palette: [\"#FAD12D\", \"#1E8449\", \"#D68910\", \"#a2d43f\"]\n}, \"Classification map\");"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
